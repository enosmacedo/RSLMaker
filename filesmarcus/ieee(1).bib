@ARTICLE{9112157,
author={A. {Kumari} and V. {Kumar} and M. Y. {Abbasi} and S. {Kumari} and P. {Chaudhary} and C. {Chen}},
journal={IEEE Access}, title={CSEF: Cloud-Based Secure and Efficient Framework for Smart Medical System Using ECC},
year={2020},
volume={8},
number={},
pages={107838-107852},
abstract={Smart architecture is the concept to manage the facilities via internet utilization in a proper manner. There are various technologies used in smart architecture such as cloud computing, internet of things, green computing, automation and fog computing. Smart medical system (SMS) is one of the application used in architecture, which is based on communication networking along with sensor devices. In SMS, a doctor provides online treatment to patients with the help of cloud-based applications such as mobile device, wireless body area network, etc. Security and privacy are the major concern of cloud-based applications in SMS. To maintain, security and privacy, we aim to design an elliptic curve cryptography (ECC) based secure and efficient authentication framework for cloud-assisted SMS. There are six phases in the proposed protocol such as: patient registration phase, healthcare center upload phase, patient data upload phase, treatment phase, checkup phase and emergency phase. In CSEF, there are four entities like healthecare center, patient, cloud and doctor. In CSEF, mutual authentication establishes between healthcare center and cloud, patient and cloud, doctor and cloud, and patient and healthcare center by the using ECC and hash function. The CSEF is secure against security attacks, and satisfies many security attributes such as man-in-the-middle attack, impersonation attack, data non-repudiation, doctor anonymity, replay attack, known-key security property, message authentication, patient anonymity, data confidentiality, stolen-verifier attack, parallel session attack and session key security. Further, the CSEF is efficient in terms of computation and communication compared to others related frameworks. As a result, CSEF can be utilized in cloud-based SMS.},
keywords={biomedical communication;body area networks;cloud computing;computer network security;data privacy;health care;Internet of Things;medical computing;message authentication;patient treatment;public key cryptography;smart architecture;cloud computing;internet of things;fog computing;smart medical system;communication networking;cloud-based applications;wireless body area network;privacy;ECC;secure authentication framework;efficient authentication framework;cloud-assisted SMS;patient registration phase;healthcare center upload phase;patient data upload phase;treatment phase;checkup phase;emergency phase;CSEF;security attacks;security attributes;known-key security property;patient anonymity;session key security;cloud-based SMS;internet utilization;Cloud computing;Medical services;Authentication;Protocols;Privacy;Elliptic curve cryptography;Cloud-medical system;elliptic curve cryptography;mutual authentication;signature;security and privacy},
doi={10.1109/ACCESS.2020.3001152},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{7968630,
author={A. {Stanciu}},
booktitle={2017 21st International Conference on Control Systems and Computer Science (CSCS)}, title={Blockchain Based Distributed Control System for Edge Computing},
year={2017},
volume={},
number={},
pages={667-671},
abstract={Edge computing proposes a novel model for providing computational resources close to end devices that are connected to the network. It has numerous applications in Internet of Things, as well as smart grids, healthcare, smart home, etc. This paper presents ongoing research regarding the use of blockchain technology as a platform hierarchical and distributed control systems based on IEC 61499 standard. Hyperledger Fabric was selected as the blockchain solution, where function blocks are to be implemented as smart contracts on a supervisor level. The integration with the edge nodes that perform on the executive level responsible for actual process control is based on a micro-services architecture where Docker containers implement function blocks, and Kubernetes platform is used for orchestrating the execution of containers across the edge resources.},
keywords={cloud computing;data handling;distributed databases;Internet of Things;Kubernetes platform;Docker containers;microservices architecture;supervisor level;smart contracts;function blocks;blockchain solution;Hyperledger Fabric;IEC 61499 standard;blockchain technology;Internet of Things;computational resources;edge computing;blockchain based distributed control system;Decentralized control;Edge computing;IEC Standards;Peer-to-peer computing;Cloud computing;Computational modeling;edge computing;IoT;blockchain;smart contracts;hierarchical distributed control system},
doi={10.1109/CSCS.2017.102},
ISSN={2379-0482},
month={May},}
@INPROCEEDINGS{8540586,
author={N. {Singh} and U. {Lakhina} and I. {Elamvazuthi} and A. {Jangra} and A. K. {Singh}},
booktitle={2018 International Conference on Intelligent and Advanced System (ICIAS)}, title={Biomedical Data Privacy Enhancement Architecture Based on Multi-Keyword Search Technique},
year={2018},
volume={},
number={},
pages={1-6},
abstract={The Collaborative healthcare cloud environment offers potential benefits, including cost reduction and improvising the healthcare quality delivered to patients. Though, such scenarios experiences substantial challenges in case of the privacy and security of the exceptionally sensitive information contained in Electronic Health Records (EHRs). Through this paper, a Hierarchical tree-based architecture is proposed. The work is based upon multi-keyword search technique which incorporates secure search using stemming and lemmatization algorithms to improve the process efficiency and privacy detailing. It helps biomedical departments and patients to connect easily and process their queries without any intruder's intervention. Furthermore, performance of the proposed solution is empirically indorsed through the simulation experiments.},
keywords={cloud computing;data privacy;electronic health records;health care;trees (mathematics);multikeyword search technique;lemmatization algorithms;biomedical data privacy enhancement architecture;Collaborative healthcare cloud environment;cost reduction;exceptionally sensitive information;electronic health records;hierarchical tree-based architecture;EHR;stemming algorithm;Cloud computing;Indexes;Pattern matching;Encryption;Servers;Data privacy;Biomedical Systems;Cloud computing;Data privacy;EHRs;Fog computing;Healthcare collaboration;Multi-keyword search;thermal imaging;ultrasound},
doi={10.1109/ICIAS.2018.8540586},
ISSN={},
month={Aug},}
@ARTICLE{8787865,
author={M. {Abdel-Basset} and G. {Manogaran} and A. {Gamal} and V. {Chang}},
journal={IEEE Internet of Things Journal}, title={A Novel Intelligent Medical Decision Support Model Based on Soft Computing and IoT},
year={2020},
volume={7},
number={5},
pages={4160-4170},
abstract={Internet of Things (IoT) has gain the importance with the growing applications in the fields of ubiquitous and context-aware computing. In IoT, anything can be a portion of it, whether it is unintelligent objects or sensor nodes; thus extremely different kinds of services can be developed. In this regard, data storage, resource management, service creation and discovery, and resource and power management would facilitate advanced mechanism and much better infrastructure. Cloud computing and fog computing play an important role when the quantity of data and information IoT are critical. Thus, it would not be potential for standalone strength forced IoT to handle. Cloud of things is an integration of IoT with cloud computing or fog computing which can aid to realize the objectives of evolving IoT and future Internet. Fog computing is an expansion to the notion of cloud computing to the network brim, making it suitable for IoT and other implementations that need real-time and fundamental interactions. Regardless of many virtually and services unlimited resources presented by cloud-like intelligent building monitoring and others, it yet countenances various difficulties when interfering many smart things in human's life. Mobility, response time, and location consciousness are the most prominent problems. Fog and mobile edge computing have been established, to get rid of these difficulties of cloud computing. In this article, we suggest a novel framework based on computer propped diagnosis and IoT to detect and observe type-2 diabetes patients. The recommended healthcare system aims to obtain a better accuracy of diagnosis with mysterious data. The overall experimental results indicate the validity and robustness of our proposed algorithms.},
keywords={cloud computing;decision support systems;diseases;health care;home automation;Internet of Things;medical computing;mobile computing;virtually services unlimited resources;cloud-like intelligent building monitoring;mobile edge computing;cloud computing;computer propped diagnosis;novel intelligent medical decision support model;soft computing;context-aware computing;fog computing;information IoT;cloud of things;healthcare system;type-2 diabetes patients;Edge computing;Cloud computing;Diabetes;Internet of Things;Computational modeling;Decision making;Cloud computing;fog computing;Industry 5.0;Internet of Things (IoT);neutrosophic multicriteria decision making;type-2 diabetes},
doi={10.1109/JIOT.2019.2931647},
ISSN={2327-4662},
month={May},}
@INPROCEEDINGS{8911651,
author={M. {Roddy} and T. {Truong} and P. {Walsh} and M. {Al Bado} and Y. {Wu} and M. {Healy} and S. {Ahearne}},
booktitle={2019 IEEE 2nd 5G World Forum (5GWF)}, title={5G Network Slicing for Mission-critical use cases},
year={2019},
volume={},
number={},
pages={409-414},
abstract={The demand for prehospital emergency care has increased during the last decades throughout the Western world, in terms of numbers of emergency calls and dispatched ambulances. This development represents a challenge for both the prehospital emergency systems and the emergency departments at the hospitals [1]. Stroke is the fourth single leading cause of death in the UK and an accurate recognition of stroke by in-ambulance or emergency medical services (EMS) or prehospital ambulance paramedics, offers significant potential to reduce delays in presentation and treatment in acute stroke [2]. This paper demonstrates Proof-of-Concept (PoC) approaches for 5G network slicing in mission-critical use cases from the H2020 5G PPP SliceNet project, which is implementing an End-to-End (E2E) cognitive network slicing and slice management framework in virtualised multi-domain, multi-tenant 5G Networks. The paper shows how the PoC's key enablers, such as QoS-aware network slicing, edge computing and hardware acceleration, can assist with a continuous collection, processing and streaming of patient data that could shorten the time to assess and provide optimal clinical treatment pathways for potential stroke patients.},
keywords={cognitive radio;emergency services;health care;hospitals;medical information systems;mobile computing;patient care;patient treatment;quality of service;telemedicine;clinical treatment;hardware acceleration;emergency medical services;acute stroke;prehospital ambulance paramedics;in-ambulance;prehospital emergency systems;dispatched ambulances;emergency calls;prehospital emergency care;potential stroke patients;QoS-aware network slicing;multitenant 5G Networks;virtualised multidomain;slice management framework;end-to-end cognitive network slicing;H2020 5G PPP SliceNet project;5G mobile communication;Broadband communication;Stroke (medical condition);Network slicing;Mission critical systems;Hospitals;Electronic healthcare;5G;proof-of-concept (PoC);quality of service (QoS);quality of experience (QoE);network slicing;mission-critical services (MCX);eHealth;connected ambulances;artificial intelligence (AI);machine learning (ML);end-to-end (E2E);mobile edge computing (MEC);hardware acceleration;Digital Service Provider (DSP);Network Service Provider (NSP);Business Verticals;Service Level Agreement (SLA);Radio Access Network (RAN)},
doi={10.1109/5GWF.2019.8911651},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{9016504,
author={L. {de Castro Kersting} and P. {Guilherme Tassinari Araujo} and L. {Rodrigues Saquette} and T. {Baptista Noronha} and F. {Diniz Rossi} and G. {da Cunha Rodrigues}},
booktitle={2020 International Conference on Information Networking (ICOIN)}, title={In direction on dealing with timeliness in fog ecosystems: a healthcare case study},
year={2020},
volume={},
number={},
pages={523-528},
abstract={The exponential rise in the number of sensors generating data to the cloud services has boosted studies regarding Internet-of-Things (IoT). In this scenario, a huge problem has arisen: How to accurately deal with this growing demand in processing devices to address such amount of data, and consequently send it to the cloud? This paper proposes a fog environment as a solution to deal with this limitation. Therefore, this work presents a set of evaluations that help to understand how to pick IoT sensors up based on its capabilities along with the features required by fog customers applications. In other words, it refers to how to deal with timeliness in Fog Computing Environments. The results showed valuable outcomes based on parameters such as effective transmission and packet error which is essential to explain how to choose IoT sensors when dealing with timeliness in fog computing environments.},
keywords={cloud computing;health care;Internet of Things;fog ecosystem timeliness;fog computing environments;IoT sensors;fog environment;processing devices;Internet-of-Things;cloud services;healthcare case study;Edge computing;Cloud computing;Computer architecture;Performance evaluation;Sensor phenomena and characterization;Mathematical model},
doi={10.1109/ICOIN48656.2020.9016504},
ISSN={1976-7684},
month={Jan},}
@INPROCEEDINGS{9250196,
author={A. M. {Borujeni} and M. {Fathy} and N. {Mozayani}},
booktitle={2020 4th International Conference on Smart City, Internet of Things and Applications (SCIOT)}, title={Developing and Evaluating A Real time and Energy Efficient Architecture for An Internet of Health Things},
year={2020},
volume={},
number={},
pages={106-111},
abstract={Real-time health monitoring systems play a critical role in preventing heart disease by processing vital sign monitoring data. The internet of things will enhance the entire health care service-delivery and can lead to reducing the immediate risk in real-time. Fog assisted health-care IoT system and Edge computing technology are an emerging paradigm that reducing emergency response time and enhanced the quality of experiences. In hierarchical architectures, the task placement strategy for a task or service is a challenge that requires a successful response. In this paper, we propose a quality of experiences-aware health monitoring application according to patients' demands and evaluate to clarify the impacts of different scenarios. The appropriate task placement scenarios in this hierarchical architecture lead to a satisfying quality of experience for improving health services. These policies are evaluated in terms of health services delivery, energy consumption, cost of execution(CoE) in the cloud, and network usage by iFogSim toolkit. In this paper, we have developed a new approach to improve resource management policies to achieve satisfactory results.},
keywords={diseases;health care;Internet;Internet of Things;medical administrative data processing;medical information systems;patient monitoring;resource allocation;energy efficient architecture;health things;real-time health monitoring systems;heart disease;vital sign monitoring data;emergency response time;hierarchical architectures;task placement strategy;hierarchical architecture lead;satisfying quality;health services delivery;energy consumption;health care service-delivery;task placement scenarios;Medical services;Computer architecture;Real-time systems;Time factors;Internet of Things;Task analysis;Monitoring;Fog Computing;Healthcare Monitoring;Internet of Health Things;Quality of Experience;Resource Management},
doi={10.1109/SCIOT50840.2020.9250196},
ISSN={},
month={Sep.},}
@ARTICLE{7491206,
author={A. {Bader} and H. {Ghazzai} and A. {Kadri} and M. {Alouini}},
journal={IEEE Access}, title={Front-end intelligence for large-scale application-oriented internet-of-things},
year={2016},
volume={4},
number={},
pages={3257-3272},
abstract={The Internet-of-things (IoT) refer to the massive integration of electronic devices, vehicles, buildings, and other objects to collect and exchange data. It is the enabling technology for a plethora of applications touching various aspects of our lives, such as healthcare, wearables, surveillance, home automation, smart manufacturing, and intelligent automotive systems. Existing IoT architectures are highly centralized and heavily rely on a back-end core network for all decision-making processes. This may lead to inefficiencies in terms of latency, network traffic management, computational processing, and power consumption. In this paper, we advocate the empowerment of front-end IoT devices to support the back-end network in fulfilling end-user applications requirements mainly by means of improved connectivity and efficient network management. A novel conceptual framework is presented for a new generation of IoT devices that will enable multiple new features for both the IoT administrators as well as end users. Exploiting the recent emergence of software-defined architecture, these smart IoT devices will allow fast, reliable, and intelligent management of diverse IoT-based applications. After highlighting relevant shortcomings of the existing IoT architectures, we outline some key design perspectives to enable front-end intelligence while shedding light on promising future research directions.},
keywords={computer network management;decision making;Internet of Things;software defined networking;telecommunication traffic;front-end intelligence;large-scale application-oriented Internet of Things;back-end core network;decision making process;network traffic management;computational processing;latency;power consumption;software defined architecture;smart IoT device;intelligent management;Internet of things;Collaboration;Edge computing;Software defined architecture;Computer architecture;Surveillance;Data exchange;Telecommunication network management;Internet of things (IoT);front-end intelligence;administrative domains;collaboration and socialization;software-defined architectures;edge computing;fog computing},
doi={10.1109/ACCESS.2016.2580623},
ISSN={2169-3536},
month={},}
@ARTICLE{7936471,
author={L. {Lyu} and J. {Jin} and S. {Rajasegarar} and X. {He} and M. {Palaniswami}},
journal={IEEE Internet of Things Journal}, title={Fog-Empowered Anomaly Detection in IoT Using Hyperellipsoidal Clustering},
year={2017},
volume={4},
number={5},
pages={1174-1184},
abstract={Anomaly detection is important for time-critical Internet of Things (IoT) applications, such as healthcare and emergency management. The recent introduction of Fog computing architecture provides an efficient platform for delay sensitive IoT applications. Exploiting the advantages of Fog computing for anomaly detection provides the ability to detect abnormal patterns in an accurate and timely manner. Use of Centralized and Distributed anomaly detection methods suffer from significant latency and energy consumption issues. Hence, we propose a novel anomaly detection method, called Fog-Empowered anomaly detection, by harnessing the processing power of the Fog computing platform and using an efficient hyperellipsoidal clustering algorithm. The end nodes in the Fog computing architecture do not perform any processing or clustering on the data. The Fog layer and the Cloud layer nodes perform the clustering and anomaly detection process, thus helping to achieve anomaly detection in a timely manner. The evaluation using synthetic and real datasets demonstrates that our proposed approach achieves a significant reduction in latency and energy consumption compared to the Distributed and Centralized schemes, while achieving a comparable detection accuracy compared to a Centralized scheme.},
keywords={cloud computing;Internet of Things;pattern clustering;security of data;Fog computing architecture;delay sensitive IoT applications;anomaly detection process;time-critical Internet of Things applications;fog-empowered anomaly detection;hyperellipsoidal clustering algorithm;cloud layer nodes;Cloud computing;Edge computing;Ellipsoids;Internet of Things;Computer architecture;Clustering algorithms;Data models;Anomaly detection;Fog computing;hyperellipsoidal clustering;Internet of Things (IoT)},
doi={10.1109/JIOT.2017.2709942},
ISSN={2327-4662},
month={Oct},}
@ARTICLE{8010408,
author={Y. {Sahni} and J. {Cao} and S. {Zhang} and L. {Yang}},
journal={IEEE Access}, title={Edge Mesh: A New Paradigm to Enable Distributed Intelligence in Internet of Things},
year={2017},
volume={5},
number={},
pages={16441-16458},
abstract={In recent years, there has been a paradigm shift in Internet of Things (IoT) from centralized cloud computing to edge computing (or fog computing). Developments in ICT have resulted in the significant increment of communication and computation capabilities of embedded devices and this will continue to increase in coming years. However, existing paradigms do not utilize low-level devices for any decision-making process. In fact, gateway devices are also utilized mostly for communication interoperability and some low-level processing. In this paper, we have proposed a new computing paradigm, named Edge Mesh, which distributes the decision-making tasks among edge devices within the network instead of sending all the data to a centralized server. All the computation tasks and data are shared using a mesh network of edge devices and routers. Edge Mesh provides many benefits, including distributed processing, low latency, fault tolerance, better scalability, better security, and privacy. These benefits are useful for critical applications, which require higher reliability, real-time processing, mobility support, and context awareness. We first give an overview of existing computing paradigms to establish the motivation behind Edge Mesh. Then, we describe in detail about the Edge Mesh computing paradigm, including the proposed software framework, research challenges, and benefits of Edge Mesh. We have also described the task management framework and done a preliminary study on task allocation problem in Edge Mesh. Different application scenarios, including smart home, intelligent transportation system, and healthcare, are presented to illustrate the significance of Edge Mesh computing paradigm.},
keywords={cloud computing;embedded systems;Internet of Things;internetworking;mobility management (mobile radio);network servers;open systems;software fault tolerance;intelligent transportation system;healthcare;smart home;task allocation problem;task management framework;software framework;context awareness;mobility support;real-time processing;fault tolerance;distributed processing;centralized server;decision-making tasks;communication interoperability;gateway devices;embedded devices;computation capabilities;communication capabilities;ICT;fog computing;edge computing;centralized cloud computing;IoT;Internet-of-Things;distributed intelligence;edge mesh computing paradigm;Cloud computing;Edge computing;Servers;Resource management;Security;Decision making;Sensors;Edge devices;Internet of Things;distributed intelligence;distributed computing;mesh network},
doi={10.1109/ACCESS.2017.2739804},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8531185,
author={A. H. {Celdrán} and F. J. {García Clemente} and J. {Weimer} and I. {Lee}},
booktitle={2018 IEEE 20th International Conference on e-Health Networking, Applications and Services (Healthcom)}, title={ICE++: Improving Security, QoS, and High Availability of Medical Cyber-Physical Systems through Mobile Edge Computing},
year={2018},
volume={},
number={},
pages={1-8},
abstract={The disruptive vision of Medical Cyber-Physical Systems (MCPS) enables the promising next-generation of eHealth systems that are intended to interoperate efficiently, safely, and securely. Safety-critical interconnected systems that analyze patients' vital signs gathered from medical devices, infer the state of the patient's health, and start treatments issuing information to doctors and medical actuators should improve the patients' safety in a cost-efficient fashion. Despite the benefits provided by the MCPS vision, it also opens the door to critical challenges like the security and privacy, Quality of Service (QoS), and high availability of the devices composed to support the MCPS scenario. The Integrated Clinical Environment (ICE) standard is a significant step toward promoting open coordination of heterogeneous medical devices by considering the previous challenges. However, a lot of effort is still required in order to cover the whole aspects of these challenges and enable the future eHealth. In this context, we identify critical shortcomings of ICE using challenge scenarios regarding security, QoS, and high availability. According to these concerns and following the ICE standard, we propose the novel ICE++ architecture, which is oriented to the Mobile Edge Computing paradigm and combines SDN and NFV techniques to manage efficiently and automatically the MCPS elements taking into account its security, QoS, and high availability. Finally, we perform experiments that demonstrate the potential usefulness of our solution regarding the efficient and automatic management of the ICE components.},
keywords={cyber-physical systems;data privacy;health care;medical computing;medical information systems;open systems;patient treatment;quality of service;software defined networking;heterogeneous medical devices;QoS;ICE standard;disruptive vision;eHealth systems;safety-critical interconnected systems;medical actuators;MCPS vision;mobile edge computing paradigm;medical cyber-physical systems;patient treatment;patients health;patients vital signs;data security;data privacy;quality of service;integrated clinical environment standard;SDN techniques;NFV techniques;Ice;Quality of service;Security;Medical services;Privacy;Computer architecture;Hardware;MCPS;ICE;MEC;security;privacy;QoS;high availability},
doi={10.1109/HealthCom.2018.8531185},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{8744826,
author={A. {Alexandru} and D. {Coardos} and E. {Tudora}},
booktitle={2019 22nd International Conference on Control Systems and Computer Science (CSCS)}, title={IoT-Based Healthcare Remote Monitoring Platform for Elderly with Fog and Cloud Computing},
year={2019},
volume={},
number={},
pages={154-161},
abstract={In the context of a fast aging population and of its increasing need for healthcare and assistance, ubiquitous usage of Internet of Things (IoT)-based smart applications can mitigate the consequential social burden. Connected sensors and devices inside the seniors' home produce a significant amount of data about them and their daily activities. IoT and Big Data Analytics (BDA) are an important mean to derive knowledge and support for improving the life conditions for the older adults by increasing the role of Information and Communication Technology (ICT) for accomplish this goal. IoT analytics can aid in personalizing applications that benefit both elderly people and the ever-growing industries that need adapt their offer to the consumer's profiles. This paper presents a new platform that enables innovative analytics on IoT captured data from smart residences of elderly people. A solution based on the use of fog nodes and cloud system is suggested in order to afford data-driven services and to manage the complexity and provision of the necessary resources for online and offline data processing, storage, and analysis. The requirements and the design of the platform architecture are underlined. We propose an architecture of a platform based on fog computing nodes coupled with cloud computing that offers an efficient near real time processing of the big data resulted from IoT system that provides insights and data processing and analysis facilities into cloud. This integrated design has an important impact on time sensitive applications by addressing the latency issues of cloud.},
keywords={Big Data;cloud computing;data analysis;geriatrics;health care;Internet of Things;patient monitoring;IoT-based healthcare remote monitoring platform;cloud computing;fast aging population;consequential social burden;older adults;elderly people;data-driven services;fog computing nodes;big data analytics;ubiquitous usage;Internet of things;BDA;information-communication technology;ICT;Internet of Things (IoT);Big Data Analytics;fog computing;cloud computing;health},
doi={10.1109/CSCS.2019.00034},
ISSN={2379-0482},
month={May},}
@INPROCEEDINGS{9316537,
author={C. {Bouanaka} and A. E. {Laouir} and R. {Medkour}},
booktitle={2020 IEEE/ACS 17th International Conference on Computer Systems and Applications (AICCSA)}, title={IEDSS: Efficient Scheduling of Emergency Department Resources based on Fog Computing},
year={2020},
volume={},
number={},
pages={1-6},
abstract={Emergency is an essential mission of public hospitals, one of its main features is to meet requirements expected by the population, whatever their nature. This work proposes a fog-based architecture integrating intelligent algorithms; based on machine learning models, to improve the emergency department performance and the patient experience. The proposed architecture effectiveness is ensured via the fog infrastructure where interactions between the smart scheduling system; deployed on the cloud, and the doctors are maintained. To ensure the efficiency property, we adopt machine learning algorithms to assign and classify patients with regards to the urgency of their cases, their waiting time and physician's availability.},
keywords={Medical services;Scheduling;Optimal scheduling;Computer architecture;Cloud computing;Processor scheduling;Task analysis;Fog computing;Machine learning;healthcare systems;Emergy Department;Task scheduling},
doi={10.1109/AICCSA50499.2020.9316537},
ISSN={2161-5330},
month={Nov},}
@INPROCEEDINGS{8885533,
author={A. {Emam} and A. A. {Abdellatif} and A. {Mohamed} and K. A. {Harras}},
booktitle={2019 IEEE Wireless Communications and Networking Conference (WCNC)}, title={EdgeHealth: An Energy-Efficient Edge-based Remote mHealth Monitoring System},
year={2019},
volume={},
number={},
pages={1-7},
abstract={Promoting smart and scalable remote health monitoring systems is challenging due to the enormous amount of collected data that needs to be processed and transferred given the limited network resources and battery-operated devices. Thus, the conventional cloud computing paradigm alone, is not always the most suitable solution for enabling such systems. In this context, we propose and implement a smart edge-based health system that aims at decreasing the system latency and energy consumption, while optimizing the delivery of the medical data. In particular, we formulate a multi-objective optimization framework that enables an edge node to dynamically adjust compression parameters and select the optimal radio access technology (RAT) while maintaining a trade-off between energy consumption, latency, and distortion. Furthermore, to evaluate and verify our framework, we develop an experimental testbed, where a data emulator is implemented to send EEG data to an edge node that classifies, compresses, and transfers the gathered data through the optimal RAT to the health cloud. Our experimental results show that the proposed system can offer about 30% energy savings while decreasing the delivery time to half of its value compared to a system that lacks edge processing capabilities.},
keywords={cloud computing;data compression;electroencephalography;health care;medical signal processing;optimisation;patient monitoring;radio access networks;energy-efficient edge-based remote mHealth monitoring system;scalable remote health monitoring systems;network resources;battery-operated devices;conventional cloud;smart edge-based health system;energy consumption;medical data;multiobjective optimization framework;edge node;optimal radio access technology;data emulator;EEG data;optimal RAT;health cloud;edge processing;Radio access technologies;Electroencephalography;Monitoring;Image edge detection;Medical services;Sensors;Feature extraction;Mobile-Health;EEG signal;multi-RAT;Seizures detection;edge computing},
doi={10.1109/WCNC.2019.8885533},
ISSN={1558-2612},
month={April},}
@ARTICLE{7882669,
author={S. K. {Sharma} and X. {Wang}},
journal={IEEE Access}, title={Live Data Analytics With Collaborative Edge and Cloud Processing in Wireless IoT Networks},
year={2017},
volume={5},
number={},
pages={4621-4635},
abstract={Recently, big data analytics has received important attention in a variety of application domains including business, finance, space science, healthcare, telecommunication and Internet of Things (IoT). Among these areas, IoT is considered as an important platform in bringing people, processes, data and things/objects together in order to enhance the quality of our everyday lives. However, the key challenges are how to effectively extract useful features from the massive amount of heterogeneous data generated by resource-constrained IoT devices in order to provide real-time information and feedback to the end-users, and how to utilize this data-aware intelligence in enhancing the performance of wireless IoT networks. Although there are parallel advances in cloud computing and edge computing for addressing some issues in data analytics, they have their own benefits and limitations. The convergence of these two computing paradigms, i.e., massive virtually shared pool of computing and storage resources from the cloud and real-time data processing by edge computing, could effectively enable live data analytics in wireless IoT networks. In this regard, we propose a novel framework for coordinated processing between edge and cloud computing/processing by integrating advantages from both the platforms. The proposed framework can exploit the network-wide knowledge and historical information available at the cloud center to guide edge computing units towards satisfying various performance requirements of heterogeneous wireless IoT networks. Starting with the main features, key enablers and the challenges of big data analytics, we provide various synergies and distinctions between cloud and edge processing. More importantly, we identify and describe the potential key enablers for the proposed edge-cloud collaborative framework, the associated key challenges and some interesting future research directions.},
keywords={cloud computing;data analysis;Internet of Things;collaborative edge;cloud processing;wireless IoT networks;big data analytics;Internet of Things;IoT;data-aware intelligence;cloud computing;edge computing;Cloud computing;Wireless communication;Data analysis;Big Data;Wireless sensor networks;Edge computing;Distributed databases;Big data;data analytics;internet of things (IoT);cloud computing;edge computing;fog computing},
doi={10.1109/ACCESS.2017.2682640},
ISSN={2169-3536},
month={},}
@ARTICLE{9136600,
author={M. A. {Rahman} and M. S. {Hossain} and N. A. {Alrajeh} and N. {Guizani}},
journal={IEEE Network}, title={B5G and Explainable Deep Learning Assisted Healthcare Vertical at the Edge: COVID-I9 Perspective},
year={2020},
volume={34},
number={4},
pages={98-105},
abstract={B5G-based tactile edge learning shows promise as a solution to handle infectious diseases such as COVID-19 at a global level. By leveraging edge computing with the 5G RAN, management of epidemic diseases such as COVID-19 can be conducted efficiently. Deploying a hierarchical edge computing architecture offers several benefits such as scalability, low latency, and privacy for the data and the training model, which enables analysis of COVID-19 by a local trusted edge server. However, existing deep learning (DL) algorithms suffer from two crucial drawbacks: first, the training requires a large COVID-19 dataset on various dimensions, which is difficult for any local authority to manage. Second, the DL results require ethical approval and explanations from healthcare providers and other stakeholders in order to be accepted. In this article, we propose a B5G framework that supports COVID-19 diagnosis, leveraging the low-latency, high-bandwidth features of the 5G network at the edge. Our framework employs a distributed DL paradigm where each COVID-19 edge employs its own local DL framework and uses a three-phase reconciliation with the global DL framework. The local DL model runs on edge nodes while the global DL model runs on a cloud environment. The training of a local DL model is performed with the dataset available from the edge; it is applied to the global model after receiving approval from the subject matter experts at the edge. Our framework adds semantics to existing DL models so that human domain experts on COVID-19 can gain insight and semantic visualization of the key decision-making activities that take place within the deep learning ecosystem. We have implemented a subset of various COVID-19 scenarios using distributed DL at the edge and in the cloud. The test results are promising.},
keywords={5G mobile communication;biomedical communication;cloud computing;data privacy;decision making;diseases;epidemics;health care;learning (artificial intelligence);medical computing;mobile computing;neural nets;patient diagnosis;telecommunication security;B5G-based tactile edge learning;5G RAN;hierarchical edge computing architecture;local trusted edge server;COVID-19 dataset;COVID-19 diagnosis;local DL model;edge nodes;global DL model;deep learning ecosystem;COVID-19 scenarios;assisted healthcare vertical;infectious diseases;epidemic diseases;data privacy;distributed DL paradigm;cloud environment;semantic visualization;decision-making activities;COVID-19;Deep learning;Hospitals;5G mobile communication;Solid modeling;Vaccines;Image edge detection},
doi={10.1109/MNET.011.2000353},
ISSN={1558-156X},
month={July},}
@ARTICLE{8922842,
author={S. {Tanwar} and J. {Vora} and S. {Kaneriya} and S. {Tyagi} and N. {Kumar} and V. {Sharma} and I. {You}},
journal={IEEE Consumer Electronics Magazine}, title={Human Arthritis Analysis in Fog Computing Environment Using Bayesian Network Classifier and Thread Protocol},
year={2020},
volume={9},
number={1},
pages={88-94},
abstract={Nowadays, many people are facing the problem of arthritis. Regular monitoring and consultation of joint health from a specialist can help patients with this chronicle disease. The ratio of orthopedic doctors to patients with arthritis is low, worldwide. Use of smart devices can support the healthcare industry a lot. Motivated by these facts, here we propose an architecture to track the hand movements of the patient. For regular monitoring of patients with arthritis, fog and cloud gateways for real-time response generation are used. Thread protocol and Bayesian network classifier have been included in the proposed architecture to achieve reliable communication and anomaly detection, respectively. A dataset of 431 patients with arthritis is taken in real time and simulated on OMNet++ simulator. Observations show that the packet delivery ratio is improved by 15-20%, the response time is reduced by 20-30%, and the packet delivery rate is improved by 25-35%, in comparison to not using the fog and thread protocol.},
keywords={belief networks;cloud computing;diseases;health care;internetworking;medical computing;mobile computing;orthopaedics;protocols;routing protocols;human arthritis analysis;fog computing environment;Bayesian network classifier;chronicle disease;orthopedic doctors;smart devices;healthcare industry;hand movements;regular monitoring;cloud gateways;real-time response generation;packet delivery ratio;response time;Arthritis;Bayes methods;Biomedical monitoring;Logic gates;Smart devices;Sensors;Edge computing},
doi={10.1109/MCE.2019.2941456},
ISSN={2162-2256},
month={Jan},}
@INPROCEEDINGS{8766763,
author={A. Z. {Al-Marridi} and A. {Mohamed} and A. {Erbad} and A. {Al-Ali} and M. {Guizani}},
booktitle={2019 15th International Wireless Communications Mobile Computing Conference (IWCMC)}, title={Efficient EEG Mobile Edge Computing and Optimal Resource Allocation for Smart Health Applications},
year={2019},
volume={},
number={},
pages={1261-1266},
abstract={In the past few years, a rapid increase in the number of patients requiring constant monitoring, which inspires researchers to develop intelligent and sustainable remote smart healthcare services. However, the transmission of big real-time health data is a challenge since the current dynamic networks are limited by different aspects such as the bandwidth, end-to-end delay, and transmission energy. Due to this, a data reduction technique should be applied to the data before being transmitted based on the resources of the network. In this paper, we integrate efficient data reduction with wireless networking transmission to enable an adaptive compression with an acceptable distortion, while reacting to the wireless network dynamics such as channel fading and user mobility. Convolutional Auto-encoder (CAE) approach was used to implement an adaptive compression/reconstruction technique with the minimum distortion. Then, a resource allocation framework was implemented to minimize the transmission energy along with the distortion of the reconstructed signal while considering different network and applications constraints. A comparison between the results of the resource allocation framework considering both CAE and Discrete wavelet transforms (DWT) was also captured.},
keywords={biomedical communication;data reduction;discrete wavelet transforms;electroencephalography;health care;medical signal processing;mobile computing;patient monitoring;radio networks;resource allocation;signal reconstruction;discrete wavelet transforms;DWT;signal reconstruction;convolutional auto-encoder approach;adaptive compression-reconstruction technique;acceptable distortion;wireless networking transmission;efficient data reduction;data reduction technique;current dynamic networks;big real-time health data;sustainable remote smart healthcare services;intelligent healthcare services;constant monitoring;smart health applications;efficient EEG mobile edge computing;transmission energy;resource allocation framework;minimum distortion;user mobility;channel fading;wireless network dynamics;Brain modeling;Distortion;Optimization;Mathematical model;Resource management;Bandwidth;Delays;Optimization;Resource optimization;Convolutional Auto-encoder;e-Health systems;Compression.},
doi={10.1109/IWCMC.2019.8766763},
ISSN={2376-6506},
month={June},}
@INPROCEEDINGS{7885450,
author={F. {Beligianni} and M. {Alamaniotis} and A. {Fevgas} and P. {Tsompanopoulou} and P. {Bozanis} and L. H. {Tsoukalas}},
booktitle={Mediterranean Conference on Power Generation, Transmission, Distribution and Energy Conversion (MedPower 2016)}, title={An internet of things architecture for preserving privacy of energy consumption},
year={2016},
volume={},
number={},
pages={1-7},
abstract={Energy consumption by residential customers represents today around 30 to 40% of the total consumed energy, with the residential loads often to be charged for significant contribution to the peak demands both seasonal and daily. The integration of the Information and Communication Technologies (ICT) with power delivery infrastructure into Smart Grid (SG) will highly automate the production, distribution, monitoring and management of electric power, but will also introduce issues regarding consumer privacy. Internet of things (IoT) is an emerging scientific area with many practical applications to a vast variety of domains such as smart cities, home automation, autonomous vehicles, assistive technologies and healthcare. IoT is able to facilitate electric power management, by monitoring and controlling energy production and consumption, leading to significant savings. However, the IoT concept introduces several challenges and questions, with security, privacy and interoperability to be among them. In this paper, we discuss the integration of IoT and Fog computing with power systems towards efficient energy management and we illustrate a solution that preserves consumer privacy in smart grids.},
keywords={energy consumption;energy management systems;Internet of Things;smart power grids;consumer privacy;energy management;fog computing;energy production control;electric power management;healthcare;assistive technologies;autonomous vehicle;home automation;smart cities;IoT;SG;smart grid;ICT;information and communication technologies;residential loads;energy consumption;privacy preservation;Internet Of Things architecture;Smart grid;Internet of Things;Fog computing;privacy;forecasting},
doi={10.1049/cp.2016.1096},
ISSN={},
month={Nov},}
@ARTICLE{8534320,
author={M. A. {Rahman} and M. S. {Hossain} and G. {Loukas} and E. {Hassanain} and S. S. {Rahman} and M. F. {Alhamid} and M. {Guizani}},
journal={IEEE Access}, title={Blockchain-Based Mobile Edge Computing Framework for Secure Therapy Applications},
year={2018},
volume={6},
number={},
pages={72469-72478},
abstract={Mobile edge computing (MEC) is being introduced and leveraged in many domains, but few studies have addressed MEC for secure in-home therapy management. To this end, this paper presents an in-home therapy management framework, which leverages the IoT nodes and the blockchain-based decentralized MEC paradigm to support low-latency, secure, anonymous, and always-available spatiotemporal multimedia therapeutic data communication within an on-demand data-sharing scenario. To the best of our knowledge, this non-invasive, MEC-based IoT therapy platform is first done by our group. This platform can provide a full-body joint range of motion data for physically challenged individuals in a decentralized manner. With MEC, the framework can provide therapy diagnostic and analytical data on demand to a large portion of humanity who are either born with disabilities or became disabled due to accidents, war-time injuries, or old age. For security, the framework uses blockchain–Tor-based distributed transactions to preserve the therapeutic data privacy, ownership, generation, storage, and sharing. Our initial test results from a complete implementation of the framework show that it can support a sufficiently large number of users without considerable increase in mean processing time.},
keywords={Medical treatment;Task analysis;Cloud computing;5G mobile communication;Blockchain;mobile edge computing;therapy;IoT},
doi={10.1109/ACCESS.2018.2881246},
ISSN={2169-3536},
month={},}
@ARTICLE{9205252,
author={S. {Yu} and X. {Chen} and Z. {Zhou} and X. {Gong} and D. {Wu}},
journal={IEEE Internet of Things Journal}, title={When Deep Reinforcement Learning Meets Federated Learning: Intelligent Multitimescale Resource Management for Multiaccess Edge Computing in 5G Ultradense Network},
year={2021},
volume={8},
number={4},
pages={2238-2251},
abstract={Recently, smart cities, healthcare system, and smart vehicles have raised challenges on the capability and connectivity of state-of-the-art Internet-of-Things (IoT) devices, especially for the devices in hotspots area. Multiaccess edge computing (MEC) can enhance the ability of emerging resource-intensive IoT applications and has attracted much attention. However, due to the time-varying network environments, as well as the heterogeneous resources of network devices, it is hard to achieve stable, reliable, and real-time interactions between edge devices and their serving edge servers, especially in the 5G ultradense network (UDN) scenarios. Ultradense edge computing (UDEC) has the potential to fill this gap, especially in the 5G era, but it still faces challenges in its current solutions, such as the lack of: 1) efficient utilization of multiple 5G resources (e.g., computation, communication, storage, and service resources); 2) low overhead offloading decision making and resource allocation strategies; and 3) privacy and security protection schemes. Thus, we first propose an intelligent UDEC (I-UDEC) framework, which integrates blockchain and artificial intelligence (AI) into 5G UDEC networks. Then, in order to achieve real-time and low overhead computation offloading decisions and resource allocation strategies, we design a novel two-timescale deep reinforcement learning (2Ts-DRL) approach, consisting of a fast-timescale and a slow-timescale learning process, respectively. The primary objective is to minimize the total offloading delay and network resource usage by jointly optimizing computation offloading, resource allocation, and service caching placement. We also leverage federated learning (FL) to train the 2Ts-DRL model in a distributed manner, aiming to protect the edge devices’ data privacy. Simulation results corroborate the effectiveness of both the 2Ts-DRL and FL in the I-UDEC framework and prove that our proposed algorithm can reduce task execution time up to 31.87%.},
keywords={Edge computing;Servers;Resource management;Cloud computing;5G mobile communication;Machine learning;Blockchain;computation offloading;deep reinforcement learning (DRL);federated learning (FL);multiaccess edge computing (MEC);service caching;ultradense network (UDN)},
doi={10.1109/JIOT.2020.3026589},
ISSN={2327-4662},
month={Feb},}
@ARTICLE{9241470,
author={A. {Feriani} and A. {Refaey} and E. {Hossain}},
journal={IEEE Internet of Things Magazine}, title={Tracking Pandemics: A MEC-Enabled IoT Ecosystem with Learning Capability},
year={2020},
volume={3},
number={3},
pages={40-45},
abstract={The COVID-19 pandemic has resulted in unprecedented challenges to global society and the healthcare system in particular. The main objective of this article is to introduce an end-to-end Internet of Things (IoT) ecosystem for healthcare that uses an open source hardware and interoperable IoT standard for eHealth monitoring in general, and COVID-19 symptoms (e.g., fever, coughing, and fatigue) in particular. The system is designed to monitor the physical conditions of human subjects and send the data to a hierarchical multi-access edge computing (MEC) framework. Such a system is expected to be cognizant, taskable (i.e., tasks can be assigned to any computing process in the system), and adaptable. To this end, we demonstrate how a learning method can be introduced in the ecosystem to achieve taskability and efficiency. Specifically, the proposed system utilizes a shared representation learning process to extract actionable information from large volumes of high-dimensional data obtained from IoT edge devices. These edge devices are enabled with tri-sensors for real-time monitoring of COVID-19 symptoms. The feasibility of the proposed system is evaluated by testing real datasets.},
keywords={diseases;epidemics;health care;Internet of Things;learning (artificial intelligence);medical information systems;open systems;patient monitoring;public domain software;telemedicine;MEC-enabled IoT ecosystem;COVID-19 pandemic;healthcare system;open source hardware;COVID-19 symptoms;multiaccess edge computing;representation learning;IoT edge devices;real-time monitoring;ehealth monitoring;Internet of Things;interoperable IoT standard;high-dimensional data;tri-sensors;Internet of Things;COVID-19;Biomedical monitoring;Cloud computing;Sensors;Ecosystems;Coronaviruses;Pandemics},
doi={10.1109/IOTM.0001.2000142},
ISSN={2576-3199},
month={Sep.},}
@INPROCEEDINGS{8441162,
author={D. E. D. I. {Abou-Tair} and S. {Büchsenstein} and A. {Khalifeh}},
booktitle={2018 19th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)}, title={A Privacy Preserving Framework for the Internet of Things},
year={2018},
volume={},
number={},
pages={27-31},
abstract={With the proliferation of the Internet of Things (loT) and cloud based services, it becomes very essential to design and implement efficient mechanisms, to protect the users private information and secure them, taking into account the loT devices limited computational and storage capabilities. In addition, these devices are usually accessed by multiple users, and are connected to a cloud service provider, that have an access of the users data. In this paper, a privacy preserving framework is proposed that utilizes Fog layer, which act as intermediator between the loT devices and the cloud, where users data are anonymized and secured. Further, a case study in the field of healthcare is described that shows the importance of the proposed framework.},
keywords={computer network security;data privacy;Internet of Things;users data;privacy preserving framework;users private information;cloud service provider;fog layer;Internet of Things;health care field;Privacy;Cloud computing;Cryptography;Data privacy;Edge computing;Internet of Things;Internet of Things;Cloud Computing;FOG Computing;Privacy;Security},
doi={10.1109/SNPD.2018.8441162},
ISSN={},
month={June},}
@ARTICLE{8392676,
author={A. {Limaye} and T. {Adegbija}},
journal={IEEE Internet of Things Journal}, title={HERMIT: A Benchmark Suite for the Internet of Medical Things},
year={2018},
volume={5},
number={5},
pages={4212-4222},
abstract={The growth of the Internet of Things (IoT) will transform the healthcare industry, and enable the emergence of the Internet of Medical Things (IoMT). In this paper, we present and analyze HERMIT, a benchmark suite for the IoMT. The goal of HERMIT is to facilitate research into new microarchitectures and optimizations that will enable efficient execution of emerging IoMT applications. HERMIT comprises of applications spanning various domains in the healthcare industry, including computerized tomography scan, ultrasound, magnetic resonance imaging, implantable heart monitors, wearable devices. HERMIT also includes supplementary applications for security and data compression. We analyze HERMIT on an IoT prototyping platform to derive insights into IoMT applications' compute and memory characteristics. We also compare HERMIT to three commonly used benchmark suites: 1) MiBench; 2) SPEC CPU2006; and 3) PARSEC, and show that IoMT applications' characteristics differ from existing benchmarks. Our results motivate the need for a new benchmark suite to enable IoMT-targeted microarchitecture research.},
keywords={biomedical equipment;biomedical MRI;cardiology;computer architecture;computerised tomography;data compression;health care;Internet of Things;medical image processing;microprocessor chips;patient monitoring;HERMIT;benchmark suite;Medical Things;healthcare industry;emerging IoMT applications;commonly used benchmark suites;IoMT-targeted microarchitecture research;Benchmark testing;Medical services;Medical diagnostic imaging;Internet of Things;Microarchitecture;Security;Edge computing;healthcare;Internet of Medical Things (IoMT);Internet of Things (IoT);low-power embedded systems;medical devices;right-provisioned microprocessors;workload characterization},
doi={10.1109/JIOT.2018.2849859},
ISSN={2327-4662},
month={Oct},}
@INPROCEEDINGS{8010665,
author={R. {Strässle} and S. {Gerke} and T. {Brunschwiler} and Y. {Temiz} and J. {Weiss} and A. {Sridhar} and S. {Paredes} and E. {Loertscher} and N. {Ebejer} and B. {Michel} and H. -. {Lee} and C. {Alvarado} and I. {Faro} and T. {Van Kessel} and M. {Meghelli} and M. A. {Taubenblatt} and S. {Zafar} and F. {Libsch} and K. {Matsumoto}},
booktitle={2017 IEEE/ACM International Conference on Connected Health: Applications, Systems and Engineering Technologies (CHASE)}, title={Internet of the Body and Cognitive Hypervisor},
year={2017},
volume={},
number={},
pages={296-297},
abstract={Wearables that continuously acquire medically relevant parameters can reduce duration of hospitalizations and derive treatment optimizations for individual patients thus improving the quality of medical treatments. We demonstrate an architecture that includes wearables, edge and cloud computing to provide optimal user interaction and analytics of multi-parameter wearable data to accomplish this goal. We also explore the trade-offs of on-wearable processing versus raw data transmission and the use of commercial location monitors to acquire indoor location data.},
keywords={cloud computing;Internet;medical computing;mobile computing;patient monitoring;wearable computers;cognitive hypervisor;Internet;medically relevant parameters;hospitalizations;treatment optimizations;medical treatments;individual patients;edge computing;cloud computing;user interaction;multiparameter wearable data;on-wearable processing;raw data transmission;commercial location monitors;indoor location data;Biomedical monitoring;Electrocardiography;Virtual machine monitors;Monitoring;Reflection;Temperature measurement;Prediction algorithms;wearable;edge computing;healthcare},
doi={10.1109/CHASE.2017.110},
ISSN={},
month={July},}
@ARTICLE{9257055,
author={O. {Postolache} and O. A. {Dobre}},
journal={IEEE Instrumentation Measurement Magazine}, title={TC-13 — wireless and telecommunications in measurements — in action},
year={2020},
volume={23},
number={8},
pages={14-17},
abstract={Recent developments in the field of telecommunications, and at the same time in the field of smart sensors and instrumentation, have opened new horizons for society, especially for the digital society and smart implementations such as smart cities, smart homes, smart agriculture, smart healthcare, smart transportation, and smart manufacturing through Industry 4.0. To optimize the deployment of new smart sensing and instrumentation for these applications, communications between different sensing and actuation modules, as well as communications to convey the sensed information to decision-making entities, represent important issues in the 5G and beyond era. Characteristics such as flexibility, interoperability, and scalability of wireless and wired systems are key factors for the development of the digital society. In this framework, TC-13 members are working to provide solutions for the emerging field of telecommunications, with a focus on wireless communications (beyond 5G, Wi-Fi, satellite, unmanned aerial vehicles, as well as the co-existence of such systems), optical communications (fiberoptic based, optical wireless, and visible light) and underwater communications (acoustic and optical wireless). At the same time, and in strong connection with the above developments, significant research efforts have been made in the area of Internet-of-things (IoT). TC-13 is developing important research work related to IoT ecosystem components, including the communication between sensors and instrumentation and the edge/fog/cloud computing. 5G is a key component in the evolution of cloud-computing toward a more distributed environment, including fog and edge computing.},
keywords={5G mobile communication;autonomous aerial vehicles;cloud computing;distributed processing;intelligent sensors;Internet of Things;optical communication;remotely operated vehicles;satellite communication;telecommunication equipment;wireless LAN;wireless telecommunications;smart sensors;digital society;smart implementations;smart cities;smart homes;smart agriculture;smart healthcare;smart transportation;smart manufacturing;smart sensing;actuation modules;sensed information;decision-making entities;wireless wired systems;TC-13 members;wireless communications;unmanned aerial vehicles;optical wireless;visible light;underwater communications;Industry 4.0;beyond 5G communication;Wi-Fi;satellite communication;fiber optic based light;Internet-of-things;edge computing;fog computing;cloud computing;Sensors;Instruments;5G mobile communication;Conferences;Wireless sensor networks;Wireless communication;Telecommunications},
doi={10.1109/MIM.2020.9257055},
ISSN={1941-0123},
month={Nov},}
@INPROCEEDINGS{8432310,
author={P. {Ritrovato} and F. {Xhafa} and A. {Giordano}},
booktitle={2018 IEEE 32nd International Conference on Advanced Information Networking and Applications (AINA)}, title={Edge and Cluster Computing as Enabling Infrastructure for Internet of Medical Things},
year={2018},
volume={},
number={},
pages={717-723},
abstract={The continuous adoption of fitness and medical smart sensors are boosting the development of Internet of Medical Things (IoMT), reshaping and revolutionizing Healthcare. This digital transformation is paving the way to new forms of care based on real-time analysis of huge amounts of data produced by sensors, which is seen as a basis for improving clinical efficiency and helping to save lives. A medical sensor typically produces several KBs of data per second so the collection and analysis of these data can be approached with Big Data technologies. The aim of this paper is to present and evaluate a hybrid architecture for real-time anomaly detection from data streams coming from sensors attached to patients. The architecture includes an edge computing data staging platform based on Raspberry Pi 3 for data logging, data transformation in RDF triple and data streaming towards a cluster computing running Apache Kafka for collecting RDFStreams, Apache Flink for running a parallel version of the Hierarchical Temporal Memory algorithm and Cassandra for data storing. The different layers of the architecture have been evaluated in terms of both CPU performance and memory usage using the REALDISP dataset.},
keywords={Big Data;health care;intelligent sensors;Internet of Things;pattern clustering;Big Data technologies;real-time anomaly detection;edge computing data staging platform;Raspberry Pi 3;data storing;medical smart sensors;internet of medical things;IoMT;healthcare;Apache Kafka;hierarchical temporal memory algorithm;Cassandra;cluster computing;Medical services;Computer architecture;Big Data;Real-time systems;Biomedical monitoring;Wearable sensors;eHealth;IoMT;wearables;Big Data;stream computing},
doi={10.1109/AINA.2018.00108},
ISSN={2332-5658},
month={May},}
@INPROCEEDINGS{7987536,
author={A. {Limaye} and T. {Adegbija}},
booktitle={2017 IEEE Computer Society Annual Symposium on VLSI (ISVLSI)}, title={A Workload Characterization for the Internet of Medical Things (IoMT)},
year={2017},
volume={},
number={},
pages={302-307},
abstract={We perform an extensive study of medical applications that will potentially execute on the Internet of Medical Things (IoMT), from an edge computing perspective. Using this study, we perform a workload characterization of potential IoMT applications and explore the microarchitecture implications of these applications. Our study includes workloads spanning a variety of medical applications including medical image processing algorithms, inverse Radon transform, and implantable heart monitors. We compare these workloads' characteristics to an existing embedded systems benchmark suite, MiBench, to reveal their differences and similarities. The analysis presented herein will enable the study and design of right-provisioned microprocessors for the IoMT, and provide a framework for studying the execution characteristics of workloads in other emerging Internet of Things application domains.},
keywords={Internet of Things;medical computing;workload characterization;Internet of Medical Things;medical applications;edge computing perspective;IoMT applications;medical image processing algorithms;inverse Radon transform;implantable heart monitors;embedded systems;MiBench;Medical diagnostic imaging;Medical services;Edge computing;Biomedical monitoring;Monitoring;Transforms;Internet of Things;edge computing;Internet of Medical Things;right-provisioned microprocessors;low-power embedded systems;workload characterization;medical devices;healthcare},
doi={10.1109/ISVLSI.2017.60},
ISSN={2159-3477},
month={July},}
@ARTICLE{9186159,
author={L. {Zhou} and D. {Wu} and X. {Wei} and J. {Chen}},
journal={IEEE Journal on Selected Areas in Communications}, title={Cross-Modal Stream Scheduling for eHealth},
year={2021},
volume={39},
number={2},
pages={426-437},
abstract={Cross-modal applications that elaborately integrate audio, video, and haptic streams will become the mainstream of the eHealth systems. However, existing stream schedulers usually fail to simultaneously meet the cross-modal transmission requests in terms of low latency, high reliability, high throughput, and low complexity. To circumvent this dilemma, this article proposes a general cross-modal stream scheduling scheme by fully taking advantage of the characteristics of different modal streams and their underlying temporal, spatial, and semantic relevance. Specifically, we first propose a hierarchical stream category framework, in which the transmission priority of the modal stream instead of the data flow can be flexibly settled. Next, we design a series of modal-aware stream scheduling schemes by jointly making use of the network slice and mobile edge computing to achieve the tradeoff among the various metrics. Importantly, the transmission strategy can be adjusted adaptively to realize the optimal resource allocation. Subsequently, we analyze the relationship among the user experience, multi-modal impact, and stream scheduling through investigating the interacted impacts among the different modal streams, then develop a user experience based scheduling switch strategy to improve the application generality and reduce the performance fluctuation. Numerical objective and subjective results demonstrate the efficiency of the proposed cross-modal scheduling scheme.},
keywords={Haptic interfaces;Electronic healthcare;Reliability;Streaming media;Throughput;Resource management;Scheduling;Cross-modal;scheduling;latency;reliability;throughput;complexity},
doi={10.1109/JSAC.2020.3021543},
ISSN={1558-0008},
month={Feb},}
@INPROCEEDINGS{8250193,
author={D. {Rahbari} and M. {Nickray}},
booktitle={2017 21st Conference of Open Innovations Association (FRUCT)}, title={Scheduling of fog networks with optimized knapsack by symbiotic organisms search},
year={2017},
volume={},
number={},
pages={278-283},
abstract={Internet of things as a concept uses wireless sensor networks that have limitations in power, storage, and delay when processing and sending data to the cloud. Fog computing as an extension of cloud services to the edge of the network reduces latency and traffic, so it is very useful in healthcare, wearables, intelligent transportation systems and smart cities. Scheduling is the NP-hard issues in fog computing. Edge devices due to proximity to sensors and clouds are capable of processing power and are beneficial for resource management algorithms. We present a knapsack-based scheduling optimized by symbiotic organisms search that is simulated in iFogsim as a standard simulator for fog computing. The results show improvements in the energy consumption by 18%, total network usage by 1.17%, execution cost by 15%, and sensor lifetime by 5% in our scheduling method are better than the FCFS (First Come First Served) and knapsack algorithms.},
keywords={cloud computing;computational complexity;knapsack problems;resource allocation;scheduling;wireless sensor networks;fog networks;optimized knapsack;symbiotic organisms search;wireless sensor networks;fog computing;cloud services;intelligent transportation systems;NP-hard issues;edge devices;resource management algorithms;total network usage;sensor lifetime;scheduling method;healthcare;wearables;smart cities;Cloud computing;Organisms;Scheduling;Sensors;Edge computing;Network topology},
doi={10.23919/FRUCT.2017.8250193},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9139661,
author={C. {Kumar Dehury} and S. {Narayana Srirama}},
booktitle={2020 20th IEEE/ACM International Symposium on Cluster, Cloud and Internet Computing (CCGRID)}, title={An efficient service dispersal mechanism for fog and cloud computing using deep reinforcement learning},
year={2020},
volume={},
number={},
pages={589-598},
abstract={Thousands of high-end physical servers are used to fulfill the huge resource demand of diverse applications or services, ranging from healthcare data analytic services to gaming services. The network latency, as one of the major limitations of cloud computing, becomes the primary reason for introducing fog computing by pushing the computing environment towards the edge of the network. The ability to offer computing environments in close proximity to the user's device improves the delivery of high-quality services. The majority of the research is devoted to providing the high quality of services using either fog or cloud environment. In this paper, a novel deep reinforcement learning-based service dispersal approach for fog and cloud computing (DRLSD-FC) is adopted for offering the service using both environments simultaneously. The request to avail services is sliced and dispersed between the nearby fog and cloud environments. By taking advantage of cloud resources, the proposed approach minimizes the workload on the fog environment without compromising the service quality. The proposed approach is implemented using the Keras framework. Implementation results show that DRLSD-FC can outperform over other related approaches.},
keywords={cloud computing;learning (artificial intelligence);neural nets;high-end physical servers;cloud computing;fog computing;deep reinforcement learning-based service dispersal approach;Keras framework;Cloud computing;Servers;Edge computing;Machine learning;Resource management;Quality of service;Monitoring;Deep Reinforcement learning;fog computing;cloud computing;service delivery;service dispersal},
doi={10.1109/CCGrid49817.2020.00-34},
ISSN={},
month={May},}
@INPROCEEDINGS{7134002,
author={M. {Aazam} and E. {Huh}},
booktitle={2015 IEEE International Conference on Pervasive Computing and Communication Workshops (PerCom Workshops)}, title={Dynamic resource provisioning through Fog micro datacenter},
year={2015},
volume={},
number={},
pages={105-110},
abstract={Lately, pervasive and ubiquitous computing services have been under focus of not only the research community, but developers as well. Different devices generate different types of data with different frequencies. Emergency, healthcare, and latency sensitive services require real-time response. Also, it is necessary to decide what type of data is to be uploaded in the cloud, without burdening the core network and the cloud. For this purpose, Fog computing plays an important role. Fog resides between underlying IoTs and the cloud. Its purpose is to manage resources, perform data filtration, preprocessing, and security measures. For this purpose, Fog requires an effective and efficient resource management framework, which we provide in this paper. Moreover, since Fog has to deal with mobile nodes and IoTs, which involves objects and devices of different types, having a fluctuating connectivity behavior. All such types of service customers have an unpredictable relinquish probability, since any object or device can quit resource utilization at any moment. In our proposed methodology for resource estimation and management, we have taken into account these factors and formulate resource management on the basis of fluctuating relinquish probability of the customer, service type, service price, and variance of the relinquish probability. Implementation of our system was done using Java, while evaluation was done on CloudSim toolkit. The discussion and results show that these factors can help service provider estimate the right amount of resources, according to each type of service customers.},
keywords={cloud computing;computer centres;Internet of Things;mobile computing;probability;resource allocation;dynamic resource provisioning;Fog microdatacenter;ubiquitous computing services;pervasive computing services;research community;real-time response;cloud computing;Fog computing;IoT;data filtration;data preprocessing;security measures;resource management framework;mobile nodes;resource utilization;service type;service price;Java;CloudSim toolkit;service provider;Resource management;Cloud computing;Estimation;Wireless sensor networks;Sensors;Conferences;Logic gates;IoT;Cloud of Things;Fog computing;Edge Computing;Micro Data Center (MDC);resource management;Fog-Smart Gateway (FSG)},
doi={10.1109/PERCOMW.2015.7134002},
ISSN={},
month={March},}
@INPROCEEDINGS{8403540,
author={A. {Roy} and C. {Roy} and S. {Misra} and Y. {Rahulamathavan} and M. {Rajarajan}},
booktitle={2018 IEEE International Conference on Communications Workshops (ICC Workshops)}, title={CARE: Criticality-Aware Data Transmission in CPS-Based Healthcare Systems},
year={2018},
volume={},
number={},
pages={1-6},
abstract={In this paper, we propose a scheme, criticality-aware data transmission (CARE) in CPS-based healthcare systems, for increasing the processing rate of the sensed physiological parameters' value of any patient. The criticality of a patient may vary at any instant of time, and thus, continuous monitoring and quick processing of the physiological parameter value of a patient is essential. Therefore, in order to reduce the latency of data processing of a critical patient, we consider fog computing in our architecture. Based on the criticality value of physiological parameters, a Local Processing Unit (LPU) transmits the sensor data either to the fog aggregation node or cloud. We use a cooperative game theory-based Nash bargaining approach, where the LPUs bargain among themselves to decide whether the sensor data need to be transmitted to cloud or fog aggregation node. Based on the criticality index and the weight factor assigned to the LPU participating in the bargaining process, the utility of each LPU is computed. Analytical results show that the utility increases with the increase in the criticality index of any patient. Considering the total number of WBANs 5, 10, and 15, the average utility varies 75%-80%. Moreover, the data dissemination delay and power consumption are reduced by 23.39% and 31.089% respectively in the presence of fog node.},
keywords={body area networks;game theory;health care;CARE;criticality-aware data transmission;CPS-based healthcare systems;physiological parameter value;data processing;Local Processing Unit;sensor data;fog aggregation node;data dissemination delay;cooperative game theory-based Nash bargaining approach;Biomedical monitoring;Cloud computing;Body area networks;Wireless communication;Edge computing;Physiology;Games},
doi={10.1109/ICCW.2018.8403540},
ISSN={2474-9133},
month={May},}
@INPROCEEDINGS{8682766,
author={C. {Chou} and A. A. {Wu}},
booktitle={ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, title={Low-Complexity Compressive Analysis in Sub-Eigenspace for ECG Telemonitoring System},
year={2019},
volume={},
number={},
pages={7575-7579},
abstract={Compressive sensing (CS) is attractive in long-term electrocardiography (ECG) telemonitoring to extend life-time for resource-limited wireless wearable sensors. Moreover, health monitoring has emphasized the need for edge computing to process real-time data without the bandwidth costs. However, the reconstructed analysis (RA) and the compressed learning (CL) frameworks have extremely high memory and computational overhead, cost-prohibitive for online usage at resource-constrained edge device. In this paper, to efficiently analyze the received CS measurements with different levels of compression, we propose a low-complexity framework of Compressive Analysis in Sub-Eigenspace (CA-SE) based on subspace-based representation. The dictionary is used for sifting the sub-eigen information from the CS measurements online, and it is built by eigenspace learning offline. The framework can reduce the memory overhead with a single light-weight machine learning model and multiple small filter matrices, and the computational complexity with sifting by matrix-vector product rather than sparse coding. CA-SE is implemented in ECG-based atrial fibrillation detection. The memory overhead of CA-SE is 13 and 39 times fewer compared with RA and CL, respectively, and the computational complexity of CA-SE is 42 and 10 times fewer compared with RA and CL, respectively.},
keywords={compressed sensing;electrocardiography;learning (artificial intelligence);medical signal detection;patient monitoring;telemedicine;health monitoring;edge computing;bandwidth costs;reconstructed analysis;RA;compressed learning frameworks;CL;resource-constrained edge device;low-complexity framework;subspace-based representation;computational complexity;CA-SE;ECG-based atrial fibrillation detection;ECG telemonitoring system;long-term electrocardiography telemonitoring;resource-limited wireless wearable sensors;CS measurements;machine learning model;compressive sensing;low-complexity compressive analysis;eigenspace learning;Dictionaries;Electrocardiography;Computational modeling;Sparse matrices;Eigenvalues and eigenfunctions;Biomedical measurement;Computational complexity;Compressive sensing;edge computing;compressive analytics;sub-eigenspace;subspace-based representation},
doi={10.1109/ICASSP.2019.8682766},
ISSN={2379-190X},
month={May},}
@INPROCEEDINGS{9026409,
author={M. A. {Uddin} and A. {Stranieri} and I. {Gondal} and V. {Balasubramanian}},
booktitle={2019 25th Asia-Pacific Conference on Communications (APCC)}, title={Blockchain Leveraged Task Migration in Body Area Sensor Networks},
year={2019},
volume={},
number={},
pages={177-184},
abstract={Blockchain technologies emerging for healthcare support secure health data sharing with greater interoperability among different heterogeneous systems. However, the collection and storage of data generated from Body Area Sensor Net-works(BASN) for migration to high processing power computing services requires an efficient BASN architecture. We present a decentralized BASN architecture that involves devices at three levels; 1) Body Area Sensor Network-medical sensors typically on or in patient's body transmitting data to a Smartphone, 2) Fog/Edge, and 3) Cloud. We propose that a Patient Agent(PA) replicated on the Smartphone, Fog and Cloud servers processes medical data and execute a task offloading algorithm by leveraging a Blockchain. Performance analysis is conducted to demonstrate the feasibility of the proposed Blockchain leveraged, distributed Patient Agent controlled BASN.},
keywords={biomedical communication;body area networks;cloud computing;cryptography;distributed databases;health care;medical information systems;open systems;smart phones;wireless sensor networks;edge computing;cloud computing;fog computing;task migration;distributed Patient Agent;task offloading algorithm;medical data;Smartphone;decentralized BASN architecture;high processing power computing services;interoperability;health data sharing;healthcare support;Blockchain technologies;body area sensor networks;Task analysis;Cloud computing;Servers;Medical services;Computer architecture;Privacy;Internet of Things;Task Offload;Blockchain;Patient Agent;Fog/Edge;Cloud;Body Area Sensor Network;Assignment Algorithm},
doi={10.1109/APCC47188.2019.9026409},
ISSN={2163-0771},
month={Nov},}
@ARTICLE{8392685,
author={D. C. {Yacchirema} and D. {Sarabia-JáCome} and C. E. {Palau} and M. {Esteve}},
journal={IEEE Access}, title={A Smart System for Sleep Monitoring by Integrating IoT With Big Data Analytics},
year={2018},
volume={6},
number={},
pages={35988-36001},
abstract={Obtrusive sleep apnea (OSA) is one of the most important sleep disorders because it has a direct adverse impact on the quality of life. Intellectual deterioration, decreased psychomotor performance, behavior, and personality disorders are some of the consequences of OSA. Therefore, a real-time monitoring of this disorder is a critical need in healthcare solutions. There are several systems for OSA detection. Nevertheless, despite their promising results, these systems not guiding their treatment. For these reasons, this research presents an innovative system for both to detect and support of treatment of OSA of elderly people by monitoring multiple factors such as sleep environment, sleep status, physical activities, and physiological parameters as well as the use of open data available in smart cities. Our system architecture performs two types of processing. On the one hand, a pre-processing based on rules that enables the sending of real-time notifications to responsible for the care of elderly, in the event of an emergency situation. This pre-processing is essentially based on a fog computing approach implemented in a smart device operating at the edge of the network that additionally offers advanced interoperability services: technical, syntactic, and semantic. On the other hand, a batch data processing that enables a descriptive analysis that statistically details the behavior of the data and a predictive analysis for the development of services, such as predicting the least polluted place to perform outdoor activities. This processing uses big data tools on cloud computing. The performed experiments show a 93.3% of effectivity in the air quality index prediction to guide the OSA treatment. The system's performance has been evaluated in terms of latency. The achieved results clearly demonstrate that the pre-processing of data at the edge of the network improves the efficiency of the system.},
keywords={Big Data;cloud computing;geriatrics;health care;Internet of Things;open systems;patient monitoring;sleep;real-time monitoring;healthcare solutions;OSA detection;innovative system;elderly people;sleep environment;physical activities;physiological parameters;open data;smart cities;real-time notifications;fog computing approach;smart device operating;batch data processing;predictive analysis;outdoor activities;performed experiments;air quality index prediction;OSA treatment;smart system;sleep monitoring;integrating IoT;obtrusive sleep apnea;important sleep disorders;direct adverse impact;intellectual deterioration;personality disorders;Big Data tools;psychomotor performance;Sleep apnea;Monitoring;Biomedical monitoring;Real-time systems;Computer architecture;Big Data;Sensors;Internet-of-Things;big data;interoperability;sleep monitoring;health monitoring;open data;fog computing;cloud computing},
doi={10.1109/ACCESS.2018.2849822},
ISSN={2169-3536},
month={},}
@ARTICLE{8908803,
author={S. {Dai} and M. {Li Wang} and Z. {Gao} and L. {Huang} and X. {Du} and M. {Guizani}},
journal={IEEE Transactions on Vehicular Technology}, title={An Adaptive Computation Offloading Mechanism for Mobile Health Applications},
year={2020},
volume={69},
number={1},
pages={998-1007},
abstract={Recently, research intergrading medicine and Artificial Intelligence has attracted extensive attention. Mobile health has emerged as a promising paradigm for improving people's work and life in the future. However, high mobility of mobile devices and limited resources pose challenges for users to deal with the applications in mobile health that require large amount of computational resources. In this paper, a novel computation offloading mechanism is proposed in the environments combining of the Internet of Vehicles and Multi-Access Edge Computing. Through the proposed mechanism, mobile health applications are divided into several parts and can be offloaded to appropriate nearby vehicles while meeting the requirements of application completion time, energy consumption, and resource utilization. A particle swarm optimization based approach is proposed to optimize the the aforementioned computation offloading problem in a specific medical application. Evaluations of the proposed algorithms against local computing method serves as baseline method are conducted via extensive simulations. The average task completion time saved by our proposed task allocation scheme increases continually compared with the local solution. Specially, the global resource utilization rate increased from 71.8% to 94.5% compared with the local execution time.},
keywords={artificial intelligence;medicine;mobile computing;particle swarm optimisation;resource allocation;telemedicine;vehicular ad hoc networks;adaptive computation offloading mechanism;mobile health applications;mobile devices;computational resources;multiaccess edge computing;particle swarm optimization based approach;computation offloading problem;medicine;task allocation;application task completion time;energy consumption;Internet of Vehicles;artificial intelligence;mobile health applications;global resource utilization rate;local computing method;medical application;Medical services;Cloud computing;Medical diagnostic imaging;Delays;Artificial intelligence;Mobile handsets;Computational modeling;Computation offloading;disaster medicine;internet of vehicles;mobile health;multi-access edge computing},
doi={10.1109/TVT.2019.2954887},
ISSN={1939-9359},
month={Jan},}
@ARTICLE{8675166,
author={L. P. {Qian} and Y. {Wu} and B. {Ji} and L. {Huang} and D. H. K. {Tsang}},
journal={IEEE Network}, title={HybridIoT: Integration of Hierarchical Multiple Access and Computation Offloading for IoT-Based Smart Cities},
year={2019},
volume={33},
number={2},
pages={6-13},
abstract={The Internet of Things (IoT) is an emerging technology that proffers to connect massive smart devices together and to the Internet. On the basis of IoT, a smart city is endowed with real-time monitoring, ubiquitous sensing, universal connectivity, and intelligent information processing and control. An IoT-based smart city can offer various smart services to citizens and administrators, thus improving the utilization of public resources regarding transportation, healthcare, environment, entertainment, and energy. The integration of transmitting, computing, and caching is having a profound impact on the development of flexible and efficient IoT in smart cities. However, with the introduction of ultra dense networking (UDN) and mobile edge computing (MEC), we have to carefully consider a joint problem across the physical layer and MAC layer to enable the efficient transmission, computation, and caching of big IoT data generated by massive IoT devices distributed in a city. In doing so, efficient multiple access and computation offloading should be addressed in the physical layer and MAC layer, respectively. In this article, we propose a scalable and sustainable IoT framework that integrates UDN-based hierarchical multiple access and computation offloading between MEC and cloud to support the smart city vision. The proposed integrated framework can substantially reduce the end-to-end delay and energy consumption of computing data from massive IoT devices. Numerical comparison results are presented to show the efficiency of the proposed framework. In addition, we discuss a number of open research issues in implementing the proposed framework.},
keywords={cloud computing;data analysis;Internet of Things;mobile computing;smart cities;town and country planning;computation offloading;IoT-based smart city;massive smart devices;mobile edge computing;physical layer;MAC layer;big IoT data;massive IoT devices;UDN-based hierarchical multiple access;smart city vision;computing data;IoT framework;ultra dense networking;Internet of Things;Cloud computing;Smart cities;Computer architecture;Microprocessors;Edge computing},
doi={10.1109/MNET.2019.1800149},
ISSN={1558-156X},
month={March},}
@ARTICLE{9165267,
author={M. S. {Hossain} and G. {Muhammad}},
journal={IEEE Network}, title={Deep Learning Based Pathology Detection for Smart Connected Healthcares},
year={2020},
volume={34},
number={6},
pages={120-125},
abstract={New generation communication technologies and advanced deep learning models present a tremendous opportunity to develop fast, accurate, and seamless distributed systems in different sectors including the healthcare sector. in this article, we suggest a smart healthcare framework consisting of a pathology detection system, which is developed using deep learning. The pathology can be detected from electroencephalogram signals of a subject. in the framework, a smart EEG headset captures EEG signals and sends them to a mobile edge computing server. The server preprocesses the signals and transmits them to a cloud server. The cloud server does the main processing using deep learning and decides on whether the subject has pathology or not. Clients and stakeholders of the framework are connected via an authentication manager located in the cloud server. Experiment results on a publicly available database confirm the appropriateness of the proposed framework.},
keywords={electroencephalography;health care;learning (artificial intelligence);medical signal processing;cloud server;mobile edge computing server;EEG signals;smart EEG headset;electroencephalogram signals;pathology detection system;smart healthcare framework;healthcare sector;seamless distributed systems;deep learning models;Brain modeling;Cloud computing;Medical services;Electroencephalography;Servers;Pathology;Machine learning},
doi={10.1109/MNET.011.2000064},
ISSN={1558-156X},
month={November},}
@INPROCEEDINGS{9124813,
author={X. {Gao} and L. {Ma} and J. {Jin} and J. {Li} and Z. {Ma} and Y. {Zhai} and X. {Li}},
booktitle={2020 IEEE Wireless Communications and Networking Conference Workshops (WCNCW)}, title={Glioma Segmentation Strategies in 5G Teleradiology},
year={2020},
volume={},
number={},
pages={1-6},
abstract={As an essential part of the telemedicine system, teleradiology not only realizes mutual recognition of image diagnosis among medical institutions, but also ensures the quality of medical image diagnosis. In this paper, an edge computing (EC) driven 5G teleradiology framework is proposed to segment glioma accurately. In our framework, through the high-speed transmission and sharing mechanism of medical image data under 5G condition, the high-definition magnetic resonance imaging (MRI) images data of glioma patients are delivered to the edge server for data augmentation and training. Three typical data augmentation methods, i.e., traditional geometric transformation, DCGAN, and CycleGAN, are used to study the impact of the proportions of synthetic images generated by the above data augmentation methods to original MRI images on the performance of glioma segmentation. It is observed that training with different proportions leads to different segmentation results. Based on this observation, an efficient data augmentation strategy is established, which exploits the optimal proportions of synthetic and original data to yield the best glioma segmentation results in terms of sensitivity, specificity, accuracy, and Dice score. Experiments on the BraTS dataset show that the proposed data augmentation strategy improves the average Dice score of Dense U-net compared to the conventional data augmentation method. With the aid of our EC driven 5G teleradiology framework, accurate glioma segmentation results can be acquired rapidly at the terminal equipment to facilitate the online diagnosis.},
keywords={biomedical MRI;image segmentation;medical image processing;neural nets;telemedicine;tumours;magnetic resonance imaging images;glioma patients;edge server;MRI images;data augmentation;glioma segmentation;edge computing;5G teleradiology;DCGAN;CycleGAN;Dice score;BraTS dataset;U-net;high-speed transmission;medical image diagnosis;telemedicine system;5G teleradiology;EC;Glioma Segmentation;BraTS;GAN;Dense U-net},
doi={10.1109/WCNCW48565.2020.9124813},
ISSN={},
month={April},}
@INPROCEEDINGS{8795338,
author={N. {Takiddeen} and I. {Zualkernan}},
booktitle={2019 Fourth International Conference on Fog and Mobile Edge Computing (FMEC)}, title={Smartwatches as IoT Edge Devices: A Framework and Survey},
year={2019},
volume={},
number={},
pages={216-222},
abstract={Smartwatches have finally come of age and represent a unique platform for building IoT applications involving people. Today, smartwatches are used in various IoT scenarios including healthcare and fitness. Since the current smartwatches are equipped with a variety of sensors and heterogenous wireless protocols, they can be used to enact a variety of people-based Social Internet of Things (SIoT). Such applications involve sending sensor data from millions of watches through the IoT cloud. Processors on current watches are powerful enough to run even deep learning algorithms and may support peak download data rates of more than 50 Mbits/second. However, battery life remains a limiting factor. Most smartwatch applications capture and process context. This paper provides a survey and framework based on context computation, edge analytics, and computation off-loading as applied to IoT applications using smartwatches. This framework can be a basis of meaningful discussion of various solutions to address various technical problems like short battery life of smartwatches when used in IoT applications.},
keywords={Internet of Things;learning (artificial intelligence);protocols;wearable computers;sensor data;IoT cloud;peak download data rates;IoT edge devices;heterogenous wireless protocols;smartwatch applications;people-based social Internet of Things;SIoT;deep learning algorithms;context computation;edge analytics;computation off-loading;SIoT;Smartwatch;IoT;Computation Offloading},
doi={10.1109/FMEC.2019.8795338},
ISSN={},
month={June},}
@ARTICLE{8306827,
author={Q. {Zhang} and Q. {Zhang} and W. {Shi} and H. {Zhong}},
journal={IEEE Transactions on Parallel and Distributed Systems}, title={Firework: Data Processing and Sharing for Hybrid Cloud-Edge Analytics},
year={2018},
volume={29},
number={9},
pages={2004-2017},
abstract={Now we are entering the era of the Internet of Everything (IoE) and billions of sensors and actuators are connected to the network. As one of the most sophisticated IoE applications, real-time video analytics is promising to significantly improve public safety, business intelligence, and healthcare & life science, among others. However, cloud-centric video analytics requires that all video data must be preloaded to a centralized cluster or the cloud, which suffers from high response latency and high cost of data transmission, given the scale of zettabytes of video data generated by IoE devices. Moreover, video data is rarely shared among multiple stakeholders due to various concerns, which restricts the practical deployment of video analytics that takes advantages of many data sources to make smart decisions. Furthermore, there is no efficient programming interface for developers and users to easily program and deploy IoE applications across geographically distributed computation resources. In this paper, we present a new computing framework, Firework, which facilitates distributed data processing and sharing for IoE applications via a virtual shared data view and service composition. We designed an easy-to-use programming interface for Firework to allow developers to program on Firework. This paper describes the system design, implementation, and programming interface of Firework. The experimental results of a video analytics application demonstrate that Firework reduces up to 19.52 percent of response latency and at least 72.77 percent of network bandwidth cost, compared to a cloud-centric solution.},
keywords={cloud computing;data privacy;data visualisation;Internet of Things;video signal processing;Firework;virtual shared data view;service composition;video analytics application;cloud-centric solution;hybrid cloud-edge analytics;cloud-centric video analytics;video data;data transmission;IoE devices;data sources;distributed data processing;IoE applications;programming interface;internet of everything;sensors;actuators;public safety;business intelligence;healthcare;life science;centralized cluster;high response latency;zettabytes;multiple stakeholders;geographically distributed computation resources;computing framework;data sharing;system design;network bandwidth cost;Cloud computing;Streaming media;Stakeholders;Programming;Edge computing;Data processing;Distributed databases;Distributed big data processing;edge computing;internet of everything},
doi={10.1109/TPDS.2018.2812177},
ISSN={1558-2183},
month={Sep.},}
@INPROCEEDINGS{7444724,
author={M. {Aazam} and M. {St-Hilaire} and C. {Lung} and I. {Lambadaris}},
booktitle={2016 13th IEEE Annual Consumer Communications Networking Conference (CCNC)}, title={PRE-Fog: IoT trace based probabilistic resource estimation at Fog},
year={2016},
volume={},
number={},
pages={12-17},
abstract={Lately, pervasive and ubiquitous computing services have been under focus of not only the research community, but developers as well. Different devices generate different types of data with different frequencies. Emergency, healthcare, and latency sensitive services require real-time responses. Also, it is necessary to decide what type of data has to be uploaded to the cloud, without burdening the core network and the cloud. For this purpose, the cloud on the edge of the network, known as Fog or Micro Datacenter (MDC), plays an important role. Fog resides between the underlying Internet of Things (IoTs) and the mega datacenter cloud. Its purpose is to manage resources, perform data filtration, preprocessing, and security measures. To achieve this, Fog requires an effective and efficient resource management framework, which we propose in this paper. Fog has to deal with mobile nodes and IoTs, which involves objects and devices of different types having a fluctuating connectivity behavior. All such types of service customers have an unpredictable relinquish probability, since any object or device can stop using resources at any moment. In our proposed methodology for resource estimation and management through Fog computing, we take into account these factors and formulate resource management on the basis of fluctuating relinquish probability of the customer, service type, service price, and variance of the relinquish probability. With the intent of showing practical implications of our method, we implemented it on Crawdad real trace and Amazon EC2 pricing. Based on various services, differentiated through Amazon's price plans and historical record of Cloud Service Customers (CSCs), the model determines the amount of resources to be allocated. More loyal CSCs get better services, while for the contrary case, the provider reserves resources cautiously.},
keywords={cloud computing;probability;ubiquitous computing;pre-fog;IoT trace based probabilistic resource estimation;ubiquitous computing services;pervasive computing services;micro datacenter;Internet of Things;mega datacenter cloud;resource estimation;fog computing;resource management;relinquish probability;cloud service customers;CSC;Cloud computing;Resource management;Sensors;Estimation;Wireless sensor networks;Computational modeling;Conferences;IoT;Cloud of Things;Fog computing;Edge computing;Micro Datacenter (MDC);resource management},
doi={10.1109/CCNC.2016.7444724},
ISSN={2331-9860},
month={Jan},}
@ARTICLE{8390903,
author={H. {Sun} and Z. {Zhang} and R. Q. {Hu} and Y. {Qian}},
journal={IEEE Vehicular Technology Magazine}, title={Wearable Communications in 5G: Challenges and Enabling Technologies},
year={2018},
volume={13},
number={3},
pages={100-109},
abstract={As wearable devices become more ingrained in our daily lives, traditional communication networks primarily designed for human-being-oriented applications are facing tremendous challenges. The forthcoming fifth-generation (5G) wireless systems look to support unprecedented high capacity, low latency, and massive connectivity. In this article, we examine key challenges facing wearable communication devices. A cloud/edge communication architecture that integrates the cloud radio access network (CRAN), software-defined network (SDN), device-to-device (D2D) communications, and cloud/edge technologies is presented. Computation offloading enabled by this multilayer communications architecture can offload computation-excessive and latency-stringent applications to nearby devices through D2D communications or to nearby edge nodes through cellular or other wireless technologies. Critical issues faced by wearable communications, e.g., short battery life, limited computing capability, and stringent latency, can be greatly alleviated by this cloud/edge architecture. Together with the presented architecture, current transmission and networking technologies [including nonorthogonal multiple access (NOMA), mobile edge computing (MCE), and energy harvesting] can greatly enhance the performance of wearable communications in terms of spectral efficiency, energy efficiency, latency, and connectivity.},
keywords={5G mobile communication;cellular radio;cloud computing;mobile computing;radio access networks;software defined networking;nearby edge nodes;cellular technologies;computing capability;current transmission;networking technologies;wearable communications;wearable devices;traditional communication networks;human-being-oriented applications;fifth-generation wireless systems;wearable communication devices;software-defined network;device-to-device communications;computation offloading;multilayer communications architecture;latency-stringent applications;wireless technologies;energy harvesting;5G wireless systems;cloud-edge communication architecture;cloud radio access network;CRAN;D2D communications;time 2.0 d;Biomedical monitoring;Cloud computing;Wireless LAN;Bluetooth;Sensors;5G mobile communication;Computer architecture;Wearable computing},
doi={10.1109/MVT.2018.2810317},
ISSN={1556-6080},
month={Sep.},}
@INPROCEEDINGS{8210771,
author={R. {Straessle} and Y. {Temiz} and S. {Gerke} and J. {Weiss} and A. {Sridhar} and S. {Paredes} and T. {Brunschwiler} and E. {Loertscher} and N. {Ebejer} and B. {Michel} and T. {van Kessel} and I. {Faro} and S. {Zafar} and F. {Libsch} and M. A. {Taubenblatt} and K. {Matsumoto}},
booktitle={2017 IEEE 19th International Conference on e-Health Networking, Applications and Services (Healthcom)}, title={Internet of the body and cognitive companion: Enabling high-quality monitoring of patients at home},
year={2017},
volume={},
number={},
pages={1-6},
abstract={Wearables that continuously acquire vital and other medically relevant parameters facilitate treatment optimizations for individual patients and reduce the duration of hospitalizations - thus improving the patients' quality of life. To accomplish this, we demonstrate a scalable architecture that connects wearables through a hub to the cloud, combines edge and cloud computing to provide optimal user interaction, and allows analytics on multi-stream data from those connected devices.},
keywords={cloud computing;human computer interaction;medical computing;patient monitoring;patient treatment;software architecture;cognitive companion;wearables;treatment optimizations;scalable architecture;optimal user interaction;Internet;high-quality patient monitoring;hospitalizations;edge computing;cloud computing;multistream data;Electrocardiography;Bluetooth;Cloud computing;Temperature sensors;Sensor phenomena and characterization;Medical services;Gateway;hub;connected sensors;wearables;ECG;Bluemix;machine learning;analytics;healthcare},
doi={10.1109/HealthCom.2017.8210771},
ISSN={},
month={Oct},}
@ARTICLE{9056486,
author={P. K. {Sharma} and J. {Park} and J. H. {Park} and K. {Cho}},
journal={IEEE Access}, title={Wearable Computing for Defence Automation: Opportunities and Challenges in 5G Network},
year={2020},
volume={8},
number={},
pages={65993-66002},
abstract={Recently, wearable technologies have evolved in the most unexpected field like a military force outside of healthcare, fitness, lifestyle and similar areas. The growing need for soldiers' coordination, training and health, the increase in asymmetric warfare, suspected geopolitical conflicts and soldiers' modernization programs, among others, are some of the factors that fuel the growth of the military wearables market. Wearable computation plays an important role in improving the capabilities of the soldier. Further, the 5G network promises a solution to the many network and performance challenges in order to adopt more sophisticated wearable technologies in defense automation. In this paper, we conduct a study to identify the role of wearable computing for the defence automation system. We present the taxonomy of wearable computing in defence automation system and explain the relationship of each attribute. In addition, we identify the raise issues and challenges in communication and cybersecurity when deploying the 5G network in defense automation. Furthermore, we propose the design of the wearable smartwatch architecture as a use case of healthcare transformation in defense automation in the 5G environment.},
keywords={5G mobile communication;military computing;security of data;wearable computers;wearable computing;5G network;soldiers;military wearables market;wearable computation;sophisticated wearable technologies;defence automation system;wearable smartwatch architecture;Wearable computers;Automation;5G mobile communication;Biomedical monitoring;Military computing;Taxonomy;Sensors;Wearable computing;5G network;security and privacy;edge computing},
doi={10.1109/ACCESS.2020.2985313},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8795360,
author={K. {Macheta} and K. M. {Malarski} and M. N. {Petersen} and S. {Ruepp}},
booktitle={2019 Fourth International Conference on Fog and Mobile Edge Computing (FMEC)}, title={Network Slicing for End-to-End Latency Provisioning in Internet of Things},
year={2019},
volume={},
number={},
pages={197-198},
abstract={The Internet of Things technology is vastly growing, and more and more applications are being linked to IoT. IoT is moving from a massive deployment and gadget-like applications to also include critical applications for industry, telemedicine or utilities. In this work, we present our plans for a simulation framework that can evaluate and provide end-to-end latency bound connectivity through network slicing.},
keywords={Internet of Things;synchronisation;telecommunication network planning;network slicing;IoT;end-to-end latency bound connectivity;end-to-end latency provisioning;Internet of Things;Internet of Things;network slicing;latency;NFV},
doi={10.1109/FMEC.2019.8795360},
ISSN={},
month={June},}
@INPROCEEDINGS{8210762,
author={M. V. {Ngo} and Q. D. {La} and D. {Leong} and T. Q. S. {Quek}},
booktitle={2017 IEEE 19th International Conference on e-Health Networking, Applications and Services (Healthcom)}, title={User behavior driven MAC scheduling for body sensor networks},
year={2017},
volume={},
number={},
pages={1-6},
abstract={We propose a new framework combining dynamic sampling rates for healthcare sensors driven by user behavior, and an adaptive MAC scheduling scheme applied to the time-slotted channel hopping (TSCH) protocol in IEEE 802.15.4, which provides high throughput and reliable communications. First, we introduce a system software architecture for machine-learning-assisted healthcare monitoring that detects the user's behavior using edge computing and adjusts the sampling rates of the healthcare sensors accordingly. Second, we propose an adaptive MAC scheduling scheme for TSCH based on a state machine model that reacts to the dynamic traffic generated by the healthcare sensors. In case of an urgent state, the MAC scheduler automatically allocates extra timeslots to the appropriate sensors so as to enable the reliable transfer of high-resolution sensor data for further analysis. Experimental results from our testbed, implemented in Contiki-OS on the OpenMote-CC2538 platform, show that the proposed adaptive scheduling scheme can respond quickly to changes in user behavior and ensure the reliable transfer of sensor data in emergency situations.},
keywords={access protocols;adaptive scheduling;body sensor networks;distributed processing;health care;learning (artificial intelligence);patient monitoring;telecommunication network reliability;telecommunication scheduling;wireless channels;wireless sensor networks;Zigbee;time-slotted channel hopping protocol;IEEE 802.15.4;machine-learning-assisted healthcare monitoring;edge computing;Contiki-OS;OpenMote-CC2538 platform;reliable communications;adaptive MAC scheduling scheme;healthcare sensors;body sensor networks;adaptive scheduling scheme;high-resolution sensor data;Sensors;Medical services;Monitoring;Adaptive scheduling;Logic gates;Adaptive systems;Uplink},
doi={10.1109/HealthCom.2017.8210762},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8537865,
author={A. {Buzachis} and G. M. {Bernava} and M. {Busa} and G. {Pioggia} and M. {Villari}},
booktitle={2018 IEEE 4th International Conference on Collaboration and Internet Computing (CIC)}, title={Towards the Basic Principles of Osmotic Computing: A Closed-Loop Gamified Cognitive Rehabilitation Flow Model},
year={2018},
volume={},
number={},
pages={446-452},
abstract={The Internet of Medical Things (IoMT) is a sweeping revolution in the healthcare industry, with IoT quickly establishing itself as a critical part of modern healthcare. The rapid proliferation of such IoMT devices can bring limitations to the current Cloud-IoT centric infrastructures which are not designed to handle huge volumes and velocity of data generated. To address this problem, it is necessary to revisit the network architecture, pushing some data, processing and services directly on the edge nodes of the network where the data originates, away from the centralized Cloud. In this context, Osmotic Computing (OC) aims to provide a new paradigm for the integration between a centralized Cloud layer and Edge/IoT layers. The deployment and migration strategies through the Cloud and Edge layers depend on the infrastructures and applications requirements. This scientific work promotes the basic principles behind the OC paradigm and proposes a closed-loop OC flow model applied to a gamified cognitive rehabilitation use case. Moreover, the use case introduces the development of a customized virtual reality system based on a serious game which allows the patient to carry out physical and cognitive rehabilitation therapies using a natural user interface based on Microsoft Kinect. eas.},
keywords={cloud computing;health care;Internet of Things;patient rehabilitation;patient treatment;user interfaces;virtual reality;Osmotic Computing;centralized Cloud layer;Edge/IoT layers;migration strategies;closed-loop OC flow model;physical rehabilitation;closed-loop gamified cognitive rehabilitation flow model;sweeping revolution;healthcare industry;IoMT devices;Internet of Medical Things;Cloud-IoT centric infrastructures;natural user interface;virtual reality system;Medical services;Cloud computing;Internet of Things;Games;Computational modeling;Solid modeling;osmotic-computing;cloud-computing;edge-computing;healthcare;IoMT;serious-games;gamification},
doi={10.1109/CIC.2018.00067},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9300103,
author={M. {Zaiter} and S. {Hacini}},
booktitle={2020 21st International Arab Conference on Information Technology (ACIT)}, title={A Distributed Fault Tolerance Mechanism for an IoT Healthcare system},
year={2020},
volume={},
number={},
pages={1-6},
abstract={IoT environment is one of important upshots of IT development; it offers comfort to human daily life. We are interested in our paper in the healthcare IoT field which aims to remotely monitor the patient's health state using a set of physiological IoT sensors. In IoT systems dependability is a strong constraint because the fault occurrence can have a bad consequence on human life. The fault tolerance is one of the mechanisms that can insure a dependable function of the IoT healthcare system. To do this, we improve in this paper the centralized agent based architecture [1] by proposing more robust distributed one. That is by eliminating the weakness due to the centralization of the control. This upgrading is motivated by the fact that the current improvement of the network technologies and the occurrence of new promising paradigms like edge computing and 5G [2] require different reasoning philosophy.},
keywords={Sensors;Fault tolerant systems;Fault tolerance;Computer architecture;Biomedical monitoring;Monitoring;Task analysis;IoT;Medical System;Dependability;Fault Tolerance;Agent},
doi={10.1109/ACIT50332.2020.9300103},
ISSN={},
month={Nov},}
@ARTICLE{8283593,
author={S. {Rani} and S. H. {Ahmed} and S. C. {Shah}},
journal={IEEE Internet of Things Journal}, title={Smart Health: A Novel Paradigm to Control the Chickungunya Virus},
year={2019},
volume={6},
number={2},
pages={1306-1311},
abstract={Chikungunya is a mosquito instinctive disease that spreads hurriedly in various parts of the country. For the awareness and prevention measure of this disease a new paradigm in Smart Health (S-Health) required to be devised. The auspicious prospective of evolving Internet of Things (IoT) technologies for interconnected heterogeneous devices and objects has played a vital role in the next generation health care systems for eminent patient care to protect the citizens from these types of diseases. Still there is a need for real time health monitoring to analyze the patients for early preventive measures and precautions for healthy life. S-Health care IoT has substantial impending for the cognizance of analogues monitoring. It includes the interconnected apps, objects (devices and people), communication technologies, tracking system, and patients' knowledge base. This paper presents an IoT-enabled model where data collected from the sensors, objects, and people will be gathered at the cloud to take the preventive actions by healthcare professionals. Precautionary measures will be taken by collecting the information about causes of growth of mosquitoes. The suitability of the approach is validated at the base layer of the IoT and data is transmitted to the cloud with the help of edge nodes. From simulations, it is endorsed that the proposed approach is better over ME-CBCCP protocol.},
keywords={diseases;health care;Internet of Things;medical administrative data processing;medical computing;microorganisms;patient care;Smart Health;chickungunya virus;mosquito instinctive disease;prevention measure;interconnected heterogeneous devices;generation health care systems;time health monitoring;early preventive measures;S-Health care IoT;analogues monitoring;interconnected apps;communication technologies;patients;IoT-enabled model;preventive actions;precautionary measures;Internet of Things technologies;Medical services;Cloud computing;Smart cities;Sensors;Monitoring;Edge computing;Big Data;Chickungunya;edge computing;Internet of Things (IoT);IoT framework;Smart Health (S-Health)},
doi={10.1109/JIOT.2018.2802898},
ISSN={2327-4662},
month={April},}
@ARTICLE{8334922,
author={Y. {Hao} and D. {Tian} and G. {Fortino} and J. {Zhang} and I. {Humar}},
journal={IEEE Communications Standards Magazine}, title={Network Slicing Technology in a 5G Wearable Network},
year={2018},
volume={2},
number={1},
pages={66-71},
abstract={With the popularization of wearable devices, designing a network architecture that can meet the latency requirements of different wearable devices and can also efficiently utilize network communication, storage, and computation resources will be a challenging problem. In this article, we first propose a new 5G wearable network based on 5G ultra-dense cellular network and mobile edge computing, to meet the access and latency requirements of wearable devices. Then we use network slicing technology in the proposed 5G wearable network to enhance the network resource sharing and energy-efficient utilization. In addition, based on the service cognitive engine and network cognitive engine deployed in the network, we introduce data-driven network slicing management to adjust the network resources in accordance with the wearable service dynamics. Finally, some challenges and open issues are discussed.},
keywords={5G mobile communication;cellular radio;cognitive radio;mobile computing;resource allocation;telecommunication network management;network slicing technology;5G wearable network;network architecture;latency requirements;network communication;5G ultra-dense cellular network;network resource sharing;energy-efficient utilization;network slicing management;wearable service dynamics;wearable devices;computation resources;mobile edge computing;service cognitive engine;network cognitive engine;data-driven network slicing management;5G mobile communication;Network slicing;Wearable computers;Cloud computing;Cellular networks;Resource management},
doi={10.1109/MCOMSTD.2018.1700083},
ISSN={2471-2833},
month={MARCH},}
@ARTICLE{8552413,
author={Y. {Hao} and Y. {Jiang} and M. S. {Hossain} and A. {Ghoneim} and J. {Yang} and I. {Humar}},
journal={IEEE Sensors Journal}, title={Data-Driven Resource Management in a 5G Wearable Network Using Network Slicing Technology},
year={2019},
volume={19},
number={19},
pages={8379-8386},
abstract={The rapid development of the wearable technology brings an explosive growth of wearable devices and imposes a new challenge to the current network. This is because the wearable devices require real-time interaction and data processing. To cope with this challenge and to realize reasonable utilization of resources, this paper first introduces the network slice-based 5G wearable networks, including the 5G ultra-dense cellular network, the edge caching, and the edge computing. Then, in order to realize the service aware and efficient management of network slicing resources, we propose a data-driven resource management framework which includes the service cognitive engine, the resources cognitive engine, and the global cognitive engine. Furthermore, through information perception, analytical prediction, policy decisions, and performance evaluation, the data-driven resources management method is realized. Finally, we set up a real testbed and conduct a related experiment. The experimental results show that the data-driven resources management scheme can realize the service-aware resources allocation and improve the utilization ratio of resources.},
keywords={5G mobile communication;cache storage;cellular radio;cognitive systems;mobile computing;real-time systems;resource allocation;wearable devices;real-time interaction;data processing;network slice-based 5G wearable networks;5G ultra-dense cellular network;data-driven resource management framework;service cognitive engine;resources cognitive engine;global cognitive engine;resource utilization;edge caching;edge computing;network slicing resource management;information perception;analytical prediction;policy decisions;performance evaluation;service-aware resource allocation;5G mobile communication;Wearable computers;Biomedical monitoring;Resource management;Network slicing;Sensors;Engines;Network slicing;5G wearable networks;data-driven intelligence;cognitive computing},
doi={10.1109/JSEN.2018.2883976},
ISSN={1558-1748},
month={Oct},}
@INPROCEEDINGS{8543429,
author={B. D. {Cruz}},
booktitle={2018 IEEE/ACM 5th International Conference on Mobile Software Engineering and Systems (MOBILESoft)}, title={Programming Support for Data Intensive Distributed Mobile Applications at the Edge},
year={2018},
volume={},
number={},
pages={37-38},
abstract={Mobile, IoT, and wearable devices have been transitioning from passive consumers of remote data to active generators of massive amounts of data. Mobile apps often need to move data, generated on one device, to other nearby devices for processing. For example, when reading its wearer's health vitals, a health monitoring app on a wearable device needs to transfer the data to the wearer's smartphone for display and analysis. This local processing of data by means of nearby computing resources has been promoted as a solution to network bandwidth bottlenecks, and commonly referred to as edge computing. Despite the critical dependence of edge computing on the device-to-device data sharing functionality, its mainstream implementations introduce low-level and hard-to-maintain code into the mobile codebase. To address this problem, this research introduces Remote ICC (RICCi), a novel middleware framework that provides programming support for data-intensive mobile applications at the edge, thereby reconciling programming convenience and performance efficiency. RICCi builds upon the native Android Inter-Component Communication (ICC) to simultaneously support seamless and efficient inter-device data sharing via a convenient and familiar programming model. To reach these design objectives, RICCi innovates in the middleware space by offering distributed programming abstractions that are data-oriented rather than procedure-oriented, thereby elevating latency into a first-class design concern for developing distributed mobile apps.},
keywords={Android (operating system);distributed programming;Internet of Things;middleware;mobile computing;smart phones;programming support;efficient inter-device data sharing;distributed mobile apps;middleware framework;device-to-device data sharing functionality;wearer smartphone;IoT;native Android inter-component communication;programming model;local data processing;programming abstractions;efficient inter-device data;seamless inter-device data;performance efficiency;programming convenience;RICCi;Remote ICC;mobile codebase;hard-to-maintain code;edge computing;network bandwidth bottlenecks;health monitoring app;active generators;remote data;passive consumers;wearable device;data intensive distributed mobile applications;Programming;Distributed databases;Middleware;Measurement;Security;Mobile applications;Programming Model;Data Sharing;Distributed Computing;Android;Inter Component Communication},
doi={},
ISSN={},
month={May},}
@INPROCEEDINGS{9197786,
author={R. {Beri} and M. K. {Dubey} and A. {Gehlot} and R. {Singh}},
booktitle={2020 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)}, title={Health Assessment Model to Identify and Control Risk Associated with Preeclampsia using IoT},
year={2020},
volume={},
number={},
pages={421-425},
abstract={Preeclampsia refers to a condition that occurs due to a sudden increase in Blood Pressure during 20 weeks of pregnancy. Preeclampsia may lead to the damage of some other organs of the body liver or kidneys or leads to the occurrence of brain stroke or seizures. It occurs in 15 to 20 women in 100 and becomes a significant reason for maternal mortality or infant loss. It is necessary to prevent the risks related to preeclampsia by monitoring the health parameters of the patient in a real-time environment. The risk assessment model, when amalgamating with IoT and other related technologies, offers intelligent solutions to monitor health parameters in a real-time environment. The present study is focusing on proposing an IoT based health assessment framework to capture the blood pressure and other health-related parameters of pregnant women continuously. The captured data is then processed and analyzed by fog nodes. These fog nodes then provide real-time suggestions to the patient for improving health conditions. Moreover, the fog nodes also send the processed data to cloud servers for further analysis by healthcare providers.},
keywords={blood;health care;Internet of Things;liver;medical computing;obstetrics;patient monitoring;risk management;brain stroke;maternal mortality;health parameters;real-time environment;risk assessment model;IoT based health assessment framework;health-related parameters;fog nodes;health conditions;health assessment model;body liver;Pregnancy;Real-time systems;Blood pressure;Biomedical monitoring;Temperature sensors;Fog Computing;Preeclampsia;Internet of Things (IoT);Smart E-healthcare system;Smart Pregnancy},
doi={10.1109/ICRITO48877.2020.9197786},
ISSN={},
month={June},}
@INPROCEEDINGS{9311036,
author={G. {Mathew} and S. {Sindhu Ramachandran} and S. {V.S.}},
booktitle={2020 IEEE / ITU International Conference on Artificial Intelligence for Good (AI4G)}, title={EdgeAI: Diabetic Retinopathy Detection in Intel Architecture},
year={2020},
volume={},
number={},
pages={75-80},
abstract={Diabetic retinopathy is a leading cause of blindness among working-age adults. Millions of people suffer from Diabetic Retinopathy in India. More dreaded situation is faced by the population in rural India where access to quality healthcare is limited. AI comes to the rescue in those situations where initial diagnosis can be performed without much manual intervention. Early detection of this condition is critical for good prognosis. In this paper we propose a solution using UP2 board (Edge device based on x86 architecture) where AI diagnosis can be performed on the local premise itself. We used PyTorch framework for training the model using EfficientNet-B4 network architecture. Trained model was optimized using Intel Distribution of Open-VINO, and hence there is no much compromise in execution time. Inference time for execution of single image in UP2 board is 0.2 sec. Our model achieved test metric performance comparable to baseline literature results, with sensitivity of 91.5% and specificity of 97.86%. For proof of concept we used open dataset from Kaggle 2019 competition hosted by Aravind Hospital, India.},
keywords={Retinopathy;Diabetes;Artificial intelligence;Training;Retina;Deep learning;Performance evaluation;Diabetic Retinopathy;PyTorch;Intel Distribution of OpenVINO;Edge Computing;UP2 board},
doi={10.1109/AI4G50087.2020.9311036},
ISSN={},
month={Sep.},}
@ARTICLE{8839508,
author={H. {Jiang} and J. {Starkman} and Y. -J. {Lee} and H. {Chen} and X. {Qian} and M. -C. {Huang}},
journal={IEEE Transactions on Mobile Computing}, title={Distributed Deep Learning Optimized System over the Cloud and Smart Phone Devices},
year={2021},
volume={20},
number={1},
pages={147-161},
abstract={Deep learning has been becoming a promising focus in data mining research. With deep learning techniques, researchers can discover deep properties and features of events from quantitative mobile sensor data. However, many data sources are geographically separated and have strict privacy, security, and regulatory constraints. Upon releasing the privacy-sensitive data, these data sources generally no longer physically possess their data and cannot interfere with the way their personal data being used. Therefore, it is necessary to explore distributed data mining architecture which is able to conduct consensus learning based on needs. Accordingly, we propose a distributed deep learning optimized system which contains a cloud server and multiple smartphone devices with computation capabilities and each device is served as a personal mobile data hub for enabling mobile computing while preserving data privacy. The proposed system keeps the private data locally in smartphones, shares trained parameters, and builds a global consensus model. The feasibility and usability of the proposed system are evaluated by three experiments and related discussion. The experimental results show that the proposed distributed deep learning system can reconstruct the behavior of centralized training. We also measure the cumulative network traffic in different scenarios and show that the partial parameter sharing strategy does not only preserve the performance of the trained model but also can reduce network traffic. User data privacy is protected on two levels. First, local private training data do not need to be shared with other people and the user has full control of their personal training data all the time. Second, only a small fraction of trained gradients of the local model are selected for sharing, which further reduces the risk of information leaking.},
keywords={Deep learning;Data models;Data mining;Distributed databases;Computational modeling;Computer architecture;Mobile handsets;Distributed deep neural networks;mobile computing;edge computing;deep learning;wearable computers and body area networks;wearable healthcare},
doi={10.1109/TMC.2019.2941492},
ISSN={1558-0660},
month={Jan},}
@ARTICLE{8930831,
author={D. {Belli} and S. {Chessa} and B. {Kantarci} and L. {Foschini}},
journal={IEEE Communications Magazine}, title={Toward Fog-Based Mobile Crowdsensing Systems: State of the Art and Opportunities},
year={2019},
volume={57},
number={12},
pages={78-83},
abstract={MCS is an emerging paradigm that leverages the pervasiveness of mobile, wearable, and vehicle-mounted devices to collect data from urban environments for ubiquitous service provisioning. In order to manage MCS application data streams efficiently, a scalable computing infrastructure hosting heterogeneous and distributed resources is critical. FC, as a geo-distributed computing paradigm, is a key enabler for this requirement as it bridges cloud servers and smart mobile devices. Research on the integration of MCS with FC has recently started to be explored, recognizing the requirements of MCS and their coexistence with cyber-physical systems. In this article, we analyze the state of the art of FC solutions in MCS systems. After a brief overview of MCS, we emphasize the link between MCS and FC. We then investigate the existing fog-based MCS architectures in detail by focusing on their building blocks, as well as the challenges that remain unaddressed. Our detailed review on the subject results in a taxonomy of FC solutions in MCS systems. In particular, we highlight the node structures, the information exchanged, the resource and service management, and the type of solutions adopted concerning privacy and security. Moreover, we provide a thorough discussion on the open issues and challenges by reporting useful insights for researchers in MCS and FC.},
keywords={cloud computing;cyber-physical systems;file servers;mobile computing;wearable devices;MCS application data streams;distributed resources;smart mobile devices;cyber-physical systems;MCS systems;fog-based mobile crowdsensing systems;vehicle-mounted devices;geodistributed computing;fog-based MCS architectures;cloud servers;Edge computing;Crowdsourcing;Distributed databases;Mobile handsets;Cyber-physical systems;Computer architecture;Urban areas},
doi={10.1109/MCOM.001.1900003},
ISSN={1558-1896},
month={December},}
@INPROCEEDINGS{8538589,
author={M. F. F. {da Silva Lisboa Tigre} and G. L. {Santos} and T. {Lynn} and D. {Sadok} and J. {Kelner} and P. T. {Endo}},
booktitle={2018 IEEE Symposium on Computers and Communications (ISCC)}, title={Modeling the availability of an e-health system integrated with edge, fog and cloud infrastructures},
year={2018},
volume={},
number={},
pages={00416-00421},
abstract={The Internet of Things has the potential of transforming health systems through the collection and analysis of patient physiological data via wearable devices and sensor networks. Such systems can offer assisted living services in realtime and offer a range of multimedia-based health services. However, lack of service availability, particularly in the cases of emergencies, can lead to adverse outcomes and in the worst case, death. In this paper, we propose an e-health monitoring architecture based on sensors and cloud and fog infrastructure scenarios. Further, we propose stochastic models to analyze how failures impact on the e-health system availability. We analyze four different scenarios and from results, we identify that the sensors and fog devices are the components that have the most significant impact on the availability of the entire e-health system in the scenarios analyzed.},
keywords={assisted living;cloud computing;distributed processing;Internet of Things;medical information systems;multimedia computing;patient care;patient monitoring;physiological models;stochastic processes;wearable computers;e-health monitoring architecture;fog infrastructure scenarios;stochastic models;e-health system availability;fog devices;cloud infrastructures;Internet of Things;patient physiological data;wearable devices;sensor networks;multimedia-based health services;service availability;assisted living services;edge infrastructures;Cloud computing;Monitoring;Biomedical monitoring;Maintenance engineering;Computational modeling;Analytical models;Edge computing},
doi={10.1109/ISCC.2018.8538589},
ISSN={1530-1346},
month={June},}
@INPROCEEDINGS{9249167,
author={M. {Pourkiani} and M. {Abedi}},
booktitle={2020 11th International Conference on Network of the Future (NoF)}, title={FCSTD: Fog-Cloud Smart Task Distribution by Exploiting the Artificial Neural Networks},
year={2020},
volume={},
number={},
pages={38-42},
abstract={In order to reduce the response time and the Internet bandwidth utilization in combined Fog-Cloud scenarios, we propose Fog-Cloud Smart Task Distribution (FCSTD) method, which intelligently distributes the tasks between the fog and cloud servers with regard to the application requirements. This approach uses Artificial Neural Networks for predicting the response time and the size of the results and then distributes the tasks by considering the predicted amounts. To investigate the performance of FCSTD, we applied it to a real-world case study (which is a delay-sensitive online healthcare application that monitors the health status of people) and analyzed its performance for the distribution of different types of tasks. The achieved results show that FCSTD provides better performance for reducing the Internet bandwidth utilization and response time in comparison to the other proposed methods in the literature.},
keywords={cloud computing;health care;neural nets;FCSTD;Artificial Neural Networks;response time;Internet bandwidth utilization;combined Fog-Cloud scenarios;Fog-Cloud Smart Task Distribution method;cloud servers;delay-sensitive online healthcare application;health status monitoring;fog servers;Cloud computing;Bandwidth;Artificial neural networks;Network architecture;Time factors;Servers;Task analysis;Fog Computing;Cloud Computing;Response time;Bandwidth;Task Distribution},
doi={10.1109/NoF50125.2020.9249167},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9073062,
author={A. {Banerjee} and B. K. {Mohanta} and S. S. {Panda} and D. {Jena} and S. {Sobhanayak}},
booktitle={2020 International Conference on Artificial Intelligence and Signal Processing (AISP)}, title={A Secure IoT-Fog Enabled Smart Decision Making system using Machine Learning for Intensive Care unit},
year={2020},
volume={},
number={},
pages={1-6},
abstract={Internet of Things(IoT) is a connection of smart things and act quickly in any environment. Fog computing based framework has been used to be integrated with IoT to enable real-time processing at the network edge, aiming to improve the users experience and resilience of the services in case of emergency. With the advantage of distributed architecture and close to end-users, fog edge computing can provide faster response and greater quality of service for IoT applications. In this paper, we have proposed a framework that uses, fog computing along with IoT and machine learning to provide a better and smarter healthcare experience. The security of the framework is ensured by application of Blockchain technology.},
keywords={Medical services;Internet of Things;Biomedical monitoring;Monitoring;Public key;IoT;Decision;Data Analysis;ICU;Machine Learning;Security;Blockchain;Fog computing.},
doi={10.1109/AISP48273.2020.9073062},
ISSN={2640-5768},
month={Jan},}
@INPROCEEDINGS{9138937,
author={S. {Zhao} and H. {Zhang} and S. {Bhuyan} and C. S. {Mishra} and Z. {Ying} and M. T. {Kandemir} and A. {Sivasubramaniam} and C. R. {Das}},
booktitle={2020 ACM/IEEE 47th Annual International Symposium on Computer Architecture (ISCA)}, title={Déjà View: Spatio-Temporal Compute Reuse for‘ Energy-Efficient 360° VR Video Streaming},
year={2020},
volume={},
number={},
pages={241-253},
abstract={The emergence of virtual reality (VR) and augmented reality (AR) has revolutionized our lives by enabling a 360° artificial sensory stimulation across diverse domains, including, but not limited to, sports, media, healthcare, and gaming. Unlike the conventional planar video processing, where memory access is the main bottleneck, in 360° VR videos the compute is the primary bottleneck and contributes to more than 50% energy consumption in battery-operated VR headsets. Thus, improving the computational efficiency of the video processing pipeline in a VR is critical. While prior efforts have attempted to address this problem through acceleration using a GPU or FPGA, none of them has analyzed the 360° VR pipeline to examine if there is any scope to optimize the computation with known techniques such as memoization.Thus, in this paper, we analyze the VR computation pipeline and observe that there is significant scope to skip computations by leveraging the temporal and spatial locality in head orientation and eye correlations, respectively, resulting in computation reduction and energy efficiency. The proposed Déjà View design takes advantage of temporal reuse by memoizing head orientation and spatial reuse by establishing a relationship between left and right eye projection, and can be implemented either on a GPU or an FPGA. We propose both software modifications for existing compute pipeline and microarchitectural additions for further enhancement. We evaluate our design by implementing the software enhancements on an NVIDIA Jetson TX2 GPU board and our microarchitectural additions on a Xilinx Zynq-7000 FPGA model using five video workloads. Experimental results show that Déjà View can provide 34% computation reduction and 17% energy saving, compared to the state-of-the-art design.},
keywords={augmented reality;field programmable gate arrays;graphics processing units;video signal processing;video streaming;temporal reuse;head orientation;microarchitectural additions;NVIDIA Jetson TX2 GPU board;Xilinx Zynq-7000 FPGA model;video workloads;spatio-temporal compute reuse;VR video streaming;augmented reality;360° artificial sensory stimulation;conventional planar video processing;memory access;360° VR videos;primary bottleneck;energy consumption;battery-operated VR headsets;computational efficiency;video processing pipeline;VR computation pipeline;significant scope;temporal locality;spatial locality;energy efficiency;Virtual Reality;Edge Computing;IoT;360° Video Processing},
doi={10.1109/ISCA45697.2020.00030},
ISSN={},
month={May},}
@INPROCEEDINGS{9245189,
author={R. N. A. {Sosu} and C. N. {Babu} and S. A. {Frimpong} and J. {Essuman}},
booktitle={2020 43rd International Convention on Information, Communication and Electronic Technology (MIPRO)}, title={The Relevance Of Blockchain With Dew Computing: A Review},
year={2020},
volume={},
number={},
pages={1934-1940},
abstract={Blockchain after its discovery and application to bitcoin has become a vital platform for data validation and verification across diverse sectors such as healthcare, supply chain, governance, and many others. The era of cloud computing has facilitated the access of one's data on the go making it almost impossible to lose data as your work. However, the use of the cloud demands constant aces to the internet warranting the relevance of the dew computing paradigm with terms to give access to one's data locally without the use of the internet and then updating the document on the cloud based on the internet restoration. In this paper, we seek to conduct a review of the above areas of blockchain and dew computing drawing the need for the integration of both technologies.},
keywords={cloud computing;cryptography;distributed databases;blockchain;bitcoin;diverse sectors;healthcare;supply chain;cloud computing;constant aces;dew computing paradigm;Internet restoration;Cloud computing;Supply chains;Blockchain;Computer architecture;Medical services;Dew computing;Edge computing;blockchain;cloud computing;dew computing;public blockchain;private blockchain;proof of work;proof of stake;depreciated proof of stake},
doi={10.23919/MIPRO48935.2020.9245189},
ISSN={2623-8764},
month={Sep.},}
@ARTICLE{9151945,
author={J. {Fontaine} and M. {Ridolfi} and B. {Van Herbruggen} and A. {Shahid} and E. {De Poorter}},
journal={IEEE Access}, title={Edge Inference for UWB Ranging Error Correction Using Autoencoders},
year={2020},
volume={8},
number={},
pages={139143-139155},
abstract={Indoor localization knows many applications, such as industry 4.0, warehouses, healthcare, drones, etc., where high accuracy becomes more critical than ever. Recent advances in ultra-wideband localization systems allow high accuracies for multiple active users in line-of-sight environments, while they still introduce errors above 300 mm in non-line-of-sight environments due to multi-path effects. Current work tries to improve the localization accuracy of ultra-wideband through offline error correction approaches using popular machine learning techniques. However, these techniques are still limited to simple environments with few multi-path effects and focus on offline correction. With the upcoming demand for high accuracy and low latency indoor localization systems, there is a need to deploy (online) efficient error correction techniques with fast response times in dynamic and complex environments. To address this, we propose (i) a novel semi-supervised autoencoder-based machine learning approach for improving ranging accuracy of ultra-wideband localization beyond the limitations of current improvements while aiming for performance improvements and a small memory footprint and (ii) an edge inference architecture for online UWB ranging error correction. As such, this paper allows the design of accurate localization systems by using machine learning for low-cost edge devices. Compared to a deep neural network (as state-of-the-art, with a baseline error of 75 mm) the proposed autoencoder achieves a 29% higher accuracy. The proposed approach leverages robust and accurate ultra-wideband localization, which reduces the errors from 214 mm without correction to 58 mm with correction. Validation of edge inference using the proposed autoencoder on a NVIDIA Jetson Nano demonstrates significant uplink bandwidth savings and allows up to 20 rapidly ranging anchors per edge GPU.},
keywords={error correction;indoor radio;learning (artificial intelligence);neural nets;telecommunication computing;ultra wideband communication;ultra-wideband localization systems;multiple active users;line-of-sight environments;nonline-of-sight environments;multipath effects;localization accuracy;offline error correction;machine learning techniques;offline correction;low latency indoor localization systems;efficient error correction techniques;dynamic environments;complex environments;ranging accuracy;performance improvements;edge inference architecture;online UWB ranging error correction;accurate localization systems;low-cost edge devices;baseline error;accurate ultra-wideband localization;semisupervised autoencoder-based machine learning approach;Distance measurement;Error correction;Ultra wideband technology;Neural networks;Machine learning;Support vector machines;Computer architecture;Autoencoders;edge computing;machine learning;ultra-wideband localization},
doi={10.1109/ACCESS.2020.3012822},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9047710,
author={G. {Postolache} and P. S. {Girão} and O. A. {Postolache} and J. M. {Dias Pereira} and V. {Viegas}},
booktitle={2019 13th International Conference on Sensing Technology (ICST)}, title={IoT based model of healthcare for physiotherapy},
year={2019},
volume={},
number={},
pages={1-6},
abstract={Small and reliable devices that are used not only in clinics or hospital but also in home, give information on movements, activities or other relevant data on person health and functioning. The data acquired by these devices would increase the accessibility to healthcare services and quality of care, in a safe environment. There are scarce data related to integration of Internet of Things (IoT) technologies into information system for physiotherapy or motor rehabilitation. In this work it is presented a framework for IoT based information system for physiotherapy. The presented model for physiotherapy includes: the capacity of IoT based information system to receive inputs from different modalities; support for modularity and common communication technologies for IoT; gateway capabilities and/or edge computing; data storage and analysis in Server, Cloud Server or Microservices. Research is needed for better understanding what is the optimal model and architecture for IoT platforms targeting people with different types of disabilities, as well as an optimal universal design that may increase the quality of care for people with disability.},
keywords={health care;Internet of Things;internetworking;medical computing;patient rehabilitation;person health;Internet of Things technologies;physiotherapy;IoT based information system;communication technologies;data storage;IoT platforms;Medical services;Information systems;Logic gates;Biological system modeling;Sensors;Wireless sensor networks;Internet of Things;health model;Internet of Things;physiotherapy},
doi={10.1109/ICST46873.2019.9047710},
ISSN={2156-8073},
month={Dec},}
@INPROCEEDINGS{8561038,
author={S. C. {Shah}},
booktitle={2017 International Conference on Computational Science and Computational Intelligence (CSCI)}, title={Mobile Edge Cloud: Opportunities and Challenges},
year={2017},
volume={},
number={},
pages={1572-1577},
abstract={Mobile edge cloud is emerging as a promising technology to internet of things and cyber physical system applications such as smart home and intelligent video surveillance. In smart home, various sensors are deployed to monitor the home environment and physiological health of individuals. The data collected by sensors are sent to an application, where numerous algorithms for emotion and sentiment detection, activity recognition and situation management are applied to provide healthcare- and emergency-related services and to manage resources at the home. The executions of these algorithms require a vast amount of computing and storage resources. To address the issue, the conventional approach is to send the collected data to an application on an internet cloud. This approach has several problems such as high communication latency, communication energy consumption and unnecessary data traffic to the core network. To overcome the drawbacks of the conventional cloud-based approach, a new system called mobile edge cloud is proposed. In mobile edge cloud, multiple mobile and stationary devices interconnected through wireless local area networks are combined to create a small cloud infrastructure at a local physical area such as home. Compared to traditional mobile distributed computing systems, mobile edge cloud introduces several complex challenges due to the heterogeneous computing environment, heterogeneous and dynamic network environment, node mobility, and limited battery power. The real time requirements associated with internet of things and cyber physical system applications make the problem even more challenging. In this paper, we describe the applications and challenges associated with design and development of mobile edge cloud system and propose an architecture based on a cross layer design approach for effective decision making.},
keywords={cloud computing;decision making;Internet;mobile computing;video surveillance;mobile edge cloud system;cyber physical system applications;smart home;internet cloud;conventional cloud-based approach;traditional mobile distributed computing systems;heterogeneous computing environment;dynamic network environment;node mobility;internet of things;effective decision making;Mobile cloud;Mobile ad hoc cloud;Local cloud;Edge computing;Fog computing},
doi={10.1109/CSCI.2017.348},
ISSN={},
month={Dec},}
@ARTICLE{9201136,
author={V. {Nguyen} and T. T. {Khanh} and T. Z. {Oo} and N. H. {Tran} and E. -N. {Huh} and C. S. {Hong}},
journal={IEEE Communications Letters}, title={Latency Minimization in a Fuzzy-Based Mobile Edge Orchestrator for IoT Applications},
year={2021},
volume={25},
number={1},
pages={84-88},
abstract={Currently, matching the incoming Internet of Things applications to the current state of computing and networking resources of a mobile edge orchestrator (MEO) is critical for providing the high quality of service while temporally and spatially changing the incoming workload. However, MEO needs to scale its capacity concerning a large number of devices to avoid task failure and to reduce service time. To cope with this issue, we propose MEO with fuzzy-based logic that splits tasks from mobile devices and maps them onto the cloud and edge servers to reduce the latency of handling these tasks and task failures. A fuzzy-based MEO handles the multi-criteria decision-making process to decide where the offloaded task should run by considering multiple parameters in the same framework. Our approach selects the appropriate host for task execution and finds the optimal task-splitting strategy. Compared to the existing approaches, the service time using our proposal can achieve up to 7.6%, 22.6%, 38.9%, and 51.8% performance gains for augmented reality, healthcare, compute-intensive, and infotainment applications, respectively.},
keywords={Task analysis;Servers;Cloud computing;Mobile handsets;Edge computing;Wide area networks;Delays;Mobile edge orchestrator;edge computing;cloud computing;latency minimization;fuzzy-based approach},
doi={10.1109/LCOMM.2020.3024957},
ISSN={1558-2558},
month={Jan},}
@INPROCEEDINGS{7511465,
author={V. B. C. {Souza} and W. {Ramírez} and X. {Masip-Bruin} and E. {Marín-Tordera} and G. {Ren} and G. {Tashakor}},
booktitle={2016 IEEE International Conference on Communications (ICC)}, title={Handling service allocation in combined Fog-cloud scenarios},
year={2016},
volume={},
number={},
pages={1-5},
abstract={The recent technological advances related to computing, storage, cloud, networking and the unstoppable deployment of end-user devices, are all coining the so-called Internet of Things (IoT). IoT embraces a wide set of heterogeneous services in highly impacting societal sectors, such as Healthcare, Smart Transportation or Media delivery, all of them posing a diverse set of requirements, including real time response, low latency, or high capacity. In order to properly address such diverse set of requirements, the combined use of Cloud and Fog computing turns up as an emerging trend. Indeed, Fog provides low delay for services demanding real time response, constrained to support low capacity queries, whereas Cloud provides high capacity at the cost of a higher latency. It is with no doubt that a new strategy is required to ease the combined operation of cloud and fog infrastructures in IoT scenarios, also referred to as Combined Fog-Cloud (CFC), in terms of service execution performance metrics. To that end, in this paper, we introduce and formulate the QoS-aware service allocation problem for CFC architectures as an integer optimization problem, whose solution minimizes the latency experienced by the services while guaranteeing the fulfillment of the capacity requirements.},
keywords={cloud computing;integer programming;Internet of Things;minimisation;quality of service;latency minimization;integer optimization problem;QoS-aware service allocation problem;CFC architecture;heterogeneous services;IoT;Internet of Things;end-user device;combined fog-cloud scenario;handling service allocation;Resource management;Cloud computing;Delays;Internet of things;Mathematical model;Computer architecture;Topology;Internet of Things;Combined Fog-Cloud;IoT Service Allocation},
doi={10.1109/ICC.2016.7511465},
ISSN={1938-1883},
month={May},}
@INPROCEEDINGS{9300090,
author={I. {Aoudia} and S. {Benharzallah} and L. {Kahloul} and O. {Kazar}},
booktitle={2020 21st International Arab Conference on Information Technology (ACIT)}, title={QoS-aware service composition in Fog-IoT computing using multi-population genetic algorithm},
year={2020},
volume={},
number={},
pages={1-9},
abstract={The Internet of things (IoT) is the integration of information space and physical space, becoming more and more popular in several places. In this paper, we will present QoS service composition approach based on multi-population genetic algorithm based on Fog-IoT computing, IoT-cloud architecture problems led us to use the 5-layared architecture implemented on a Fog computing system especially the transport layer. Our work was focus on this transport layer where we divided it into four sub-layers (security, storage, pre-processing & monitoring), it allows us to have promising advantages. Secondly, we implemented a multi-population genetic algorithm (MPGA) based on a QoS model, we considered seven QoS dimensions, i.e. Cost, response time, reliability, reputation, location, security and availability. Experimental results show the excellent results of MPGA in terms of fitness value and execution time to handle our ambulance emergency study case.},
keywords={Internet of Things;Computer architecture;Quality of service;Cloud computing;Business;Real-time systems;Optimization;Internet of Things;service composition;adaptability;context;QoS;Fog-IoT computing;Healthcare},
doi={10.1109/ACIT50332.2020.9300090},
ISSN={},
month={Nov},}
@ARTICLE{9003290,
author={M. {Gupta} and M. {Abdelsalam} and S. {Khorsandroo} and S. {Mittal}},
journal={IEEE Access}, title={Security and Privacy in Smart Farming: Challenges and Opportunities},
year={2020},
volume={8},
number={},
pages={34564-34584},
abstract={Internet of Things (IoT) and smart computing technologies have revolutionized every sphere of 21st century humans. IoT technologies and the data driven services they offer were beyond imagination just a decade ago. Now, they surround us and influence a variety of domains such as automobile, smart home, healthcare, etc. In particular, the Agriculture and Farming industries have also embraced this technological intervention. Smart devices are widely used by a range of people from farmers to entrepreneurs. These technologies are used in a variety of ways, from finding real-time status of crops and soil moisture content to deploying drones to assist with tasks such as applying pesticide spray. However, the use of IoT and smart communication technologies introduce a vast exposure to cybersecurity threats and vulnerabilities in smart farming environments. Such cyber attacks have the potential to disrupt the economies of countries that are widely dependent on agriculture. In this paper, we present a holistic study on security and privacy in a smart farming ecosystem. The paper outlines a multi layered architecture relevant to the precision agriculture domain and discusses the security and privacy issues in this dynamic and distributed cyber physical environment. Further more, the paper elaborates on potential cyber attack scenarios and highlights open research challenges and future directions.},
keywords={agriculture;crops;data privacy;Internet of Things;security of data;Internet of Things;precision agriculture domain;smart farming ecosystem;security;cyber attacks;smart farming environments;smart communication technologies;pesticide spray;soil moisture content;smart devices;technological intervention;farming industries;smart home;IoT technologies;smart computing technologies;open research challenges;cyber attack scenarios;dynamic distributed cyber physical environment;privacy issues;Privacy;Real-time systems;Computer security;Security;privacy;smart farming;precision agriculture;cloud computing;edge computing;cyber physical systems;IoT;artificial intelligence (AI);machine learning;layered architecture},
doi={10.1109/ACCESS.2020.2975142},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9122762,
author={A. {Pazienza} and R. {Anglani} and G. {Mallardi} and C. {Fasciano} and P. {Noviello} and C. {Tatulli} and F. {Vitulano}},
booktitle={2020 IEEE Conference on Evolving and Adaptive Intelligent Systems (EAIS)}, title={Adaptive Critical Care Intervention in the Internet of Medical Things},
year={2020},
volume={},
number={},
pages={1-8},
abstract={The possibility of continuous monitoring of health conditions represents a crucial aspect for the improvement of living conditions, the prevention of potential pathologies and prompt response in critical situations. In particular, in intensive care or emergency situations, the evaluation of illness degree of a clinical risk level can be considered a predictive task in situations where streams of vital signs data are gathered by medical devices and the Internet of Medical Things (IoMT) sensors. In this framework, Early Warning Score (EWS) systems generating an aggregate score based on the measurement of a set of vital signs, such as National Early Warning Score 2 (NEWS2) and Modified Early Warning Score (MEWS), may provide a helpful decision support for the estimation of health state and triggers for critical care intervention. In the present work, we address a preliminary analysis in order to investigate the most suitable Machine Learning (ML) technique for the prediction of clinical risk classes of a continuously monitored patient in a particular condition where a limited number of vital parameters is available. This analysis is then intended to be preparatory for the final goal of designing an edge device connected to one or more wearable medical devices via IoMT, which adaptively exploits the best ML model to predict a reliable EWS.},
keywords={biomedical measurement;health care;Internet of Things;learning (artificial intelligence);patient monitoring;clinical risk level;vital signs data;IoMT;health state;wearable medical devices;adaptive critical care intervention;health conditions;living conditions;intensive care;illness degree;Internet of Medical Things sensors;machine learning;Adaptive Intelligence;Internet of Medical Things;Healthcare;Machine Learning;Edge Computing},
doi={10.1109/EAIS48028.2020.9122762},
ISSN={2473-4691},
month={May},}
@INPROCEEDINGS{9221480,
author={I. L. {Olokodana} and S. P. {Mohanty} and E. {Kougianos}},
booktitle={2020 IEEE 6th World Forum on Internet of Things (WF-IoT)}, title={Kriging-Bootstrapped DNN Hierarchical Model for Real-Time Seizure Detection from EEG Signals},
year={2020},
volume={},
number={},
pages={1-5},
abstract={The Deep Neural Network (DNN) model is known for its high accuracy in classification tasks due to its intrinsic ability to learn the underlying patterns existing in a set of data. Hence it has gained momentum in seizure detection research, as in many other fields. However, its high performance is at the expense of an extensive training time. This is not appropriate for a real-time application such as seizure detection in which a swift reaction is required to save the life of the patient. This paper presents a novel Kriging-Bootstrapped Deep Neural Network hierarchical model for early seizure detection in which Kriging is first used to generate a well-correlated intermediate data set from the original input. The correlated data is then fed into the DNN for the final training. Experiments were carried out using electroencephalogram (EEG) data from both normal and epileptic patients. Results show that, with the same architecture and data size, the cumulative training time of the Krigging-Bootstrapped DNN is about 75% lower than that of the ordinary DNN without a compromise in performance as the proposed hybrid model shows a slightly better accuracy than the baseline DNN model.},
keywords={electroencephalography;learning (artificial intelligence);medical signal detection;medical signal processing;neural nets;early seizure detection;correlated data;electroencephalogram data;epileptic patients;data size;Krigging-Bootstrapped DNN;hybrid model;Kriging-Bootstrapped DNN hierarchical model;real-time seizure detection;deep neural network model;classification tasks;seizure detection research;real-time application;Kriging-Bootstrapped deep neural network hierarchical model;Smart Healthcare;Brain;Seizure Detection;Epilepsy;Edge Computing;Kriging Methods;EEG},
doi={10.1109/WF-IoT48130.2020.9221480},
ISSN={},
month={June},}
@INPROCEEDINGS{8756938,
author={Y. {Liao} and Q. {Yu} and X. {Zhai} and Q. {Ai} and Q. {Liu} and T. {Zhou}},
booktitle={2019 IEEE International Conference on Communications Workshops (ICC Workshops)}, title={Wireless Big Data Meets WBANs: An Attempt for Cooperative Task Process Assisted with MEC},
year={2019},
volume={},
number={},
pages={1-5},
abstract={With the rapid developments of wireless body area networks (WBANs), the main purpose of this emerging technology has been transformed from remote healthcare monitoring to resource-hungry interactive entertainment services such as AR/VR applications, which makes both WBANs and user equipment (UE) struggle to process the computation intensive and latency sensitive applications in real-time. This paper proposes a cooperative computation architecture that can handle the wireless big data applications by taking the advantages of WBANs and mobile edge computing (MEC). The access point (AP) in WBANs is integrated with remote radio head (RRH), which is capable of executing the high latency and low computation tasks, while MEC server can handle the low latency computation-intensive tasks. After introducing the proposed model, task classification, task offloading priority and AP offloading decision algorithms are given. Numerical results show that the proposed solution has significantly improved the network lifetime and the total number of successfully executed tasks, as compared with the existing relay-enabled task offloading scheme. Moreover, UEs with higher computation capacity promises a lower network average service latency.},
keywords={Big Data;body area networks;cooperative communication;mobile computing;relay networks (telecommunication);wireless body area networks;remote healthcare monitoring;resource-hungry interactive entertainment services;AR/VR applications;wireless big data applications;mobile edge computing;remote radio head;MEC server;low latency computation-intensive tasks;AP offloading decision algorithms;WBAN;relay-enabled task offloading scheme;Task analysis;Wireless communication;Body area networks;Computational modeling;Classification algorithms;Wireless sensor networks;Quality of service},
doi={10.1109/ICCW.2019.8756938},
ISSN={2474-9133},
month={May},}
@ARTICLE{8493469,
author={Y. {Liao} and Y. {Han} and Q. {Yu} and Q. {Ai} and Q. {Liu} and M. S. {Leeson}},
journal={IEEE Access}, title={Wireless Body Area Network Mobility-Aware Task Offloading Scheme},
year={2018},
volume={6},
number={},
pages={61366-61376},
abstract={The increasing amount of user equipment (UE) and the rapid advances in wireless body area networks bring revolutionary changes in healthcare systems. However, due to the strict requirements on size, reliability and battery lifetime of UE devices, it is difficult for them to execute latency sensitive or computation intensive tasks effectively. In this paper, we aim to enhance the UE computation capacity by utilizing small size coordinator-based mobile edge computing (C-MEC) servers. In this way, the system complexity, computation resources, and energy consumption are considerably transferred from the UE to the C-MEC, which is a practical approach since C-MEC is power charged, in contrast to the UE. First, the system architecture and the mobility model are presented. Second, several transmission mechanisms are analyzed along with the proposed mobility-aware cooperative task offloading scheme. Numerous selected performance metrics are investigated regarding the number of executed tasks, the percentage of failed tasks, average service time, and the energy consumption of each MEC. The results validate the advantage of task offloading schemes compared with the traditional relay-based technique regarding the number of executed tasks. Moreover, one can obtain that the proposed scheme archives noteworthy benefits, such as low latency and efficiently balance the energy consumption of C-MECs.},
keywords={body area networks;mobile computing;mobility management (mobile radio);wireless sensor networks;energy consumption;C-MEC;wireless body area network mobility-aware task offloading scheme;wireless body area networks;healthcare systems;battery lifetime;UE devices;latency sensitive computation intensive tasks;UE computation capacity;system complexity;computation resources;mobility model;coordinator-based mobile edge computing servers;Task analysis;Cloud computing;Medical services;Wireless communication;Servers;Body area networks;Sensors;WBANs;C-MEC;task offloading;mobility-aware},
doi={10.1109/ACCESS.2018.2876311},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9322304,
author={S. {Si-Mohammed} and A. {Ksentini} and M. {Bouaziz} and Y. {Challal} and A. {Balla}},
booktitle={GLOBECOM 2020 - 2020 IEEE Global Communications Conference}, title={UAV Mission Optimization in 5G: On Reducing MEC Service Relocation},
year={2020},
volume={},
number={},
pages={1-6},
abstract={Unmanned Aerial Vehicle (UAV) applications andservices have gained a huge deployment and adoption in differentfields, such as the military domain (Defense or reconnaissance)and the civilian domain (Healthcare, surveillance, and transport).UAV operations are generally critical and require, during opera-tions, a control link with the drones, which should be reliable withvery low latency. To ensure low-latency, 5G architecture intendsto deploy Mobile Edge Computing (MEC) servers, which providecloud computing capabilities close to the end-users. Consequently,it is envisioned that the AutoPilot application will be deployedat the MEC in order to ensure a low latency connection to thedrones. However, the high mobility of drones makes the migrationof the AutoPilot applications among MEC servers unavoidable; inorder to maintain a low latency connection with the flying drones.This may lead to frequent downtime of the service, which mayimpact the AutoPilot performances, and hence service migrationsshould be limited as much as possible. Accordingly, this paperaims to reduce the number of service migrations of drones byintroducing novel algorithms that act at the mission planningphase, where the path of the drones is defined.},
keywords={Drones;5G mobile communication;Servers;Planning;Topology;Network topology;Base stations;UAV;Flight planning;Drones;5G;MEC},
doi={10.1109/GLOBECOM42002.2020.9322304},
ISSN={2576-6813},
month={Dec},}
@INPROCEEDINGS{9221425,
author={S. P. {Shah} and B. J. {Pattan} and N. {Gupta} and N. D. {Tangudu} and S. {Chitturi}},
booktitle={2020 IEEE 3rd 5G World Forum (5GWF)}, title={Service Enabler Layer for 5G Verticals},
year={2020},
volume={},
number={},
pages={269-274},
abstract={With the emerging commercial deployments of 5G Network, the Mobile Network Operators (MNOs) will be able to offer more significant network capabilities such as efficient ultra-reliable and low latency communications (URLLC), higher bandwidth for data transfer with enhanced Mobile Broadband (eMBB), and massive capacity to connect devices with massive Internet of Things (mIoT). MNOs are making huge investments to setup 5G Networks with an anticipation of growth in their revenues. However, MNOs may not see the return of investment through end user consumer base alone and may need additional revenue streams. Thus, 5G system has been designed to have advanced built-in features such as network slicing and edge computing, considering requirements from enterprise segments or vertical industries including healthcare, automotive, smart factories, mission critical communications, etc. To enable more rapid deployment of vertical services, the 5G deployments require fostering innovation at the application layer. With the growing needs of verticals industries, the operators are now focusing on enabling standards for vertical applications in 3rd Generation Partnership Project (3GPP), a global standards forum for 5G. In this paper, the authors explain the Service Enabler Architecture Layer (SEAL) standard for 5G verticals and the services offered by the enabler layer. The paper also elaborates how the operators can leverage the SEAL to quickly develop and deploy vertical applications over the 5G Network.},
keywords={5G mobile communication;Internet of Things;telecommunication services;telecommunication standards;end user consumer base;additional revenue streams;network slicing;edge computing;vertical industries;mission critical communications;vertical services;application layer;verticals industries;5G verticals;mobile network operators;MNO;ultra-reliable low latency communications;data transfer;enhanced Mobile Broadband;5G networks;service enabler architecture layer standard;massive Internet of Things;built-in features;3rd Generation Partnership Project;3GPP;5G Verticals;Vertical Applications;SEAL},
doi={10.1109/5GWF49715.2020.9221425},
ISSN={},
month={Sep.},}
@ARTICLE{8553664,
author={A. {Ksentini} and P. A. {Frangoudis} and A. {PC} and N. {Nikaein}},
journal={IEEE Network}, title={Providing Low Latency Guarantees for Slicing-Ready 5G Systems via Two-Level MAC Scheduling},
year={2018},
volume={32},
number={6},
pages={116-123},
abstract={5G comes with the promise of sub-millisecond latency, which is critical for realizing an array of emerging URLLC services, including industrial, entertainment, telemedicine, automotive, and tactile Internet applications. At the same time, slicing-ready 5G networks face the challenge of accommodating other heterogeneous coexisting services with different and potentially conflicting requirements. Providing latency and reliability guarantees to URLLC service slices is thus not trivial. We identify transmission scheduling at the RAN level as a significant contributor to end-to-end latency when considering network slicing. In this direction, we propose a two-level MAC scheduling framework that can effectively handle uplink and downlink transmissions of network slices of different characteristics over a shared RAN, applying different per-slice scheduling policies, and focusing on reducing latency for URLLC services. Our scheme offers the necessary flexibility to dynamically manage radio resources to meet the stringent latency and reliability requirements of URLLC, as demonstrated by our simulation results.},
keywords={5G mobile communication;access protocols;synchronisation;telecommunication network reliability;telecommunication scheduling;per-slice scheduling policies;URLLC services;slicing-ready 5G systems;slicing-ready 5G networks;heterogeneous coexisting services;URLLC service slices;transmission scheduling;RAN level;network slicing;downlink transmissions;submillisecond latency;uplink transmissions;two-level MAC scheduling;Cloud computing;5G mobile communication;Job shop scheduling;Network slicing;Edge computing;Delays;Low latency communication},
doi={10.1109/MNET.2018.1800005},
ISSN={1558-156X},
month={November},}
@INPROCEEDINGS{9090646,
author={A. {Dasgupta} and M. {Manuel} and R. S. {Mansur} and N. {Nowak} and D. {Gračanin}},
booktitle={2020 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)}, title={Towards Real Time Object Recognition For Context Awareness in Mixed Reality: A Machine Learning Approach},
year={2020},
volume={},
number={},
pages={262-268},
abstract={Mixed Reality (MR) technologies provide users with an environment that incorporates virtual objects and metadata into their physical surroundings. This opens up exciting new possibilities for applications in various domains including: education, training, healthcare, and Computer Supported Cooperative Work (CSCW). Recognizing physical objects in the environment provides contextual clues that can improve user task performance and influence effective cognitive load for complex tasks. However, this facet of MR is still relatively nascent because of hardware limitations. Presently, MR headsets can only detect physical surfaces; they can not distinguish between physical artifacts that a user might need in their work environment. Machine Learning (ML) based object recognition solutions can help overcome this limitation. However, current commercially available MR devices have insufficient computational capabilities and are unable to support the state-of-the-art ML based object recognition solutions. To address these challenges, we describe a novel approach and the corresponding framework by introducing a hardware level separation between the two tasks of object recognition and rendering virtual components. Our approach leverages ML based object recognition, MR, and a portable IoT edge computing platform to support contextual awareness. We describe the implementation of this approach and provide a case study. The prototype implementation uses an edge device to process and recognize objects to get information about the user’s physical environment and provides the user with situational awareness through the MR device. Our case study uses a Christmas tree decoration activity to demonstrate the ability of the proposed framework to support assembly-type tasks. The case study establishes the applicability of the proposed approach to a variety of problem domains. Object recognition and context aware capabilities, combined with virtual indicators and instructions, provide a solution that increases usability, helps reduce human error, and improves the overall task performance.},
keywords={Virtual reality;Object recognition;Context-aware services;Real-time systems;Task analysis;Cameras;Training;Mixed/Augmented reality;Human computer interaction(HCI);Machine learning;Real-time systems;Object recognition;Information visualization},
doi={10.1109/VRW50115.2020.00054},
ISSN={},
month={March},}
@ARTICLE{8360845,
author={N. {Kumar} and J. J. P. C. {Rodrigues} and M. {Guizani} and K. R. {Choo} and R. {Lu} and C. {Verikoukis} and Z. {Zhong}},
journal={IEEE Communications Magazine}, title={Achieving Energy Efficiency and Sustainability in Edge/Fog Deployment},
year={2018},
volume={56},
number={5},
pages={20-21},
abstract={The twelve articles in this special section focus on energy efficiency as it relates to fog or edge computing. The Internet of Things (IoT) has emerged as one of the most advanced and complex technological trends, where more than 50 billion things will be connected (e.g., mobile devices, sensors, wearable devices, and other computing nodes) to the Internet by 2020. Edge/fog computing will play an increasingly important role in handling the information flow of such large and complex networks. An unintended consequence is the impact of their operations on carbon emissions and the resulting electricity costs. Thus, there has been focus on designing energy-efficient solutions for the edge-fog environment. In this Feature Topic, state-of-the-art research advances in energy efficiency and sustainability for edge/fog deployment are presented. },
keywords={Special issues and sections;Edge computing;Computer security;Green products;Computer architecture;Cloud computing;Internet of Things;Energy efficiency;Sustainable development},
doi={10.1109/MCOM.2018.8360845},
ISSN={1558-1896},
month={May},}
@ARTICLE{8767072,
author={M. {Montpetit} and S. {Fdida} and J. {Wang}},
journal={IEEE Communications Magazine}, title={Future Internet: Architectures and Protocols},
year={2019},
volume={57},
number={7},
pages={12-12},
abstract={The articles in this special section focus on future Internet applications. n the 50 years of its existence, the Internet has moved from an academic network to the supporting lifeline of the 21st century. The Internet has not only linked billions of users to one another, but revolutionized commerce, newspapers, television, and transportation. The relentless pace of technological growth is generating opportunities in all sectors of our life: entertainment, automotive, healthcare, education, and personal communications. The articles presented here provide insights on where the Internet is moving to in terms of architectures and technologies.},
keywords={Special issues and sections;Internet;Software architecture;Protocols;Resource management;Data models;Edge computing;Multithreading;Smart homes;Spread spectrum communication;Information-centric networking},
doi={10.1109/MCOM.2019.8767072},
ISSN={1558-1896},
month={July},}
@ARTICLE{9311909,
author={M. {Bennis} and M. {Debbah} and K. {Huang} and Z. {Yang}},
journal={IEEE Communications Magazine}, title={Guest Editorial: Communication Technologies for Efficient Edge Learning},
year={2020},
volume={58},
number={12},
pages={12-13},
abstract={Traditional machine learning is centralized in the cloud (data centers). Recently, the security concern and the availability of abundant data and computation resources in wireless networks are pushing the deployment of learning algorithms toward the network edge. This has led to the emergence of a fast growing area, called edge learning, which integrates two originally decoupled areas: wireless communication and machine learning. It is widely expected that the advancements in edge learning would provide a platform for implementing edge artificial intelligence (AI) in 5G-and-Beyond systems and solving large-scale problems in our society ranging from autonomous driving to personalized healthcare. A typical edge learning framework (e.g., federated learning) features distributed learning over many wireless devices as coordinated by edge servers to cooperatively train a large-scale AI model using local data and CPUs/GPUs. The iterative learning process involves repeated downloading and uploading of high-dimensional (millions to billions) model parameters or their updates by tens to hundreds of devices. This will generate enormous data traffic, placing a heavy burden on the already congested radio access networks. The training problem cannot be efficiently solved using traditional wireless techniques targeting rate maximization and decoupled from learning. Achieving the goal of edge learning with high communication efficiencies calls for the design of new wireless techniques based on a communication-and-learning integration approach.},
keywords={Special issues and sections;Communications technology;Machine learning;Edge computing},
doi={10.1109/MCOM.2020.9311909},
ISSN={1558-1896},
month={December},}
@ARTICLE{8753457,
author={E. {Liu} and A. S. {Pentland} and G. {Adamson} and R. {Ramadoss} and Y. {Yang} and W. {Tsai} and Y. {Zhao} and M. {Lei}},
journal={China Communications}, title={Guest editorial: Blockchain technologies and applications},
year={2019},
volume={16},
number={6},
pages={iii-v},
abstract={Blockchain is a technology that uses community validation to synchronize the content of ledgers replicated by multiple users. Although Blockchain derives its origins from technologies introduced decades ago, recently it has received an astonishing amount of attention in both academic and industry due to its characteristics of decentralization, point-to-point transmission, transparency, traceability, non-tampering, and data security. Both researchers and practitioners have recognized that Blockchain can be used to solve complex technical or socio-economic problems. In recent times, a number of blockchain-based applications have been released in the literature and Blockchain's approaches are used to other cases. For example, as an emerging distributed architecture and computing paradigm, Blockchain technologies have accelerated the development/application of the Internet of Things, Artificial Intelligence, Cloud/Edge Computing, Social Networking, Finance, Insurance, Healthcare, and Supply Chain Management. The popularity and rapid development of Blockchain bring many technical and regulatory challenges for research communities. There is a pressing need to balance between technical and regulatory requirements.},
keywords={},
doi={},
ISSN={1673-5447},
month={June},}