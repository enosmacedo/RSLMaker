@inproceedings{10.1145/2757384.2757397,
author = {Yi, Shanhe and Li, Cheng and Li, Qun},
title = {A Survey of Fog Computing: Concepts, Applications and Issues},
year = {2015},
isbn = {9781450335249},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2757384.2757397},
doi = {10.1145/2757384.2757397},
abstract = {Despite the increasing usage of cloud computing, there are still issues unsolved due to inherent problems of cloud computing such as unreliable latency, lack of mobility support and location-awareness. Fog computing can address those problems by providing elastic resources and services to end users at the edge of network, while cloud computing are more about providing resources distributed in the core network. This survey discusses the definition of fog computing and similar concepts, introduces representative application scenarios, and identifies various aspects of issues we may encounter when designing and implementing fog computing systems. It also highlights some opportunities and challenges, as direction of potential future work, in related techniques that need to be considered in the context of fog computing.},
booktitle = {Proceedings of the 2015 Workshop on Mobile Big Data},
pages = {37–42},
numpages = {6},
keywords = {edge computing, mobile cloud computing, cloud computing, fog computing, review, mobile edge computing},
location = {Hangzhou, China},
series = {Mobidata '15}
}

@inproceedings{10.1145/3190645.3190699,
author = {Choudhari, Tejaswini and Moh, Melody and Moh, Teng-Sheng},
title = {Prioritized Task Scheduling in Fog Computing},
year = {2018},
isbn = {9781450356961},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3190645.3190699},
doi = {10.1145/3190645.3190699},
abstract = {Fog computing, similar to edge computing, has been proposed as a model to introduce a virtualized layer between the end users and the back-end cloud data centers. Fog computing has attracted much attention due to the recent rapid deployment of smart devices and Internet-of-Things (IoT) systems, which often requires real-time, stringent-delay services. The fog layer placed between client and cloud layers aims to reduce the delay in terms of transmission and processing times, as well as the overall cost. To support the increasing number of IoT, smart devices, and to improve performance and reduce cost, this paper proposes a task scheduling algorithm in the fog layer based on priority levels. The proposed architecture, queueing and priority models, priority assignment module, and the priority-based task scheduling algorithms are carefully described. Performance evaluation shows that, comparing with existing task scheduling algorithms, the proposed algorithm reduces the overall response time and notably decreases the total cost. We believe that this work is significant to the emerging fog computing technology, and the priority-based algorithm is useful to a wide range of application domains.},
booktitle = {Proceedings of the ACMSE 2018 Conference},
articleno = {22},
numpages = {8},
keywords = {priority levels, task scheduling, fog computing, resource allocation, cloud computing},
location = {Richmond, Kentucky},
series = {ACMSE '18}
}

@inproceedings{10.1145/3386723.3387861,
author = {Khaloufi, Hayat and Abouelmehdi, Karim and Beni-Hssane, Abederrahim},
title = {Fog Computing for Smart Healthcare Data Analytics: An Urgent Necessity},
year = {2020},
isbn = {9781450376341},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386723.3387861},
doi = {10.1145/3386723.3387861},
abstract = {The advent of Internet of Things (IoT) technologies in the 21st century has led to exciting achievements. IoT smart medical devices along with wearables are generating and communicating high volume and high-velocity of heterogeneous data. Consequently, services provided by traditional methods such as cloud computing to manage these data become insufficient. Fog computing is seen as being the most effective solution for IoT-based healthcare. The stringy demand of this model was principally driven by a growing need for real-time analysis and low latency.It is apparently envisioned that the medicine field expects to draw enormous interest in combining IoT and fog computing. This in turn, improved the patient treatment, staff satisfaction, and operational efficiency and showed positive influence on all aspects of healthcare.This paper has reviewed fog computing in the context of medical IoT while comparing it with cloud computing and has attempted to present the three-layer architecture of fog-based healthcare system containing: edge, fog and cloud. It has also highlighted challenges facing IoT-driven healthcare in an ever-changing world.},
booktitle = {Proceedings of the 3rd International Conference on Networking, Information Systems &amp; Security},
articleno = {42},
numpages = {5},
keywords = {Internet of Things (IoT), Smart Healthcare, Fog Computing, Cloud Computing, Big data},
location = {Marrakech, Morocco},
series = {NISS2020}
}

@inproceedings{10.1145/3360774.3368201,
author = {Silva, Daniel Maniglia A. da and Asaamoning, Godwin and Orrillo, Hector and Sofia, Rute C. and Mendes, Paulo M.},
title = {An Analysis of Fog Computing Data Placement Algorithms},
year = {2019},
isbn = {9781450372831},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3360774.3368201},
doi = {10.1145/3360774.3368201},
abstract = {This work evaluates three Fog Computing data placement algorithms via experiments carried out with the iFogSim simulator. The paper describes the three algorithms (Cloud-only, Mapping, Edge-ward) in the context of an Internet of Things scenario, which has been based on an e-Health system with variations in applications and network topology. Results achieved show that edge placement strategies are beneficial to assist cloud computing in lowering latency and cloud energy expenditure.},
booktitle = {Proceedings of the 16th EAI International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services},
pages = {527–534},
numpages = {8},
keywords = {fog computing, edge selection, network architectures},
location = {Houston, Texas, USA},
series = {MobiQuitous '19}
}

@inproceedings{10.1145/2988287.2989150,
author = {Lin, Hsin-Peng and Shih, Yuan-Yao and Pang, Ai-Chun and Lou, Yuan-Yao},
title = {A Virtual Local-Hub Solution with Function Module Sharing for Wearable Devices},
year = {2016},
isbn = {9781450345026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2988287.2989150},
doi = {10.1145/2988287.2989150},
abstract = {Wearable devices, which are small electronic devices worn on a human body, are equipped with low level of processing and storage capacities and offer some types of integrated functionalities. Recently, wearable device is becoming increasingly popular, various kinds of wearable device are launched in the market; however, wearable devices require a powerful local-hub, most are smartphone, to replenish processing and storage capacities for advanced functionalities. Sometime it may be inconvenient to carry the local-hub (smartphone); thus, many wearable devices are equipped with Wi-Fi interface, enabling them to exchange data with local-hub though the Internet when the local-hub is not nearby. However, this results in long response time and restricted functionalities. In this paper, we present a virtual local-hub solution, which utilizes network equipment nearby (e.g., Wi-Fi APs) as the local-hub. Since migrating all applications serving the wearable devices respectively takes too much networking and storage resources, the proposed solution deploys function modules to multiple network nodes and enables remote function module sharing among different users and applications. To reduce the impact of the solution on the network bandwidth, we propose a heuristic algorithm for function module allocation with the objective of minimizing total bandwidth consumption. We conduct series of experiments, and the results show that the proposed solution can reduce the bandwidth consumption by up to half and still serve all requests given a large number of service requests.},
booktitle = {Proceedings of the 19th ACM International Conference on Modeling, Analysis and Simulation of Wireless and Mobile Systems},
pages = {278–286},
numpages = {9},
keywords = {wearable device, virtualization, local-hub, edge computing, fog computing},
location = {Malta, Malta},
series = {MSWiM '16}
}

@inproceedings{10.1145/3132465.3132475,
author = {Wu, Xiaopei and Dunne, Robert and Zhang, Qingyang and Shi, Weisong},
title = {Edge Computing Enabled Smart Firefighting: Opportunities and Challenges},
year = {2017},
isbn = {9781450355278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3132465.3132475},
doi = {10.1145/3132465.3132475},
abstract = {By collectively leveraging advanced communications systems, sensing, drones, wearable technologies and large-scale data analysis, smart firefighting is envisioned as the next generation firefighting with the capacities of gathering massive real-time scene data, transferring them into useful information and insights for fire responders, and even providing them with more safe and accurate decisions. For smart firefighting, timeliness and accuracy are two foremost system requirements, yet they are unsatisfied in many applications. One reason for such dilemma is due to the underlying used computing architecture (i.e. cloud computing) that can produce extra latency in large-scale data transmission. To address this problem, we explore the firefighting field utilizing edge computing and discuss the overall system architecture, opportunities, challenges, as well as some early technical suggestions on building edge-enabled smart firefighting. To validate the feasibility of edge computing, we simulate the firefighting context and respectively deploy a video-based flame detection algorithm on a local Intel's edge computing platform and a remote Amazon EC2. The preliminary results show that edge computing can significantly increase system's reactive speed, with on average 50% reduction in system latency.},
booktitle = {Proceedings of the Fifth ACM/IEEE Workshop on Hot Topics in Web Systems and Technologies},
articleno = {11},
numpages = {6},
keywords = {IoT, edge computing, smart firefighting, accuracy, cloud computing, timeliness},
location = {San Jose, California},
series = {HotWeb '17}
}

@article{10.1145/3301443,
author = {Puliafito, Carlo and Mingozzi, Enzo and Longo, Francesco and Puliafito, Antonio and Rana, Omer},
title = {Fog Computing for the Internet of Things: A Survey},
year = {2019},
issue_date = {April 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {2},
issn = {1533-5399},
url = {https://doi.org/10.1145/3301443},
doi = {10.1145/3301443},
abstract = {Research in the Internet of Things (IoT) conceives a world where everyday objects are connected to the Internet and exchange, store, process, and collect data from the surrounding environment. IoT devices are becoming essential for supporting the delivery of data to enable electronic services, but they are not sufficient in most cases to host application services directly due to their intrinsic resource constraints. Fog Computing (FC) can be a suitable paradigm to overcome these limitations, as it can coexist and cooperate with centralized Cloud systems and extends the latter toward the network edge. In this way, it is possible to distribute resources and services of computing, storage, and networking along the Cloud-to-Things continuum. As such, FC brings all the benefits of Cloud Computing (CC) closer to end (user) devices. This article presents a survey on the employment of FC to support IoT devices and services. The principles and literature characterizing FC are described, highlighting six IoT application domains that may benefit from the use of this paradigm. The extension of Cloud systems towards the network edge also creates new challenges and can have an impact on existing approaches employed in Cloud-based deployments. Research directions being adopted by the community are highlighted, with an indication of which of these are likely to have the greatest impact. An overview of existing FC software and hardware platforms for the IoT is also provided, along with the standardisation efforts in this area initiated by the OpenFog Consortium (OFC).},
journal = {ACM Trans. Internet Technol.},
month = apr,
articleno = {18},
numpages = {41},
keywords = {cloud computing, Fog computing, topological proximity, internet of things}
}

@inproceedings{10.1145/3341105.3375763,
author = {Kim, Jin Su and Kim, Min Gu and Lee, Myung-Won and Pan, Sung Bum},
title = {Access Control Method Using Electrocardiogram Signal for Fog Computing Security},
year = {2020},
isbn = {9781450368667},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341105.3375763},
doi = {10.1145/3341105.3375763},
abstract = {Personal identification methods using conventional fog computing services are not secure and efficient enough. This paper suggests a method for controlling fog server access rights by using ECG signals. When a user asks personal identification to control the fog server, wearable devices are used to measure ECG signals, and personal identification is confirmed through matching by using a computing device. The public ECG data is used for the experiment by means of the suggested network in order to examine the potential method for controlling the suggested fog server access rights. The experiment results revealing recognition performance of 99.81% of 52 participants in the experiment supports the fact that the method for controlling fog server access rights by using ECG signals in this paper is demonstrated as an effective method.},
booktitle = {Proceedings of the 35th Annual ACM Symposium on Applied Computing},
pages = {1772–1777},
numpages = {6},
keywords = {fog computing, fog network reliability, personal recognition, ECG signal, CNN},
location = {Brno, Czech Republic},
series = {SAC '20}
}

@article{10.1145/3186592,
author = {Mahmud, Redowan and Ramamohanarao, Kotagiri and Buyya, Rajkumar},
title = {Latency-Aware Application Module Management for Fog Computing Environments},
year = {2018},
issue_date = {March 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {1},
issn = {1533-5399},
url = {https://doi.org/10.1145/3186592},
doi = {10.1145/3186592},
abstract = {The fog computing paradigm has drawn significant research interest as it focuses on bringing cloud-based services closer to Internet of Things (IoT) users in an efficient and timely manner. Most of the physical devices in the fog computing environment, commonly named fog nodes, are geographically distributed, resource constrained, and heterogeneous. To fully leverage the capabilities of the fog nodes, large-scale applications that are decomposed into interdependent Application Modules can be deployed in an orderly way over the nodes based on their latency sensitivity. In this article, we propose a latency-aware Application Module management policy for the fog environment that meets the diverse service delivery latency and amount of data signals to be processed in per unit of time for different applications. The policy aims to ensure applications’ Quality of Service (QoS) in satisfying service delivery deadlines and to optimize resource usage in the fog environment. We model and evaluate our proposed policy in an iFogSim-simulated fog environment. Results of the simulation studies demonstrate significant improvement in performance over alternative latency-aware strategies.},
journal = {ACM Trans. Internet Technol.},
month = nov,
articleno = {9},
numpages = {21},
keywords = {resource optimization, application management, latency awareness, fog computing, Internet of things, application placement, application QoS}
}

@inproceedings{10.1145/3387168.3387210,
author = {Chen, Xuehong and Sun, Yan and He, Xiaolong},
title = {A Resource Crowd Funding Model Based on Cooperative Game in Fog Computing},
year = {2019},
isbn = {9781450376259},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387168.3387210},
doi = {10.1145/3387168.3387210},
abstract = {Compared with cloud computing, fog computing has a better performance on location-awareness, mobility support, and time delay. However, the resource quantity and resource types owned by the fog node are relatively limited, which cannot meet the demand of high-performance computing tasks. The scheme of resource sharing can resolve this problem. Therefore, in this paper, we proposed a new resource sharing scheme called resource crowd funding based on cooperative game, which can realize the resource sharing among different fog computing nodes. The resource utilization rate has increased and the fog nodes can acquire additional rewards through task cooperation in this new model, which can be shown in the simulations.},
booktitle = {Proceedings of the 3rd International Conference on Vision, Image and Signal Processing},
articleno = {31},
numpages = {5},
keywords = {Fog computing, Crowd funding, Cooperative game},
location = {Vancouver, BC, Canada},
series = {ICVISP 2019}
}

@inproceedings{10.1145/3175684.3175709,
author = {Taherizadeh, Salman and Stankovski, Vlado},
title = {Auto-Scaling Applications in Edge Computing: Taxonomy and Challenges},
year = {2017},
isbn = {9781450354301},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3175684.3175709},
doi = {10.1145/3175684.3175709},
abstract = {The perspective of online services such as Internet of Things (IoT) applications has impressively evolved over the last recent years as they are becoming more and more time-sensitive, maintained at decentralized locations and easily affected by the changing workload intensity at runtime. As a consequence, an up-and-coming trend has been emerging from previously centralized computation to distributed edge computing in order to address these new concerns. The goal of the present paper is therefore twofold. At first, to analyze modern types of edge computing applications and their auto-scaling challenges to offer desirable performance in conditions where the workload dynamically changes. Secondly, to present a new taxonomy of auto-scaling applications. This taxonomy thoroughly considers edge computing paradigm and its complementary technologies such as container-based visualization.},
booktitle = {Proceedings of the International Conference on Big Data and Internet of Thing},
pages = {158–163},
numpages = {6},
keywords = {Taxonomy, Edge computing, Cloud, Auto-scaling, Internet of Things (IoT)},
location = {London, United Kingdom},
series = {BDIOT2017}
}

@inproceedings{10.1145/3342428.3342654,
author = {Dimitrievski, Ace and Zdravevski, Eftim and Lameski, Petre and Trajkovik, Vladimir},
title = {Addressing Privacy and Security in Connected Health with Fog Computing},
year = {2019},
isbn = {9781450362610},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3342428.3342654},
doi = {10.1145/3342428.3342654},
abstract = {One of the main pillars of connected health is the application of technology to provide healthcare services remotely. Electronic health records are integrated with remote patient monitoring systems using various sensors. However, these ecosystems raise many privacy and security concerns. This paper analyzes and proposes a fog-based solution to address privacy and security challenges in connected health. Privacy protection is investigated for two types of data: less invasive sensors, such as sleep monitor; and highly invasive sensors, such as microphones. In this paper, we show how adding computing resources in the edge can improve privacy and data security, while reducing the computational and bandwidth cost in the cloud.},
booktitle = {Proceedings of the 5th EAI International Conference on Smart Objects and Technologies for Social Good},
pages = {255–260},
numpages = {6},
keywords = {Privacy, AAL, Connected Health, Fog Computing, IoT},
location = {Valencia, Spain},
series = {GoodTechs '19}
}

@article{10.1145/3423332,
author = {Naha, Ranesh Kumar and Garg, Saurabh},
title = {Multi-Criteria--Based Dynamic User Behaviour--Aware Resource Allocation in Fog Computing},
year = {2021},
issue_date = {February 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {1},
issn = {2691-1914},
url = {https://doi.org/10.1145/3423332},
doi = {10.1145/3423332},
abstract = {Fog computing is a promising computing paradigm in which IoT data can be processed near the edge to support time-sensitive applications. However, the availability of resources in computation devices is not stable, since they may not be exclusively dedicated to the Fog application processing in the Fog environment. This, combined with dynamic user behaviour, can affect the execution of applications. To address dynamic changes in user behaviour in resource-limited Fog devices, this article proposes a multi-criteria–based resource allocation policy with resource reservation to minimise overall delay, processing time, and SLA violations. This process considers Fog computing–related characteristics, such as device heterogeneity, resource constraints, and mobility, as well as dynamic changes in user requirements. We employ multiple objective functions to find appropriate resources for executing time-sensitive tasks in the Fog environment. Experimental results show that our proposed policy performs better than the existing one, reducing the total delay by 51%. The proposed algorithm also reduces processing time and SLA violations, which is beneficial for running time-sensitive applications in the Fog environment.},
journal = {ACM Trans. Internet Things},
month = jan,
articleno = {2},
numpages = {31},
keywords = {Internet of things (IoT), resource allocation, time-sensitive application, dynamic behaviour, Fog computing, application scheduling}
}

@inproceedings{10.1145/3394885.3431513,
author = {Odema, Mohanad and Rashid, Nafiul and Al Faruque, Mohammad Abdullah},
title = {Energy-Aware Design Methodology for Myocardial Infarction Detection on Low-Power Wearable Devices},
year = {2021},
isbn = {9781450379991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394885.3431513},
doi = {10.1145/3394885.3431513},
abstract = {Myocardial Infarction (MI) is a heart disease that damages the heart muscle and requires immediate treatment. Its silent and recurrent nature necessitates real-time continuous monitoring of patients. Nowadays, wearable devices are smart enough to perform on-device processing of heartbeat segments and report any irregularities in them. However, the small form factor of wearable devices imposes resource constraints and requires energy-efficient solutions to satisfy them. In this paper, we propose a design methodology to automate the design space exploration of neural network architectures for MI detection. This methodology incorporates Neural Architecture Search (NAS) using Multi-Objective Bayesian Optimization (MOBO) to render Pareto optimal architectural models. These models minimize both detection error and energy consumption on the target device. The design space is inspired by Binary Convolutional Neural Networks (BCNNs) suited for mobile health applications with limited resources. The models' performance is validated using the PTB diagnostic ECG database from PhysioNet. Moreover, energy-related measurements are directly obtained from the target device in a typical hardware-in-the-loop fashion. Finally, we benchmark our models against other related works. One model exceeds state-of-the-art accuracy on wearable devices (reaching 91.22%), whereas others trade off some accuracy to reduce their energy consumption (by a factor reaching 8.26x).},
booktitle = {Proceedings of the 26th Asia and South Pacific Design Automation Conference},
pages = {621–626},
numpages = {6},
keywords = {Wearable Devices, Neural Architecture Search, Mobile Health, Myocardial Infarction, Multi-Objective Bayesian Optimization},
location = {Tokyo, Japan},
series = {ASPDAC '21}
}

@inproceedings{10.1145/3344341.3368800,
author = {Pallewatta, Samodha and Kostakos, Vassilis and Buyya, Rajkumar},
title = {Microservices-Based IoT Application Placement within Heterogeneous and Resource Constrained Fog Computing Environments},
year = {2019},
isbn = {9781450368940},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3344341.3368800},
doi = {10.1145/3344341.3368800},
abstract = {Fog computing paradigm has created innovation opportunities within Internet of Things (IoT) domain by extending cloud services to the edge of the network. Due to the distributed, heterogeneous and resource constrained nature of the Fog computing nodes, Fog applications need to be developed as a collection of interdependent, lightweight modules. Since this concept aligns with the goals of microservices architecture, efficient placement of microservices-based IoT applications within Fog environments has the potential to fully leverage capabilities of Fog devices. In this paper, we propose a decentralized microservices-based IoT application placement policy for heterogeneous and resource constrained Fog environments. The proposed policy utilizes the independently deployable and scalable nature of microservices to place them as close as possible to the data source to minimize latency and network usage. Moreover, it aims to handle service discovery and load balancing related challenges of the microservices architecture. We implement and evaluate our policy using iFogSim simulated Fog environment. Results of the simulations show around 85% improvement in latency and network usage for the proposed microservice placement policy when compared with Cloud-only placement approach and around 40% improvement over an alternative Fog application placement method known as Edge-ward placement policy. Moreover, the decentralized placement approach proposed in this paper demonstrates significant reduction in microservice placement delay over centralized placement.},
booktitle = {Proceedings of the 12th IEEE/ACM International Conference on Utility and Cloud Computing},
pages = {71–81},
numpages = {11},
keywords = {fog computing, internet of things (iot), microservices architecture, application deployment, application placement},
location = {Auckland, New Zealand},
series = {UCC'19}
}

@inproceedings{10.1145/3227609.3227652,
author = {Pe\v{s}i\'{c}, Sa\v{s}a and To\v{s}i\'{c}, Milenko and Ikovi\'{c}, Ognjen and Radovanovi\'{c}, Milo\v{s} and Ivanovi\'{c}, Mirjana and Bo\v{s}kovi\'{c}, Dragan},
title = {Bluetooth Low Energy Microlocation Asset Tracking (BLEMAT) in a Context-Aware Fog Computing System},
year = {2018},
isbn = {9781450354899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3227609.3227652},
doi = {10.1145/3227609.3227652},
abstract = {In this paper we present a Bluetooth Low Energy Microlocation Asset Tracking system (BLEMAT) that performs real-time position estimation and asset tracking based on BLE beacons and scanners. It is built on a context-aware fog computing system comprising Internet of Things controllers, sensors and a cloud platform, helped by machine-learning models and techniques. The BLEMAT system offers detecting signal propagation obstacles, performing signal perturbation correction and beacon paths exploration as well as auto discovery and onboarding of fog controller devices. These are the key characteristics of semi-supervised indoor position estimation services. In this paper we have shown there are solid basis that a fog computing system can efficiently carry out semi-supervised machine learning procedures for high-precision indoor position estimation and space modeling without the need for detailed input information (i.e. floor plan, signal propagation map, scanner position). In addition, the fog computing system inherently brings high level of system robustness, integrity, privacy and trust.},
booktitle = {Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics},
articleno = {23},
numpages = {11},
keywords = {space modeling, indoor positioning, machine learning, Fog computing},
location = {Novi Sad, Serbia},
series = {WIMS '18}
}

@inproceedings{10.1145/3083181.3083183,
author = {Desikan, K. E. Srinivasa and Srinivasan, Manikantan and Murthy, C. Siva Ram},
title = {A Novel Distributed Latency-Aware Data Processing in Fog Computing-Enabled IoT Networks},
year = {2017},
isbn = {9781450350518},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3083181.3083183},
doi = {10.1145/3083181.3083183},
abstract = {In generic Internet of Things (IoT) architecture, all the data generated is sent via gateways (GWs) and is processed in Cloud. This approach limits many real-time applications due to high propagation latency to the Cloud and also under-utilizes the GWs' compute and storage resources. Fog Computing (FC) extends the computability and storage of Cloud computing paradigm to network's edge devices such as GWs. IoT networks with FC enabled GWs, mitigate the latency and underutilization problems by processing data at the GWs. We propose a distributed latency-aware data processing (DLA-DP) model by which FC enabled GWs dynamically exchange processing and storage capability information and probabilistically forward data to its neighboring GWs or to Cloud only when there is a limit in local processing or storage. Modeled as a network of M/M/m/B queuing systems, a DLA-DP enabled IoT network is validated with extensive simulations. DLA-DP model enables improvements such as reduced system response time, increased gateway processing and buffer occupancy efficiencies.},
booktitle = {Proceedings of the ACM Workshop on Distributed Information Processing in Wireless Networks},
articleno = {4},
numpages = {6},
keywords = {Queuing model, Fog computing, Internet of Things, Application processing efficiency, Distributed processing, Buffer efficiency},
location = {Chennai, India},
series = {DIPWN'17}
}

@inproceedings{10.1145/3109761.3158413,
author = {Razouk, Wissam and Sgandurra, Daniele and Sakurai, Kouichi},
title = {A New Security Middleware Architecture Based on Fog Computing and Cloud to Support IoT Constrained Devices},
year = {2017},
isbn = {9781450352437},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3109761.3158413},
doi = {10.1145/3109761.3158413},
abstract = {The increase of sensitive data in the current Internet of Things (IoT) raises demands of computation, communication and storage capabilities. Indeed, thanks to RFID tags and wireless sensor networks, anything can be part of IoT. As a result, a large amount of data is generated, which is hard for many IoT devices to handle, as many IoT devices are resource-constrained and cannot use the existing standard security protocols. Cloud computing might seem like a convenient solution, since it offers on-demand access to a shared pool of resources such as processors, storage, applications and services. However this comes as a cost, as unnecessary communications not only burden the core network, but also the data center in the cloud. Therefore, considering suitable approaches such as fog computing and security middleware solutions is crucial.In this paper, we propose a novel middleware architecture to solve the above issues, and discuss the generic concept of using fog computing along with cloud in order to achieve a higher security level. Our security middleware acts as a smart gateway as it is meant to pre-process data at the edge of the network. Depending on the received information, data might either be processed and stored locally on fog or sent to the cloud for further processing. Moreover, in our scheme, IoT constrained devices communicate through the proposed middleware, which provide access to more computing power and enhanced capability to perform secure communications. We discuss these concepts in detail, and explain how our proposal is effective to cope with some of the most relevant IoT security challenges.},
booktitle = {Proceedings of the 1st International Conference on Internet of Things and Machine Learning},
articleno = {35},
numpages = {8},
keywords = {fog computing, internet of things security, ressource-constrained devices, cloud},
location = {Liverpool, United Kingdom},
series = {IML '17}
}

@inproceedings{10.1145/2818869.2818889,
author = {Dubey, Harishchandra and Yang, Jing and Constant, Nick and Amiri, Amir Mohammad and Yang, Qing and Makodiya, Kunal},
title = {Fog Data: Enhancing Telehealth Big Data Through Fog Computing},
year = {2015},
isbn = {9781450337359},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2818869.2818889},
doi = {10.1145/2818869.2818889},
abstract = {The size of multi-modal, heterogeneous data collected through various sensors is growing exponentially. It demands intelligent data reduction, data mining and analytics at edge devices. Data compression can reduce the network bandwidth and transmission power consumed by edge devices. This paper proposes, validates and evaluates Fog Data, a service-oriented architecture for Fog computing. The center piece of the proposed architecture is a low power embedded computer that carries out data mining and data analytics on raw data collected from various wearable sensors used for telehealth applications. The embedded computer collects the sensed data as time series, analyzes it, and finds similar patterns present. Patterns are stored, and unique patterns are transmited. Also, the embedded computer extracts clinically relevant information that is sent to the cloud. A working prototype of the proposed architecture was built and used to carry out case studies on telehealth big data applications. Specifically, our case studies used the data from the sensors worn by patients with either speech motor disorders or cardiovascular problems. We implemented and evaluated both generic and application specific data mining techniques to show orders of magnitude data reduction and hence transmission power savings. Quantitative evaluations were conducted for comparing various data mining techniques and standard data compression techniques. The obtained results showed substantial improvement in system efficiency using the Fog Data architecture.},
booktitle = {Proceedings of the ASE BigData &amp; SocialInformatics 2015},
articleno = {14},
numpages = {6},
keywords = {Wearable Devices, Body Area Network, Big Data, Internet of Things, Edge Computing, Fog Computing, Cyber-physical Systems},
location = {Kaohsiung, Taiwan},
series = {ASE BD&amp;SI '15}
}

@inproceedings{10.1145/3132211.3134458,
author = {Chen, Zhuo and Hu, Wenlu and Wang, Junjue and Zhao, Siyan and Amos, Brandon and Wu, Guanhang and Ha, Kiryong and Elgazzar, Khalid and Pillai, Padmanabhan and Klatzky, Roberta and Siewiorek, Daniel and Satyanarayanan, Mahadev},
title = {An Empirical Study of Latency in an Emerging Class of Edge Computing Applications for Wearable Cognitive Assistance},
year = {2017},
isbn = {9781450350877},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3132211.3134458},
doi = {10.1145/3132211.3134458},
abstract = {An emerging class of interactive wearable cognitive assistance applications is poised to become one of the key demonstrators of edge computing infrastructure. In this paper, we design seven such applications and evaluate their performance in terms of latency across a range of edge computing configurations, mobile hardware, and wireless networks, including 4G LTE. We also devise a novel multi-algorithm approach that leverages temporal locality to reduce end-to-end latency by 60% to 70%, without sacrificing accuracy. Finally, we derive target latencies for our applications, and show that edge computing is crucial to meeting these targets.},
booktitle = {Proceedings of the Second ACM/IEEE Symposium on Edge Computing},
articleno = {14},
numpages = {14},
keywords = {cloudlet, edge computing, smart glass, hololens, mobile computing, augmented reality, cloud computing},
location = {San Jose, California},
series = {SEC '17}
}

@inproceedings{10.1145/3344341.3368816,
author = {Tocz\'{e}, Klervie and Lindqvist, Johan and Nadjm-Tehrani, Simin},
title = {Performance Study of Mixed Reality for Edge Computing},
year = {2019},
isbn = {9781450368940},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3344341.3368816},
doi = {10.1145/3344341.3368816},
abstract = {Edge computing is a recent paradigm where computing resources are placed close to the user, at the edge of the network. This is a promising enabler for applications that are too resource-intensive to be run on an end device, but at the same time require too low latency to be run in a cloud, such as for example mixed reality (MR). In this work, we present MR-Leo, a prototype for creating an MR-enhanced video stream. It enables offloading of the point cloud creation and graphic rendering at the edge. We study the performance of the prototype with regards to latency and throughput in five different configurations with different alternatives for the transport protocol, the video compression format and the end/edge devices used. The evaluations show that UDP and MJPEG are good candidates for achieving acceptable latency and that the design of the communication protocol is critical for offloading video stream analysis to the edge.},
booktitle = {Proceedings of the 12th IEEE/ACM International Conference on Utility and Cloud Computing},
pages = {285–294},
numpages = {10},
keywords = {mixed reality, open-source prototype, edge/fog computing, empirical performance evaluation},
location = {Auckland, New Zealand},
series = {UCC'19}
}

@inproceedings{10.1145/3316615.3318222,
author = {Shukla, Saurabh and Hassan, Mohd Fadzil and Jung, Low Tang and Awang, Azlan and Khan, Muhammad Khalid},
title = {A 3-Tier Architecture for Network Latency Reduction in Healthcare Internet-of-Things Using Fog Computing and Machine Learning},
year = {2019},
isbn = {9781450365734},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3316615.3318222},
doi = {10.1145/3316615.3318222},
abstract = {Healthcare Internet-of-things comprises a huge number of wearable sensors and interconnected computers. The high volume of IoT data is transacted over servers leading to servers overloading with high traffic causing network congestion. These cloud servers are typically for analyzing, retrieving and storing the large data generated from IoT devices. There exist challenges regarding sending real-time healthcare data from cloud servers to end-users. These challenges include the high computational latency, high communication latency, and high network latency. Due to these challenges, IoTs may not be able to send data in real-time to end-users. Fog nodes can be used to play a major role in reducing the high delay and high traffic. It can be a solution to increase system performance. In this paper, we proposed a 3-tier architecture, an analytical model for healthcare IoT using a hybrid approach consisting of fuzzy logic and reinforcement learning in a fog computing environment. The aim is to minimize network latency. The proposed model and 3-tier architecture are simulated using iFogSim simulator.},
booktitle = {Proceedings of the 2019 8th International Conference on Software and Computer Applications},
pages = {522–528},
numpages = {7},
keywords = {Fuzzy-logic, internet-of-things, cloud computing, reinforcement learning, fog computing},
location = {Penang, Malaysia},
series = {ICSCA '19}
}

@inproceedings{10.1145/3437378.3444367,
author = {Aslanpour, Mohammad S. and Toosi, Adel N. and Cicconetti, Claudio and Javadi, Bahman and Sbarski, Peter and Taibi, Davide and Assuncao, Marcos and Gill, Sukhpal Singh and Gaire, Raj and Dustdar, Schahram},
title = {Serverless Edge Computing: Vision and Challenges},
year = {2021},
isbn = {9781450389563},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3437378.3444367},
doi = {10.1145/3437378.3444367},
abstract = { Born from a need for a pure “pay-per-use” model and highly scalable platform, the “Serverless” paradigm emerged and has the potential to become a dominant way of building cloud applications. Although it was originally designed for cloud environments, Serverless is finding its position in the Edge Computing landscape, aiming to bring computational resources closer to the data source. That is, Serverless is crossing cloud borders to assess its merits in Edge computing, whose principal partner will be the Internet of Things (IoT) applications. This move sounds promising as Serverless brings particular benefits such as eliminating always-on services causing high electricity usage, for instance. However, the community is still hesitant to uptake Serverless Edge Computing because of the cloud-driven design of current Serverless platforms, and distinctive characteristics of edge landscape and IoT applications. In this paper, we evaluate both sides to shed light on the Serverless new territory. Our in-depth analysis promotes a broad vision for bringing Serverless to the Edge Computing. It also issues major challenges for Serverless to be met before entering Edge computing.},
booktitle = {2021 Australasian Computer Science Week Multiconference},
articleno = {10},
numpages = {10},
location = {Dunedin, New Zealand},
series = {ACSW '21}
}

@inproceedings{10.1145/3094405.3094411,
author = {Avino, G. and Malinverno, M. and Malandrino, F. and Casetti, C. and Chiasserini, C. F.},
title = {Characterizing Docker Overhead in Mobile Edge Computing Scenarios},
year = {2017},
isbn = {9781450350587},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3094405.3094411},
doi = {10.1145/3094405.3094411},
abstract = {Mobile Edge Computing (MEC) is an emerging network paradigm that provides cloud and IT services at the point of access of the network. Such proximity to the end user translates into ultra-low latency and high bandwidth, while, at the same time, it alleviates traffic congestion in the network core. Due to the need to run servers on edge nodes (e.g., an LTE-A macro eNodeB), a key element of MEC architectures is to ensure server portability and low overhead. A possible tool that can be used for this purpose is Docker, a framework that allows easy, fast deployment of Linux containers. This paper addresses the suitability of Docker in MEC scenarios by quantifying the CPU consumed by Docker when running two different containerized services: multiplayer gaming and video streaming. Our tests, run with varying numbers of clients and servers, yield different results for the two case studies: for the gaming service, the overhead logged by Docker increases only with the number of servers; conversely, for the video streaming case, the overhead is not affected by the number of either clients or servers.},
booktitle = {Proceedings of the Workshop on Hot Topics in Container Networking and Networked Systems},
pages = {30–35},
numpages = {6},
keywords = {Mobile Edge Computing, Docker, Containers, 5G networks},
location = {Los Angeles, CA, USA},
series = {HotConNet '17}
}

@inproceedings{10.1145/3338840.3355647,
author = {Gakpo, Godwin Kobby and Su, Xin and Choi, Chang},
title = {Moving Intelligence of Mobile Edge Computing to Maritime Network},
year = {2019},
isbn = {9781450368438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338840.3355647},
doi = {10.1145/3338840.3355647},
abstract = {We present moving intelligence of Mobile Edge Computing (MEC) closer to the vessel terminal devices in the maritime network. This technology proves to be a better approach for managing data resources generated by the internet of things (IoT) devices in a marine vessel. Regarding the problem of high transmission delay and low bandwidth in the conventional cloud computing approach, the MEC is a new revelation that extends cloud computing services such as data computation and resource storage capabilities to the edge of the maritime network. Lately, the emergence of heterogeneous IoT devices has increased the data generated from several applications such as real-time and other advanced monitoring applications. This could be processed and analyzed at the edge network with lower delay. In this paper, we propose offloading data resources for computation to the MEC network in order to minimize transmission delay and the response time considering the energy consumption at the vessel terminal. Our simulation results show offloading computation to the MEC network delivers better performance compared to the conventional cloud computing services.},
booktitle = {Proceedings of the Conference on Research in Adaptive and Convergent Systems},
pages = {189–193},
numpages = {5},
keywords = {mobile edge computing, internet of things, maritime network, vessel terminal},
location = {Chongqing, China},
series = {RACS '19}
}

@inproceedings{10.1145/3320326.3320377,
author = {Babou, Cheikh Saliou Mbacke and Sane, Bernard Ousmane and Diane, Ibrahima and Niang, Ibrahima},
title = {Home Edge Computing Architecture for Smart and Sustainable Agriculture and Breeding},
year = {2019},
isbn = {9781450366458},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3320326.3320377},
doi = {10.1145/3320326.3320377},
abstract = {Challenges of today and tomorrow in developing countries to ensure sustainable food security for their populations require smart agriculture and breeding. This necessarily depends on water control, soil erosion, livestock management, and so on. At the same time, Internet of Things (IoT) represents the latest evolution of the Internet and can significantly improve the ability to collect, analyze and retrieve data that we can then transform into information, knowledge and finally knowing. In the context of ensuring smart and sustainable agriculture, the importance of IoT seems obvious. Note that, IoT has implications for bandwidth, latency and processing speeds, given the huge amount of data to collect. Edge computing and Systems are one of the emerging solutions to reduce latency and improve bandwidth utilization for real-time applications and services. Thus, to achieve these aims, we propose, in this paper, a new three-tier architecture (3-TIER) for smart agriculture. It is based on that of Home Edge Computing allowing us to achieve ultra-low latency. This architecture will also allow us to effectively solve the problems related to agriculture and livestock breeding, but also to be able to resolve considerably the conflicts between farmers and herders. This proposal will be followed by an experimental validation of HEC architecture using the EdgeCloudSim simulator.},
booktitle = {Proceedings of the 2nd International Conference on Networking, Information Systems &amp; Security},
articleno = {45},
numpages = {7},
keywords = {Ultra-low Latency, EdgeCloudSim, Home Edge Computing (HEC), Smart Agriculture, Internet of Things (IoT), Edge Computing Systems},
location = {Rabat, Morocco},
series = {NISS19}
}

@inproceedings{10.1145/3385209.3385222,
author = {Kim, Dohyung and Mun, Jonghyeok and Park, Yoosang and Choi, Jongsun and Choi, Jaeyoung},
title = {Planning System Architecture of Fat-Client Management for Customized Healthcare Services in Edge Computing Environment},
year = {2020},
isbn = {9781450376594},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3385209.3385222},
doi = {10.1145/3385209.3385222},
abstract = {To provide customized healthcare services in edge computing environment, it is necessary to process perspectives related to delivering context information such as procedures of data collection and analysis in various data formats. It is required to have a fat-client concept that performs, data preprocessing and converting data formats where generated data sets have different structure. Furthermore, the fat-client concept has advantages of covering data acquisitions and job allocations in edge computing environment. Once data sets are collected, then users can have healthcare reports, analyzed in a different level. When dealing with procedures of analysis, their models are necessary because data sets have different formats and ranges, moreover models will be required for user customizing it by adjustment the data sets being collected. This paper proposes a method for managing fat-client to provide customized healthcare services in edge computing environment. The proposed method, provides a fat-client profile for managing each fat-client user. The fat-client profile includes information such as sequences of data sources and analysis methods. In the experiment, the fat-client management is demonstrated through data collection and monitoring of instances created by the Fat-Client profile.},
booktitle = {Proceedings of the 2020 5th International Conference on Intelligent Information Technology},
pages = {91–96},
numpages = {6},
keywords = {Customized healthcare service, Edge computing, Management, Fat-Client},
location = {Hanoi, Viet Nam},
series = {ICIIT 2020}
}

@inproceedings{10.1145/3344341.3368804,
author = {Ma, Weibin and Mashayekhy, Lena},
title = {Privacy-by-Design Distributed Offloading for Vehicular Edge Computing},
year = {2019},
isbn = {9781450368940},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3344341.3368804},
doi = {10.1145/3344341.3368804},
abstract = {Vehicular Edge Computing (VEC) is a distributed computing paradigm that utilizes smart vehicles (SVs) as computational cloudlets (edge nodes) by virtue of their inherent attributes such as mobility, low operating costs, flexible deployment, and wireless communication ability. VEC extends edge computing services by expanding computing coverage and further improving quality-of-services (QoS) for devices. Due to limited onboard energy and computation capabilities of SV-mounted cloudlets, a single vehicle might not be able to execute a large number of tasks and guarantee their desired QoS. To address this problem, the overloaded vehicle can fulfill its overwhelming workload by offloading its tasks to other available connected vehicles. However, data privacy and accessibility are of critical importance that need to be considered for offloading. In this paper, we propose privacy-by-design offloading solutions for VEC to facilitate latency requirements of user demands and reduce energy consumption of vehicles.We formulate the Data pRotection Offloading Problem (DROP) as an Integer Program and prove its NP-hardness. To provide computationally tractable solutions, we propose three distributed algorithms by leveraging graph theory to solve this problem. We evaluate the performance of our proposed algorithms by extensive experiments and compare them to the optimal results obtained by IBM ILOG CPLEX. The results demonstrate the flexibility, scalability, and cost efficiency of our proposed algorithms in providing practical privacy-by-design offloading solutions enabling edge services along the cloud-to-thing continuum.},
booktitle = {Proceedings of the 12th IEEE/ACM International Conference on Utility and Cloud Computing},
pages = {101–110},
numpages = {10},
keywords = {data protection, distributed algorithms, internet-of-things, smart connected vehicles, vehicular edge computing},
location = {Auckland, New Zealand},
series = {UCC'19}
}

@article{10.1145/3372025,
author = {Shen, Shihao and Han, Yiwen and Wang, Xiaofei and Wang, Yan},
title = {Computation Offloading with Multiple Agents in Edge-Computing–Supported IoT},
year = {2019},
issue_date = {February 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {1550-4859},
url = {https://doi.org/10.1145/3372025},
doi = {10.1145/3372025},
abstract = {With the development of the Internet of Things (IoT) and the birth of various new IoT devices, the capacity of massive IoT devices is facing challenges. Fortunately, edge computing can optimize problems such as delay and connectivity by offloading part of the computational tasks to edge nodes close to the data source. Using this feature, IoT devices can save more resources while still maintaining the quality of service. However, since computation offloading decisions concern joint and complex resource management, we use multiple Deep Reinforcement Learning (DRL) agents deployed on IoT devices to guide their own decisions. Besides, Federated Learning (FL) is utilized to train DRL agents in a distributed fashion, aiming to make the DRL-based decision making practical and further decrease the transmission cost between IoT devices and Edge Nodes. In this article, we first study the problem of computation offloading optimization and prove the problem is an NP-hard problem. Then, based on DRL and FL, we propose an offloading algorithm that is different from the traditional method. Finally, we studied the effects of various parameters on the performance of the algorithm and verified the effectiveness of both the DRL and FL in the IoT system.},
journal = {ACM Trans. Sen. Netw.},
month = dec,
articleno = {8},
numpages = {27},
keywords = {Federated learning, edge computing, computation offloading, IoT}
}

@inproceedings{10.1145/3144730.3144736,
author = {Akrivopoulos, Orestis and Amaxilatis, Dimitrios and Antoniou, Athanasios and Chatzigiannakis, Ioannis},
title = {Design and Evaluation of a Person-Centric Heart Monitoring System over Fog Computing Infrastructure},
year = {2017},
isbn = {9781450354806},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3144730.3144736},
doi = {10.1145/3144730.3144736},
abstract = {Heart disease and stroke are becoming the leading cause of death worldwide. Electrocardiography monitoring devices (ECG) are the only tool that helps physicians diagnose cardiac abnormalities. Although the design of ECGs has followed closely the electronics miniaturization evolution over the years, existing wearable ECG have limited accuracy and rely on external resources to analyze the signal and evaluate heart activity. In this paper, we work towards empowering the wearable device with processing capabilities to locally analyze the signal and identify abnormal behavior. The ability to differentiate between normal and abnormal heart activity significantly reduces (a) the need to store the signals, (b) the data transmitted to the cloud and (c) the overall power consumption. Based on this concept, the HEART platform is presented that combines wearable embedded devices, mobile edge devices, and cloud services to provide on-the-spot, reliable, accurate and instant monitoring of the heart. The performance of the system is evaluated concerning the accuracy of detecting abnormal events and the power consumption of the wearable device. Results indicate that a very high percentage of success can be achieved in terms of event detection ratio and the device being operative up to a several days without the need for a recharge.},
booktitle = {Proceedings of the First International Workshop on Human-Centered Sensing, Networking, and Systems},
pages = {25–30},
numpages = {6},
keywords = {Healthcare, Wearable, mHealth, Prototype, IoT, Evaluation},
location = {Delft, Netherlands},
series = {HumanSys'17}
}

@inproceedings{10.1145/3231053.3231062,
author = {Al-khafajiy, Mohammed and Webster, Lee and Baker, Thar and Waraich, Atif},
title = {Towards Fog Driven IoT Healthcare: Challenges and Framework of Fog Computing in Healthcare},
year = {2018},
isbn = {9781450364287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3231053.3231062},
doi = {10.1145/3231053.3231062},
abstract = {As we are within the era of the internet of things (IoT) its increasing integration to our everyday lives means that the devices involved produce massive amounts of data every second from billions of devices. The current approach used to handle this data is cloud computing. However because of its requirement of data centres this can become infeasible for the processing of data from IoT due to distance between these IoT smart objects (e.g., sensors) and the data centre. If this data holds any importance to minimal delay then the travel time between the end device and the clouds data centre could affect the relevance of that data. Therefore, to deal with these issues a new network paradigm placed closer to the IoT end devices is introduced called "Fog computing" to help address these challenges. If introduced effectively then fog computing can lead to the improvements in the quality of service (QoS) offered to systems that require the processing of delay sensitive data like healthcare systems that could benefit from the quick processing of data from sensors to allow the monitoring of patients. This paper has a main focus on healthcare systems. An architecture containing three layers; things (i.e., sensors), fog nodes and a cloud data centre is proposed alongside a framework incorporating this architecture. This framework offers collaboration among fog nodes with optimal management of resources and job allocation, which is able to achieve a high QoS (i.e., low latency) within the scenario of a healthcare system.},
booktitle = {Proceedings of the 2nd International Conference on Future Networks and Distributed Systems},
articleno = {9},
numpages = {7},
keywords = {fog-to-fog, internet of things, fog computing, resource managements, healthcare, IoT},
location = {Amman, Jordan},
series = {ICFNDS '18}
}

@inproceedings{10.1145/3312614.3312632,
author = {Nakhkash, Mohammad R. and Gia, Tuan Nguyen and Azimi, Iman and Anzanpour, Arman and Rahmani, Amir M. and Liljeberg, Pasi},
title = {Analysis of Performance and Energy Consumption of Wearable Devices and Mobile Gateways in IoT Applications},
year = {2019},
isbn = {9781450366403},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3312614.3312632},
doi = {10.1145/3312614.3312632},
abstract = {Smartphones and wearable devices, such as smart watches, can act as mobile gateways and sensor nodes in IoT applications, respectively. In conventional IoT systems, wearable devices gather and transmit data to mobile gateways where most of computations are performed. However, the improvement of wearable devices, in recent years, has decreased the gap in terms of computation capability with mobile gateways. For this reason, some recent works present offloading schemes to utilize wearable devices and hence reducing the burden of mobile gateways for specific applications. However, a comprehensive study of offloading methods on wearable devices has not been conducted. In this paper, nine applications from the LOCUS's benchmark have been utilized and tested on different boards having hardware specification close to wearable devices and mobile gateways. The execution time and energy consumption results of running the benchmark on the boards are measured. The results are then used for providing insights for system designers when designing and choosing a suitable computation method for IoT systems to achieve a high quality of service (QoS). The results show that depending on the application, offloading methods can be used for achieving certain improvements in energy efficiency. In addition, the paper compares energy consumption of a mobile gateway when running the applications in both serial and multithreading fashions.},
booktitle = {Proceedings of the International Conference on Omni-Layer Intelligent Systems},
pages = {68–73},
numpages = {6},
keywords = {Mobile Gateway, Internet-of-Things, Performance and Energy Evaluation, Wearables},
location = {Crete, Greece},
series = {COINS '19}
}

@inproceedings{10.1145/3365438.3410951,
author = {Song, Hui and Dautov, Rustem and Ferry, Nicolas and Solberg, Arnor and Fleurey, Franck},
title = {Model-Based Fleet Deployment of Edge Computing Applications},
year = {2020},
isbn = {9781450370196},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3365438.3410951},
doi = {10.1145/3365438.3410951},
abstract = {Edge computing brings software in close proximity to end users and IoT devices. Given the increasing number of distributed Edge devices with various contexts, as well as the widely adopted continuous delivery practices, software developers need to maintain multiple application versions and frequently (re-)deploy them to a fleet of many devices with respect to their contexts. Doing this correctly and efficiently goes beyond manual capabilities and requires employing an intelligent and reliable automated approach. Accordingly this paper describes a joint research with a Smart Healthcare application provider on a model-based approach to automatically assigning multiple software deployments to hundreds of Edge gateways. From a Platform-Specific Model obtained from the existing Edge computing platform, we extract a Platform-Independent Model that describes a list of target devices and a pool of available deployments. Next, we use constraint solving to automatically assign deployments to devices at once, given their specific contexts. The resulting solution is transformed back to the PSM as to proceed with software deployment accordingly. We validate the approach with a Fleet Deployment prototype integrated into the DevOps toolchain currently used by the application provider. Initial experiments demonstrate the viability of the approach and its usefulness in supporting DevOps in Edge computing applications.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems},
pages = {132–142},
numpages = {11},
keywords = {DevOps, software deployment, model-based software engineering, device fleet, IoT},
location = {Virtual Event, Canada},
series = {MODELS '20}
}

@inproceedings{10.1145/3384943.3409429,
author = {Sun, Yuhu and He, Qiang and Qi, Lianyong and Rafique, Wajid and Dou, Wanchun},
title = {DPODA: Differential Privacy-Based Online Double Auction for Pervasive Edge Computing Resource Allocation},
year = {2020},
isbn = {9781450376105},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384943.3409429},
doi = {10.1145/3384943.3409429},
abstract = {In recent years, edge computing transforms the network edge into an intelligent platform to provide better services for users by making storage, computing, control and network function closer to end-users, things, and sensors. However, due to the limitation of edge resources and the diversity of edge resource providers, there is no good mechanism to solve the resource allocation problem in the edge computing resource allocation market. Aiming at the problem of resource allocation in edge computing, this paper proposes a double auction scheme-DPODA. This scheme establishes the auction market of edge computing resources, which can improve the social welfare of auction to the maximum extent. Moreover, as the private information of users in the auction market may affect market transactions, in order to solve this problem, this paper uses differential privacy technology to effectively protect the privacy of both sides of the auction, so as to avoid the unfairness in the auction market. A large number of simulation experiments show that the algorithm proposed in this paper not only achieves the research purpose but also ensures the privacy information security of the auctioneer.},
booktitle = {Proceedings of the 2nd ACM International Symposium on Blockchain and Secure Critical Infrastructure},
pages = {130–141},
numpages = {12},
keywords = {online algorithm, privacy protection, edge computing, resource allocation, double auction, differential privacy},
location = {Taipei, Taiwan},
series = {BSCI '20}
}

@inproceedings{10.1145/3278576.3278595,
author = {Thurston, Karen Hammer and de Leon, Daniel Conte},
title = {The Healthcare IoT Ecosystem: Advantages of Fog Computing near the Edge},
year = {2018},
isbn = {9781450359580},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3278576.3278595},
doi = {10.1145/3278576.3278595},
abstract = {The Internet of Things (IoT) provides numerous opportunities for the connected healthcare industry, especially in the distributed environment known as fog which resides in a middle architectural layer adjacent to the network edge and user devices. This paper provides an overview of recent research and industry advances and challenges on fog technologies focusing on connected healthcare applications. We present and review for IoT and fog: concepts and architectures; development and lifecycle frameworks; security vulnerabilities, threats, and best practices; and connected medical device regulations.},
booktitle = {Proceedings of the 2018 IEEE/ACM International Conference on Connected Health: Applications, Systems and Engineering Technologies},
pages = {51–56},
numpages = {6},
keywords = {edge computing, fog computing, connected health, middleware, cloud operating systems, gateways, IoT, service-oriented architectures, secure systems development, secure software engineering},
location = {Washington, DC},
series = {CHASE '18}
}

@inproceedings{10.1145/3321408.3321586,
author = {Han, Yiwen and Li, Ding and Qi, Haotian and Ren, Jianji and Wang, Xiaofei},
title = {Federated Learning-Based Computation Offloading Optimization in Edge Computing-Supported Internet of Things},
year = {2019},
isbn = {9781450371582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3321408.3321586},
doi = {10.1145/3321408.3321586},
abstract = {Recent visualizations of smart cities, factories, healthcare system and etc. raise challenges on the capability and connectivity of massive Internet of Things (IoT) devices. Hence, edge computing is emerged to complement these capability-constrained devices with an idea offloading intensive computation tasks from them to edge nodes. By taking advantage of this feature, IoT devices are able to conserve more energy and still maintain the quality of services they shall provide. Nevertheless, computation offloading decisions concern joint and complex resource management and should be determined in real time facing dynamic workloads and radio environment. Therefore, in this work, we use multiple Deep Reinforcement Learning (DRL) agents deployed on IoT devices to instruct the decision making of themselves. On the other hand, Federated Learning is utilized to train DRL agents in a distributed fashion, aiming to make the DRL-based decision making practical and further decrease the transmission cost between IoT devices and Edge Nodes. Experimental results corroborate the effectiveness of both the DRL and Federated Learning in the dynamic IoT system.},
booktitle = {Proceedings of the ACM Turing Celebration Conference - China},
articleno = {25},
numpages = {5},
keywords = {edge computing, federated learning, IoT, computation offloading},
location = {Chengdu, China},
series = {ACM TURC '19}
}

@inproceedings{10.1145/3267305.3274122,
author = {Hellmund, Till and Seitz, Andreas and Haladjian, Juan and Bruegge, Bernd},
title = {IPRA: Real-Time Face Recognition on Smart Glasses with Fog Computing},
year = {2018},
isbn = {9781450359665},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3267305.3274122},
doi = {10.1145/3267305.3274122},
abstract = {The availability of artificial intelligence and smart glasses, equipped with cameras and displays, presents a strong foundation on which to build a wearable cognitive assistant, a device that provides the user with context-aware information. Although technical challenges such as power consumption and insufficient latency have plagued early versions of such products, developments in fog computing present a potential solution. In this paper, we present an application that uses fog computing to provide real-time face recognition on smart glasses. To understand the impact of fog computing on latency and battery consumption, we compare it with an adapted version that does not rely on fog computing.},
booktitle = {Proceedings of the 2018 ACM International Joint Conference and 2018 International Symposium on Pervasive and Ubiquitous Computing and Wearable Computers},
pages = {988–993},
numpages = {6},
keywords = {Real-Time, Face Recognition, Fog Computing, Wearable Cognitive Assistant, Smart Glasses, Data Glasses},
location = {Singapore, Singapore},
series = {UbiComp '18}
}

@inproceedings{10.1145/2757384.2757398,
author = {Cao, Yu and Hou, Peng and Brown, Donald and Wang, Jie and Chen, Songqing},
title = {Distributed Analytics and Edge Intelligence: Pervasive Health Monitoring at the Era of Fog Computing},
year = {2015},
isbn = {9781450335249},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2757384.2757398},
doi = {10.1145/2757384.2757398},
abstract = {Biomedical research and clinical practice are entering a data-driven era. One of the major applications of biomedical big data research is to utilize inexpensive and unobtrusive mobile biomedical sensors and cloud computing for pervasive health monitoring. However, real-world user experiences with mobile cloud-based health monitoring were poor, due to the factors such as excessive networking latency and longer response time. On the other hand, fog computing, a newly proposed computing paradigm, utilizes a collaborative multitude of end-user clients or near-user edge devices to conduct a substantial amount of computing, storage, communication, and etc. This new computing paradigm, if successfully applied for pervasive health monitoring, has great potential to accelerate the discovery of early predictors and novel biomarkers to support smart care decision making in a connected health scenarios. In this paper, we employ a real-world pervasive health monitoring application (pervasive fall detection for stroke mitigation) to demonstrate the effectiveness and efficacy of fog computing paradigm in health monitoring. Fall is a major source of morbidity and mortality among stroke patients. Hence, detecting falls automatically and in a timely manner becomes crucial for stroke mitigation in daily life. In this paper, we set to (1) investigate and develop new fall detection algorithms and (2) design and employ a real-time fall detection system employing fog computing paradigm (e.g., distributed analytics and edge intelligence), which split the detection task between the edge devices (e.g., smartphones attached to the user) and the server (e.g., servers in the cloud). Experimental results show that distributed analytics and edge intelligence, supported by fog computing paradigm, are very promising solutions for pervasive health monitoring.},
booktitle = {Proceedings of the 2015 Workshop on Mobile Big Data},
pages = {43–48},
numpages = {6},
keywords = {fog computing, pervasive health monitoring, edge intelligence, mobile computing, distributed analytics},
location = {Hangzhou, China},
series = {Mobidata '15}
}

@inproceedings{10.1109/ASE.2019.00115,
author = {Liu, Xiao and Fan, Lingmin and Xu, Jia and Li, Xuejun and Gong, Lina and Grundy, John and Yang, Yun},
title = {FogWorkflowSim: An Automated Simulation Toolkit for Workflow Performance Evaluation in Fog Computing},
year = {2019},
isbn = {9781728125084},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE.2019.00115},
doi = {10.1109/ASE.2019.00115},
abstract = {Workflow underlies most process automation software, such as those for product lines, business processes, and scientific computing. However, current Cloud Computing based workflow systems cannot support real-time applications due to network latency, which limits their application in many IoT systems such as smart healthcare and smart traffic. Fog Computing extends the Cloud by providing virtualized computing resources close to the End Devices so that the response time of accessing computing resources can be reduced significantly. However, how to most effectively manage heterogeneous resources and different computing tasks in the Fog is a big challenge. In this paper, we introduce "FogWorkflowSim" an efficient and extensible toolkit for automatically evaluating resource and task management strategies in Fog Computing with simulated user-defined workflow applications. Specifically, FogWorkflowSim is able to: 1) automatically set up a simulated Fog Computing environment for workflow applications; 2) automatically execute user submitted workflow applications; 3) automatically evaluate and compare the performance of different computation offloading and task scheduling strategies with three basic performance metrics, including time, energy and cost. FogWorkflowSim can serve as an effective experimental platform for researchers in Fog based workflow systems as well as practitioners interested in adopting Fog Computing and workflow systems for their new software projects. (Demo video: https://youtu.be/AsMovcuSkx8)},
booktitle = {Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1114–1117},
numpages = {4},
keywords = {workflow, fog computing, simulation Toolkit, performance evaluation, task scheduling},
location = {San Diego, California},
series = {ASE '19}
}

@inproceedings{10.1145/3297280.3297402,
author = {de Santana, Cleber Jorge Lira and de Mello Alencar, Brenno and Prazeres, C\'{a}ssio V. Serafim},
title = {Reactive Microservices for the Internet of Things: A Case Study in Fog Computing},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297280.3297402},
doi = {10.1145/3297280.3297402},
abstract = {The Future Internet will be able to connect most of the objects that are not yet connected on the current Internet. The Internet of Things (IoT) is an important part of the Future Internet and involves connectivity between several physical and virtual objects, allowing the emergence of new services and applications. These intelligent objects, along with their tasks, constitute domain-specific applications (vertical markets), while ubiquitous and analytic services form independent domain services (horizontal markets). The development of these applications and services in these markets brings challenges such as deployment, scalability, integration, interoperability, mobility and performance. Recent research indicates that Microservices has been successfully applied by companies such as Netflix and SoundCloud to address some of these issues in their cloud computing applications. However, in the field of IoT, the use of Microservices to deal with these challenges still presents unresolved issues. In this paper, we present a reactive Microservices architecture and apply it in a Fog Computing case study to investigate these challenges at the edge of the network. Finally, we evaluate our proposal from the perspective of performance of Microservices provided by intelligent objects (IoT gateways) at the edge of the network.},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
pages = {1243–1251},
numpages = {9},
keywords = {reactive microservices, fog computing, architecture, IoT platform, internet of things},
location = {Limassol, Cyprus},
series = {SAC '19}
}

@inproceedings{10.1145/3240765.3240794,
author = {Otseidu, Kofi and Jia, Tianyu and Bryne, Joshua and Hargrove, Levi and Gu, Jie},
title = {Design and Optimization of Edge Computing Distributed Neural Processor for Biomedical Rehabilitation with Sensor Fusion},
year = {2018},
isbn = {9781450359504},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3240765.3240794},
doi = {10.1145/3240765.3240794},
abstract = {Modern biomedical devices use sensor fusion techniques to improve the classification accuracy of motion intent of users for rehabilitation application. The design of motion classifier observes significant challenges due to the large number of channels and stringent communication latency requirement. This paper proposes an edge-computing distributed neural processor to effectively reduce the data traffic and physical wiring congestion. A special local and global networking architecture is introduced to significantly reduce traffic among multi-chips in edge computing. To optimize the design space of the features selected, a systematic design methodology is proposed. A novel mixed-signal feature extraction approach with assistance of neural network distortion recovery is also provided to significantly reduce the silicon area. A 12-channel 55nm CMOS test chip was implemented to demonstrate the proposed systematic design methodology. The measurement shows the test chip consumes only 20uW power, more than 10,000X less power than the current clinically used microprocessor and can perform edge-computing networking operation within 5ms time.},
booktitle = {Proceedings of the International Conference on Computer-Aided Design},
articleno = {120},
numpages = {8},
keywords = {low power edge processing, inter-chip communication, mixed signal feature extraction, biomedical devices, neural network},
location = {San Diego, California},
series = {ICCAD '18}
}

@inproceedings{10.1145/3369740.3369788,
author = {Roy, Satyaki and Ghosh, Nirnay and Ghosh, Preetam and Das, Sajal K.},
title = {BioMCS: A Bio-Inspired Collaborative Data Transfer Framework over Fog Computing Platforms in Mobile Crowdsensing},
year = {2020},
isbn = {9781450377515},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3369740.3369788},
doi = {10.1145/3369740.3369788},
abstract = {Mobile crowdsensing (MCS) leverages the participation of active citizens and establishes a cost-effective sensing infrastructure using their devices. The MCS platform allocates sensing tasks, for which individual user reports are collected to enable decision making. Task sensing and communication not only consume user's device energy, but also spawn redundant data leading to network congestion and issues in data management at the platform's end. MCS, being a building block of sustainable smart city applications, must ensure judicious utilization of device energy and network resources. To address these challenges, this paper proposes a bio-inspired data transfer framework, bioMCS, deployed over a fog computing platform and capable of enforcing collaborative sensing among proximate users. bioMCS achieves energy efficiency and robustness through the topological properties of a biological network called transcriptional regulatory network. It employs collaborative sensing to further restrict device energy overhead by taking advantage of energy efficient device-to-device communications like Wi-Fi direct data transfer via group owner. We evaluate our framework through extensive simulation-based experiments and demonstrate that the bioMCS framework achieves better energy and network efficiency compared to individual user-centric data transfer mechanism.},
booktitle = {Proceedings of the 21st International Conference on Distributed Computing and Networking},
articleno = {23},
numpages = {10},
keywords = {Transcriptional regulatory network, Smart city applications, Collaborative sensing, Mobile crowdsensing, Fog computing},
location = {Kolkata, India},
series = {ICDCN 2020}
}

@inproceedings{10.1109/CHASE.2017.83,
author = {Barik, Rabindra and Dubey, Harishchandra and Sasane, Sapana and Misra, Chinmaya and Constant, Nicholas and Mankodiya, Kunal},
title = {Fog2fog: Augmenting Scalability in Fog Computing for Health GIS Systems},
year = {2017},
isbn = {9781509047215},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CHASE.2017.83},
doi = {10.1109/CHASE.2017.83},
abstract = {This study considers the situation where computational loads are transferred to edge devices and single edge device is not enough. The co-operative sensing, analysis and transmission between several edge nodes helps in enhancing scalability in Fog computing frameworks. The present study uses the positive case of malaria vector borne disease affected information from 2001-2014 of Maharashtra state, India for performance analysis.},
booktitle = {Proceedings of the Second IEEE/ACM International Conference on Connected Health: Applications, Systems and Engineering Technologies},
pages = {241–242},
numpages = {2},
location = {Philadelphia, Pennsylvania},
series = {CHASE '17}
}

@inproceedings{10.5555/3408352.3408431,
author = {Magno, Michele and Wang, Xiaying and Eggimann, Manuel and Cavigelli, Lukas and Benini, Luca},
title = {InfiniWolf: Energy Efficient Smart Bracelet for Edge Computing with Dual Source Energy Harvesting},
year = {2020},
isbn = {9783981926347},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
abstract = {This work presents InfiniWolf, a novel multi-sensor smartwatch that can achieve self-sustainability exploiting thermal and solar energy harvesting, performing computationally high demanding tasks. The smartwatch embeds both a System-on-Chip (SoC) with an ARM Cortex-M processor and Bluetooth Low Energy (BLE) and Mr. Wolf, an open-hardware RISC-V based parallel ultra-low-power processor that boosts the processing capabilities on board by more than one order of magnitude, while also increasing energy efficiency. We demonstrate its functionality based on a sample application scenario performing stress detection with multi-layer artificial neural networks on a wearable multi-sensor bracelet. Experimental results show the benefits in terms of energy efficiency and latency of Mr. Wolf over an ARM Cortex-M4F micro-controllers and the possibility, under specific assumptions, to be self-sustainable using thermal and solar energy harvesting while performing up to 24 stress classifications per minute in indoor conditions.},
booktitle = {Proceedings of the 23rd Conference on Design, Automation and Test in Europe},
pages = {342–345},
numpages = {4},
keywords = {Energy Harvesting, Biomedical Applications, Wearable devices},
location = {Grenoble, France},
series = {DATE '20}
}

@inproceedings{10.1145/3132211.3134460,
author = {Ma, Lele and Yi, Shanhe and Li, Qun},
title = {Efficient Service Handoff across Edge Servers via Docker Container Migration},
year = {2017},
isbn = {9781450350877},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3132211.3134460},
doi = {10.1145/3132211.3134460},
abstract = {Supporting smooth movement of mobile clients is important when offloading services on an edge computing platform. Interruption-free client mobility demands seamless migration of the offloading service to nearby edge servers. However, fast migration of offloading services across edge servers in a WAN environment poses significant challenges to the handoff service design. In this paper, we present a novel service handoff system which seamlessly migrates offloading services to the nearest edge server, while the mobile client is moving. Service handoff is achieved via container migration. We identify an important performance problem during Docker container migration. Based on our systematic study of container layer management and image stacking, we propose a migration method which leverages the layered storage system to reduce file system synchronization overhead, without dependence on the distributed file system. We implement a prototype system and conduct experiments using real world product applications. Evaluation results reveal that compared to state-of-the-art service handoff systems designed for edge computing platforms, our system reduces the total duration of service handoff time by 80%(56%) with network bandwidth 5Mbps(20Mbps).},
booktitle = {Proceedings of the Second ACM/IEEE Symposium on Edge Computing},
articleno = {11},
numpages = {13},
keywords = {offloading services, edge computing, docker migration, union file system},
location = {San Jose, California},
series = {SEC '17}
}

@inproceedings{10.1145/3154273.3154347,
author = {Mahmud, Redowan and Koch, Fernando Luiz and Buyya, Rajkumar},
title = {Cloud-Fog Interoperability in IoT-Enabled Healthcare Solutions},
year = {2018},
isbn = {9781450363723},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3154273.3154347},
doi = {10.1145/3154273.3154347},
abstract = {The issue of utilizing Internet of Things (IoT) in Healthcare solutions relates to the problems of latency sensitivity, uneven data load, diverse user expectations and heterogeneity of the applications. Current explorations consider Cloud Computing as the base stone to create IoT-Enable solution. Nonetheless, this environment entails limitations in terms of multi-hop distance from the data source, geographical centralized architecture, economical aspects, etc. To address these limitations, there is a surge of solutions that apply Fog Computing as an approach to bring computing resources closer to the data sources. This approach is being fomented by the growing availability of powerful edge computing at lower cost and commercial developments in the area. Nonetheless, the implementation of Cloud-Fog interoperability and integration implies in complex coordination of applications and services and the demand for intelligent service orchestrations so that solutions can make the best use of distributed resources without compromising stability, quality of services, and security. In this paper, we introduce a Fog-based IoT-Healthcare solution structure and explore the integration of Cloud-Fog services in interoperable Healthcare solutions extended upon the traditional Cloud-based structure. The scenarios are evaluated through simulations using the iFogSim simulator and the results analyzed in relation to distributed computing, reduction of latency, optimization of data communication, and power consumption. The experimental results point towards improvement in instance cost, network delay and energy usage.},
booktitle = {Proceedings of the 19th International Conference on Distributed Computing and Networking},
articleno = {32},
numpages = {10},
keywords = {Cloud computing, HealthCare, Interoperable architecture, Internet of Things, Fog computing},
location = {Varanasi, India},
series = {ICDCN '18}
}

@inproceedings{10.1145/3132211.3134456,
author = {Drolia, Utsav and Guo, Katherine and Narasimhan, Priya},
title = {Precog: <u>P</u>Refetching for Image <u>Recog</u>Nition Applications at the Edge},
year = {2017},
isbn = {9781450350877},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3132211.3134456},
doi = {10.1145/3132211.3134456},
abstract = {Image recognition applications are on the rise. Increasingly, applications on edge devices such as mobile smartphones, drones and cars, are relying on recognition techniques to provide interactive and intelligent functionality. Given the complexity of these techniques, and resource constrained nature of edge devices, applications rely on offloading compute intensive recognition tasks to the cloud. This has also lead to the rise of cloud-based recognition services. This involves sending captured images to remote servers across the Internet, which leads to slower responses. With the rising numbers of edge devices, both, the network and such centralized cloud-based solutions, are likely to be under stress, and lead to further slower responses. To reduce the recognition latency, and provide better scalability to the cloud-based solutions, we propose Precog. Precog employs selective computation on the devices to reduce the need to offload images to the cloud. In coordination with edge servers, it uses prediction to prefetch parts of the trained classifiers used for recognition onto the devices, and uses these smaller models to accelerate recognition on devices. Our evaluation shows that Precog can reduce latency by up to 5\texttimes{}, better utilize edge and cloud resources and also increase accuracy. We believe that Precog is the first system to use devices and edge servers collaboratively to enable prefetching and caching on the devices, and drive down recognition latency for mobile applications.},
booktitle = {Proceedings of the Second ACM/IEEE Symposium on Edge Computing},
articleno = {17},
numpages = {13},
keywords = {machine learning, mobile, prefetching, image recognition, edge computing, caching},
location = {San Jose, California},
series = {SEC '17}
}

@inproceedings{10.1145/3318216.3363308,
author = {Wang, Junjue and Feng, Ziqiang and George, Shilpa and Iyengar, Roger and Pillai, Padmanabhan and Satyanarayanan, Mahadev},
title = {Towards Scalable Edge-Native Applications},
year = {2019},
isbn = {9781450367332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3318216.3363308},
doi = {10.1145/3318216.3363308},
abstract = {Latency-sensitive edge-native applications may be the key to commercial success of edge infrastructure. However, success in the form of widespread deployment of such applications poses its own challenges. These applications are edge-dependent by definition, and therefore cannot simply fail over to the cloud if the edge is overloaded. In this paper, we propose an adaptation-based strategy to allow scaling up the number of concurrent edge-native applications on a resource-limited cloudlet and wireless network. We demonstrate up to 40% reduction in offered load with minimal impact on latency on a variety of cognitive assistance tasks over non-adaptive approaches. Our approach is able to gracefully degrade and maintain quality of service for a subset of applications in the face of severely loaded conditions.},
booktitle = {Proceedings of the 4th ACM/IEEE Symposium on Edge Computing},
pages = {152–165},
numpages = {14},
keywords = {cloudlet, mobile computing, wearable cognitive assistance, gabriel, edge computing, resource management},
location = {Arlington, Virginia},
series = {SEC '19}
}

@inproceedings{10.1145/3323679.3326509,
author = {Kamran, Khashayar and Yeh, Edmund and Ma, Qian},
title = {DECO: Joint Computation, Caching and Forwarding in Data-Centric Computing Networks},
year = {2019},
isbn = {9781450367646},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3323679.3326509},
doi = {10.1145/3323679.3326509},
abstract = {The emergence of IoT devices and the predicted increase in the number of data-driven and delay-sensitive applications highlight the importance of dispersed computing platforms (e.g. edge computing and fog computing) that can intelligently manage in-network computation and data placement. In this paper, we propose the DECO (Data-cEntric COmputation) framework for joint computation, caching, and request forwarding in data-centric computing networks. DECO utilizes a virtual control plane which operates on the demand rates for computation and data, and an actual plane which handles computation requests, data requests, data objects and computation results in the physical network. We present a throughput optimal policy within the virtual plane, and use it as a basis for adaptive and distributed computation, caching, and request forwarding in the actual plane. We demonstrate the superior performance of the DECO policy in terms of request satisfaction delay as compared with several baseline policies, through extensive numerical simulations over multiple network topologies.},
booktitle = {Proceedings of the Twentieth ACM International Symposium on Mobile Ad Hoc Networking and Computing},
pages = {111–120},
numpages = {10},
keywords = {data-intensive computing, Distributed computing networks, data-centric computing, caching, mobile edge computing, fog computing},
location = {Catania, Italy},
series = {Mobihoc '19}
}

@article{10.1145/3266142,
author = {Concone, Federico and Re, Giuseppe Lo and Morana, Marco},
title = {A Fog-Based Application for Human Activity Recognition Using Personal Smart Devices},
year = {2019},
issue_date = {April 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {2},
issn = {1533-5399},
url = {https://doi.org/10.1145/3266142},
doi = {10.1145/3266142},
abstract = {The diffusion of heterogeneous smart devices capable of capturing and analysing data about users, and/or the environment, has encouraged the growth of novel sensing methodologies. One of the most attractive scenarios in which such devices, such as smartphones, tablet computers, or activity trackers, can be exploited to infer relevant information is human activity recognition (HAR). Even though some simple HAR techniques can be directly implemented on mobile devices, in some cases, such as when complex activities need to be analysed timely, users’ smart devices can operate as part of a more complex architecture. In this article, we propose a multi-device HAR framework that exploits the fog computing paradigm to move heavy computation from the sensing layer to intermediate devices and then to the cloud. As compared to traditional cloud-based solutions, this choice allows to overcome processing and storage limitations of wearable devices while also reducing the overall bandwidth consumption. Experimental analysis aims to evaluate the performance of the entire platform in terms of accuracy of the recognition process while also highlighting the benefits it might bring in smart environments.},
journal = {ACM Trans. Internet Technol.},
month = mar,
articleno = {20},
numpages = {20},
keywords = {fog computing, Human activity recognition, mobile crowdsensing}
}

@inproceedings{10.1145/3302516.3307356,
author = {Kim, Bongjun and Heo, Seonyeong and Lee, Gyeongmin and Song, Seungbin and Kim, Jong and Kim, Hanjun},
title = {Spinal Code: Automatic Code Extraction for near-User Computation in Fogs},
year = {2019},
isbn = {9781450362771},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3302516.3307356},
doi = {10.1145/3302516.3307356},
abstract = {In the Internet of Things (IoT) environments, cloud servers integrate various IoT devices including sensors and actuators, and provide new services that assist daily lives of users interacting with the physical world. While response time is a crucial factor of quality of the services, supporting short response time is challenging for the cloud servers due to a growing number and amount of connected devices and their communication. To reduce the burden of the cloud servers, fog computing is a promising alternative to offload computation and communication overheads from the cloud servers to fog nodes. However, since existing fog computing frameworks do not extract codes for fog nodes fully automatically, programmers should manually write and analyze their applications for fog computing. This work proposes Spinal Code, a new compiler-runtime framework for near-user computation that automatically partitions an original cloud-centric program into distributed sub-programs running over the cloud and fog nodes. Moreover, to reduce response time in the physical world, Spinal Code allows programmers to annotate latency sensitive actuators in a program, and optimizes the critical paths from required sensors to the actuators when it generates the sub-programs. This work implements 9 IoT programs across 4 service domains: healthcare, smart home, smart building and smart factory, and demonstrates that Spinal Code successfully reduces 44.3% of response time and 79.9% of communication on the cloud compared with a cloud-centric model.},
booktitle = {Proceedings of the 28th International Conference on Compiler Construction},
pages = {87–98},
numpages = {12},
keywords = {Fog Computing, IoT, Internet of Things},
location = {Washington, DC, USA},
series = {CC 2019}
}

@inproceedings{10.1145/3404397.3404410,
author = {Guo, Yeting and Liu, Fang and Cai, Zhiping and Chen, Li and Xiao, Nong},
title = {FEEL: A Federated Edge Learning System for Efficient and Privacy-Preserving Mobile Healthcare},
year = {2020},
isbn = {9781450388160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3404397.3404410},
doi = {10.1145/3404397.3404410},
abstract = {With the prosperity of artificial intelligence, neural networks have been increasingly applied in healthcare for a variety of tasks for medical diagnosis and disease prevention. Mobile wearable devices, widely adopted by hospitals and health organizations, serve as emerging sources of medical data and participate in the training of neural network models for accurate model inference. Since the medical data are privacy-sensitive and non-shareable, federated learning has been proposed to train a model across decentralized data, which involves each mobile device running a training task with its own data in parallel. However, due to the ever-increasing size and complexity of modern neural network models, it becomes inefficient, and may even infeasible, to perform training tasks on wearable devices that are resource-constrained. In this paper, we propose a FEderated Edge Learning system, FEEL, for efficient privacy-preserving mobile healthcare. Specifically, we design an edge-based training task offloading strategy to improve the training efficiency. Further, we build our system on the basis of federated learning to make use of distributed user data to improve the inference performance. In addition, during model training, we provide a differential privacy scheme to strengthen the privacy protection. A prototype system has been implemented to evaluate the training efficiency, inference performance and noise sensitivity, respectively. And the results have demonstrated that our proposal could train models in an efficient and privacy-preserving way.},
booktitle = {49th International Conference on Parallel Processing - ICPP},
articleno = {9},
numpages = {11},
keywords = {federated learning, edge computing, differential privacy},
location = {Edmonton, AB, Canada},
series = {ICPP '20}
}

@inproceedings{10.1145/3277893.3277899,
author = {Dey, Swarnava and Mukherjee, Arijit and Pal, Arpan and Balamuralidhar, P.},
title = {Partitioning of CNN Models for Execution on Fog Devices},
year = {2018},
isbn = {9781450360517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3277893.3277899},
doi = {10.1145/3277893.3277899},
abstract = {Fog Computing has in recent times captured the imagination of industrial and research organizations working on various aspects of connected livelihood and governance of smart cities. Improvements in deep neural networks imply extensive use of such models for analytics and inferencing on large volume of data, including sensor observations, images, speech. A growing need for such inferencing to be run on devices closer to the data sources, i.e. devices which reside at the edge of the network, popularly known as fog devices exists, in order to reduce the upstream network traffic. However, being computationally constrained in nature, executing complex deep inferencing models on such devices has been proved difficult. This has led to several new approaches to partition/distribute the computation and/or data over multiple fog devices. In this paper we propose a novel depth-wise input partitioning scheme for CNN models and experimentally prove that it achieves better performance compared to row/column or grid based schemes.},
booktitle = {Proceedings of the 1st ACM International Workshop on Smart Cities and Fog Computing},
pages = {19–24},
numpages = {6},
keywords = {parallel, DCNN, Fog, CNN, Edge, convolution, Cloud, distributed},
location = {Shenzhen, China},
series = {CitiFog'18}
}

@article{10.1145/3341104,
author = {Tang, Wenjuan and Ren, Ju and Zhang, Kuan and Zhang, Deyu and Zhang, Yaoxue and Shen, Xuemin (Sherman)},
title = {Efficient and Privacy-Preserving Fog-Assisted Health Data Sharing Scheme},
year = {2019},
issue_date = {December 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {6},
issn = {2157-6904},
url = {https://doi.org/10.1145/3341104},
doi = {10.1145/3341104},
abstract = {Pervasive data collected from e-healthcare devices possess significant medical value through data sharing with professional healthcare service providers. However, health data sharing poses several security issues, such as access control and privacy leakage, as well as faces critical challenges to obtain efficient data analysis and services. In this article, we propose an efficient and privacy-preserving fog-assisted health data sharing (PFHDS) scheme for e-healthcare systems. Specifically, we integrate the fog node to classify the shared data into different categories according to disease risks for efficient health data analysis. Meanwhile, we design an enhanced attribute-based encryption method through combination of a personal access policy on patients and a professional access policy on the fog node for effective medical service provision. Furthermore, we achieve significant encryption consumption reduction for patients by offloading a portion of the computation and storage burden from patients to the fog node. Security discussions show that PFHDS realizes data confidentiality and fine-grained access control with collusion resistance. Performance evaluations demonstrate cost-efficient encryption computation, storage and energy consumption.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = oct,
articleno = {68},
numpages = {23},
keywords = {Fog computing, data sharing, privacy-preservation, e-healthcare, access control}
}

@inproceedings{10.1145/3318216.3363303,
author = {Hu, Bo and Hu, Wenjun},
title = {LinkShare: Device-Centric Control for Concurrent and Continuous Mobile-Cloud Interactions},
year = {2019},
isbn = {9781450367332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3318216.3363303},
doi = {10.1145/3318216.3363303},
abstract = {Mobile applications have become increasingly sophisticated. Emerging cognitive assistance applications can involve multiple computationally intensive modules working continuously and concurrently, further straining the already limited resources on these mobile devices. While computation offloading to the edge or the cloud is still the de facto solution, existing approaches are limited by intra-application operations only or edge-/cloud-centric scheduling. Instead, we argue that operating system level coordination is needed on the mobile side to adequately support the prospects of multi-application offloading. Specifically, both the local mobile system resource and the network bandwidth to reach the cloud need to be allocated intelligently among concurrent offloading jobs.In this paper, we build a system-level scheduler service, LinkShare, that wraps over the operating system scheduler to coordinate among multiple offloading requests. We further study the scheduling requirements and suitable metrics, and find that the most intuitive approaches of minimizing the end-to-end processing time or earliest-deadline first scheduling do not work well. Instead, LinkShare adopts earliest-deadline first with limited sharing (EDF-LS), that balances real-time requirements and fairness. Extensive evaluation of an Android implementation of LinkShare shows that adding this additional scheduler is essential, and that EDF-LS reduces the deadline miss events by up to 30% compared to the baseline.},
booktitle = {Proceedings of the 4th ACM/IEEE Symposium on Edge Computing},
pages = {15–29},
numpages = {15},
location = {Arlington, Virginia},
series = {SEC '19}
}

@inproceedings{10.1145/3363347.3363366,
author = {Yousefpour, Ashkan and Devic, Siddartha and Nguyen, Brian Q. and Kreidieh, Aboudy and Liao, Alan and Bayen, Alexandre M. and Jue, Jason P.},
title = {Guardians of the Deep Fog: Failure-Resilient DNN Inference from Edge to Cloud},
year = {2019},
isbn = {9781450370134},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3363347.3363366},
doi = {10.1145/3363347.3363366},
abstract = {Partitioning and distributing deep neural networks (DNNs) over physical nodes such as edge, fog, or cloud nodes, could enhance sensor fusion, and reduce bandwidth and inference latency. However, when a DNN is distributed over physical nodes, failure of the physical nodes causes the failure of the DNN units that are placed on these nodes. The performance of the inference task will be unpredictable, and most likely, poor, if the distributed DNN is not specifically designed and properly trained for failures. Motivated by this, we introduce deepFogGuard, a DNN architecture augmentation scheme for making the distributed DNN inference task failure-resilient. To articulate deepFogGuard, we introduce the elements and a model for the resiliency of distributed DNN inference. Inspired by the concept of residual connections in DNNs, we introduce skip hyperconnections in distributed DNNs, which are the basis of deepFogGuard's design to provide resiliency. Next, our extensive experiments using two existing datasets for the sensing and vision applications confirm the ability of deepFogGuard to provide resiliency for distributed DNNs in edge-cloud networks.},
booktitle = {Proceedings of the First International Workshop on Challenges in Artificial Intelligence and Machine Learning for Internet of Things},
pages = {25–31},
numpages = {7},
keywords = {Resiliency, Robust, Fog Computing, Edge Computing, Distributed DNN Inference, Distributed Neural Networks, Reliability},
location = {New York, NY, USA},
series = {AIChallengeIoT'19}
}

@inproceedings{10.1145/3335484.3335532,
author = {Li, Ruide and Gao, Guohua and Liang, Yingjie and Zhang, Xin and Liao, Yongqiang},
title = {An AR Based Edge Maintenance Architecture and Maintenance Knowledge Push Algorithm for Communication Networks},
year = {2019},
isbn = {9781450362788},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3335484.3335532},
doi = {10.1145/3335484.3335532},
abstract = {Maintenance is an important aspect of the entire life cycle of communication network devices. The existing maintenance environment of the communication network is complex, with various types of equipment components and complicated structures. The quality of maintenance is greatly affected by the ability and experience of on-site maintenance personnel, and the maintenance cost is high, and the efficiency is low. In order to decrease the difficulty of on-site maintenance and improve maintenance efficiency and quality, we proposed an augmented reality (AR) based edge maintenance architecture. Moreover, we propose a context model-based maintenance knowledge push algorithm (CMKP) to help on-site maintenance personnel obtain auxiliary information. This will provide on-site maintenance personnel with intelligent assistance and improve overall maintenance efficiency.},
booktitle = {Proceedings of the 2019 4th International Conference on Big Data and Computing},
pages = {165–168},
numpages = {4},
keywords = {Internet of Things, Maintenance, Augmented Reality, Smart Wearable Devices, Communication Network, Edge Computing},
location = {Guangzhou, China},
series = {ICBDC 2019}
}

@inproceedings{10.1145/3318216.3363378,
author = {Xylomenos, George and Zafeiratos, Evangelos and Prokopakis, Marios},
title = {Keyword-Based Information Retrieval for the WoT},
year = {2019},
isbn = {9781450367332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3318216.3363378},
doi = {10.1145/3318216.3363378},
abstract = {The Internet of Things (IoT) is expected to contain huge numbers of "things" producing vast amounts of information. To turn these raw data to useful services for the Web of Things (WoT), we have previously proposed KIOT, a keyword-based scheme for gathering and processing IoT information using Information-Centric Networking (ICN) techniques. In KIOT data items, such as sensor readings, can be named with arbitrary sets of keywords, while users can retrieve all data items matching a desired set of keywords and (optionally) process them with arbitrary functions. In this paper we focus on a prototype implementation of the data retrieval part of KIOT. To maximize flexibility in diverse settings, our implementation automatically configures the network and its routing tables, allowing arbitrary sets of keywords to be used for both data items and queries. Our implementation can be used on any IoT device supporting Java, and is also available for large scale testing over emulated networks using Mininet.},
booktitle = {Proceedings of the 4th ACM/IEEE Symposium on Edge Computing},
pages = {407–412},
numpages = {6},
keywords = {NDN, KIOT, IoT, WoT, ICN},
location = {Arlington, Virginia},
series = {SEC '19}
}

@inproceedings{10.1145/3368235.3368848,
author = {Chegini, Hossein and Mahanti, Aniket},
title = {A Framework of Automation on Context-Aware Internet of Things (IoT) Systems},
year = {2019},
isbn = {9781450370448},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368235.3368848},
doi = {10.1145/3368235.3368848},
abstract = {An ever-increasing number of different types of objects are connecting to the Internet, and this phenomenon is called the Internet of Things(IoT). Processing the IoT generated data by Cloud Computing causes high latency. Fog Computing is a new motivation for resolving the latency issue, which is a hosting environment between the IoT and the Cloud layers. IoT applications are faced with three significant challenges: big data, device heterogeneity, and Fog resiliency. With the motivation of resolving the challenges, this proposal introduces a Microservice software framework for implementing automatic functions in the IoT-Fog-Cloud ecosystem. The proposed Microservice framework will also enable the development of IoT-based context-aware intelligent decision-making systems. We describe the functionality and contribution of each automatic function in the paper.},
booktitle = {Proceedings of the 12th IEEE/ACM International Conference on Utility and Cloud Computing Companion},
pages = {157–162},
numpages = {6},
keywords = {machine-to-machine(m2m), complex event processing, iot, cloud computing, fog computing, microservice, automation, context-aware system},
location = {Auckland, New Zealand},
series = {UCC '19 Companion}
}

@inproceedings{10.1145/3264844.3264848,
author = {Aazam, Mohammad and Harras, Khaled A. and Elgazar, Ali E.},
title = {Delay Tolerant Computing: The Untapped Potential},
year = {2018},
isbn = {9781450359269},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3264844.3264848},
doi = {10.1145/3264844.3264848},
abstract = {The digital world is expanding rapidly and advances in networking technologies such as wireless broadband (WiBro), low-power wide area networks (LPWANs), 4G/5G, LiFi, and so on, are paving the way for the emergence of sophisticated services. The number of online and mobile applications leveraging sophisticated smart devices are increasing in complexity requiring more computation and communication. While current smart phones and other IoT devices are becoming more powerful, the support gap is widening when compared to the demand of current and future compute-intensive tasks such as those often required for smart health care, ambient assisted living (AAL), virtual/augmented reality, intelligent vehicular communication, and so on. For many of these applications, computational or data storage tasks can not be entirely performed locally and have thus exploited different offloading techniques. The focus in such techniques has traditionally been on minimizing delay when supporting such applications. In this paper, we argue for the opportunity to tap into idle compute resources to support another dimension of applications characterized with high task demand, but can tolerate larger delays. We present delay tolerant computing (DTC) paradigm, and define where it falls within the compute ecosystem. We highlight the potential behind DTC with various applications, and propose a generalized architecture for how this paradigm can be realized. Finally, we show, using a couple of case studies, the potential behind DTC when compared to other compute paradigms by providing preliminary experimental results based on monetary cost, computational requirements, and delay.},
booktitle = {Proceedings of the 13th Workshop on Challenged Networks},
pages = {33–38},
numpages = {6},
keywords = {femto cloud, cloud computing, offloading, edge computing, fog computing, delay tolerant computing},
location = {New Delhi, India},
series = {CHANTS '18}
}

@inproceedings{10.1145/3127540.3127547,
author = {Bao, Wei and Li, Wei and Delicato, Flavia C. and Pires, Paulo F. and Yuan, Dong and Zhou, Bing Bing and Zomaya, Albert Y.},
title = {Cost-Effective Processing in Fog-Integrated Internet of Things Ecosystems},
year = {2017},
isbn = {9781450351621},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3127540.3127547},
doi = {10.1145/3127540.3127547},
abstract = {The emerging Internet of Things (IoT) paradigm creates a growing need to analyze a significant amount of data produced by the interconnected IoT devices. Since IoT devices have limited computation capabilities, Fog Computing is a natural complement, to provide distributed, location-aware, and easy-to-access computation resources. In this work, we address the problem of application processing and data offloading in a Fog-integrated IoT ecosystem. By leveraging the Lyapunov optimization technique, we design an online and distributed system control policy called the Distributed Weighted Backpressure (DWB) policy that asymptotically minimizes the cost of IoT devices. A three-way tradeoff among queue backlogs, communication cost, and computation cost is then investigated. Finally, simulation study has been conducted to validate the correctness and usefulness of the proposed DWB policy.},
booktitle = {Proceedings of the 20th ACM International Conference on Modelling, Analysis and Simulation of Wireless and Mobile Systems},
pages = {99–108},
numpages = {10},
keywords = {fog computing, data processing, stochastic optimization., internet of things},
location = {Miami, Florida, USA},
series = {MSWiM '17}
}

@inproceedings{10.1145/3132211.3134462,
author = {Kar, Gorkem and Jain, Shubham and Gruteser, Marco and Chen, Jinzhu and Bai, Fan and Govindan, Ramesh},
title = {PredriveID: Pre-Trip Driver Identification from in-Vehicle Data},
year = {2017},
isbn = {9781450350877},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3132211.3134462},
doi = {10.1145/3132211.3134462},
abstract = {This paper explores the minimal dataset necessary at vehicular edge nodes, to effectively differentiate drivers using data from existing in-vehicle sensors. This facilitates novel personalization, insurance, advertising, and security applications but can also help in understanding the privacy sensitivity of such data. Existing work on differentiating drivers largely relies on devices that drivers carry, or on the locations that drivers visit to distinguish drivers. Internally, however, the vehicle processes a much richer set of sensor information that is becoming increasingly available to external services. To explore how easily drivers can be distinguished from such data, we consider a system that interfaces to the vehicle bus and executes supervised or unsupervised driver differentiation techniques on this data. To facilitate this analysis and to evaluate the system, we collect in-vehicle data from 24 drivers on a controlled campus test route, as well as 480 trips over three weeks from five shared university mail vans. We also conduct studies between members of a family. The results show that driver differentiation does not require longer sequences of driving telemetry data but can be accomplished with 91% accuracy within 20s after the driver enters the vehicle, usually even before the vehicle starts moving.},
booktitle = {Proceedings of the Second ACM/IEEE Symposium on Edge Computing},
articleno = {2},
numpages = {12},
keywords = {driving telemetry data, on-board diagnostics, vehicular sensing},
location = {San Jose, California},
series = {SEC '17}
}

@inproceedings{10.1145/3318216.3363380,
author = {Kang, Kyoung Don},
title = {Towards Efficient Real-Time Decision Support at the Edge},
year = {2019},
isbn = {9781450367332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3318216.3363380},
doi = {10.1145/3318216.3363380},
abstract = {In the emerging Internet of Things (IoT) paradigm, the need for real-time decision support is increasing fast to support key applications, such as smart health, disaster recovery, or battlefield monitoring. In these applications, it is essential to efficiently retrieve fresh sensor data and process them in a timely manner to aid in decision making. However, related work is relatively scarce. In this paper, we formulate the problem of real-time decision support and explore a suite of scheduling methodologies to efficiently retrieve and process sensor data for real-time decision support subject to timing and data freshness constraints at the network edge and discuss open research issues.},
booktitle = {Proceedings of the 4th ACM/IEEE Symposium on Edge Computing},
pages = {419–424},
numpages = {6},
keywords = {data freshness, internet of things, task deadlines, real-time decision support, web of things},
location = {Arlington, Virginia},
series = {SEC '19}
}

@inproceedings{10.1145/3018896.3056808,
author = {Parkinson, Simon and Qin, Yongrui and Khan, Saad and Vallati, Mauro},
title = {Security Auditing in the Fog},
year = {2017},
isbn = {9781450347747},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3018896.3056808},
doi = {10.1145/3018896.3056808},
abstract = {Technology specific expert knowledge is often required to analyse security configurations and determine potential vulnerabilities, but it becomes difficult when it is a new technology such as Fog computing. Furthermore, additional knowledge is also required regarding how the security configuration has been constructed in respect to an organisation's security policies. Traditionally, organisations will often manage their access control permissions relative to their employees needs, posing challenges to administrators. This problem is even exacerbated in Fog computing systems where security configurations are implemented on a large amount of devices at the edges of Internet, and the administrators are required to retain adequate knowledge on how to perform complex administrative tasks. In this paper, a novel approach of translating object-based security configurations in to a graph model is presented. A technique is then developed to autonomously identify vulnerabilities and perform security auditing of large systems without the need for expert knowledge. Throughout the paper, access control configuration data is used as a case study, and empirical analysis is performed on synthetically generated access control permissions.},
booktitle = {Proceedings of the Second International Conference on Internet of Things, Data and Cloud Computing},
articleno = {191},
numpages = {9},
keywords = {fog computing, graph-based anomaly detection, security auditing, synthetic data sets},
location = {Cambridge, United Kingdom},
series = {ICC '17}
}

@inproceedings{10.1145/3366030.3366055,
author = {Dehury, Chinmaya Kumar and Srirama, Satish Narayana},
title = {Personalized Service Delivery Using Reinforcement Learning in Fog and Cloud Environment},
year = {2019},
isbn = {9781450371797},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366030.3366055},
doi = {10.1145/3366030.3366055},
abstract = {The ability to fulfil the resource demand in runtime is encouraging the businesses to migrate to cloud. Recently, to provide real-time cloud services and to save network resources, fog computing is introduced. To further improve the quality of service in delivery process, Artificial Intelligence is being applied extensively. However, the state-of-the-art in this regard is still immature as it mainly focuses at either fog or cloud. To address this issue, a novel reinforcement learning-based personalized service delivery (RLPSD) mechanism is proposed in this paper, which allows the service provider to combine the fog and cloud environments, while providing the service. RLPSD distributes the user's service requests between fog and cloud, considering the users' constraints (e.g. the distance from fog), thus resulting in personalized service delivery. The proposed RLPSD algorithm is implemented and evaluated in terms of its success rate, percentage of service requests' distribution, learning rate, discount factor, etc.},
booktitle = {Proceedings of the 21st International Conference on Information Integration and Web-Based Applications &amp; Services},
pages = {522–529},
numpages = {8},
keywords = {cloud computing, fog computing, Q-learn algorithm, service delivery, Reinforcement learning},
location = {Munich, Germany},
series = {iiWAS2019}
}

@article{10.1145/3356468,
author = {Li, Jin and Li, Tong and Liu, Zheli and Chen, Xiaofeng},
title = {Secure Deduplication System with Active Key Update and Its Application in IoT},
year = {2019},
issue_date = {December 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {6},
issn = {2157-6904},
url = {https://doi.org/10.1145/3356468},
doi = {10.1145/3356468},
abstract = {The rich cloud services in the Internet of Things create certain needs for edge computing, in which devices should be able to handle storage tasks securely, reliably, and efficiently. When processing the storage requests from edge devices, each cloud server is supposed to eliminate duplicate copies of repeating data to reduce the amount of storage space and save on bandwidth. To protect data confidentiality while supporting deduplication, some convergent-encryption-based techniques have been proposed to encrypt the data before uploading. However, all these works cannot meet two requirements while preventing brute-force attacks: (i) power-constrained edge nodes should update encryption keys efficiently when an edge node is abandoned; and (ii) the access privacy of edge nodes should be guaranteed. In this article, we propose a novel encryption scheme for secure chunk-level deduplication. Based on this scheme, we present two constructions of the secure deduplication system that support an efficient key update protocol. The key update protocol does not involve any edge node in computational tasks, so that the deduplication system can adopt an active key update strategy. Moreover, one of our constructions, which is called advance construction, can provide access privacy assurances for edge nodes. The security analysis is given in terms of the proposed threat model. The experimental analysis demonstrates that the proposed deduplication system is practical.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = oct,
articleno = {69},
numpages = {21},
keywords = {Deduplication, convergent encryption, key update, edge computing}
}

@inbook{10.1145/3419604.3419757,
author = {Essalhi, Salah Eddine and El Fenni, Mohammed Raiss and Chafnaji, Houda},
title = {Smart Energy Management for Fog-Enabled IoT Network},
year = {2020},
isbn = {9781450377331},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3419604.3419757},
abstract = {The Internet of Things (IoT) is a paradigm that continues to stir the curiosity of the scientific community, which has been the subject of several research studies in recent years. Formed by a very large number of connected devices, IoT applications generate a huge amount of data to be processed and analyzed taking into account the constraints of latency and energy. Fog computing has proven to be an efficient way to provide computing, management and storage resources through small distributed data centers located at the edge of the network, as close as possible to end-users and connected devices, offering accordingly reduced latency and energy saving. In this context, energy efficiency is one of the parameters that must be emphasized in order to cope with the increased consumption of energy associated with this gigantic volume of data. The proposed work presents a new approach based on a Fog-IoT architecture with the objective of ensuring smart energy management during communication and processing of offloaded tasks in IoT applications while respecting the latency constraint. Experimental results attests the effectiveness of the proposed approach in terms of energy efficiency.},
booktitle = {Proceedings of the 13th International Conference on Intelligent Systems: Theories and Applications},
articleno = {43},
numpages = {6}
}

@article{10.1145/3284554,
author = {Ferretti, Luca and Marchetti, Mirco and Colajanni, Michele},
title = {Fog-Based Secure Communications for Low-Power IoT Devices},
year = {2019},
issue_date = {April 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {2},
issn = {1533-5399},
url = {https://doi.org/10.1145/3284554},
doi = {10.1145/3284554},
abstract = {Designing secure, scalable, and resilient IoT networks is a challenging task because of resource-constrained devices and no guarantees of reliable network connectivity. Fog computing improves the resiliency of IoT, but its security model assumes that fog nodes are fully trusted. We relax this latter constraint by proposing a solution that guarantees confidentiality of messages exchanged through semi-honest fog nodes thanks to a lightweight proxy re-encryption scheme. We demonstrate the feasibility of the solution by applying it to IoT networks of low-power devices through experiments on microcontrollers and ARM-based architectures.},
journal = {ACM Trans. Internet Technol.},
month = mar,
articleno = {27},
numpages = {21},
keywords = {publish/subscribe, authorization, encryption, proxy re-encryption, Security, secure communications, fog computing, confidentiality, Internet-of-things}
}

@article{10.1145/3306147,
author = {Bhargava, Kriti and Ivanov, Stepan and McSweeney, Diarmuid and Donnelly, William},
title = {Leveraging Fog Analytics for Context-Aware Sensing in Cooperative Wireless Sensor Networks},
year = {2019},
issue_date = {April 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {1550-4859},
url = {https://doi.org/10.1145/3306147},
doi = {10.1145/3306147},
abstract = {In this article, we present a fog computing technique for real-time activity recognition and localization on-board wearable Internet of Things(IoT) devices. Our technique makes joint use of two light-weight analytic methods—Iterative Edge Mining(IEM) and Cooperative Activity Sequence-based Map Matching(CASMM). IEM is a decision-tree classifier that uses acceleration data to estimate the activity state. The sequence of activities generated by IEM is analyzed by the CASMM method for identifying the location. The CASMM method uses cooperation between devices to improve accuracy of classification and then performs map matching to identify the location. We evaluate the performance of our approach for activity recognition and localization of animals. The evaluation is performed using real-world acceleration data of cows collected during a pilot study at a Dairygold-sponsored farm in Kilworth, Ireland. The analysis shows that our approach can achieve a localization accuracy of up to 99%. In addition, we exploit the location-awareness of devices and present an event-driven communication approach to transmit data from the IoT devices to the cloud. The delay-tolerant communication facilitates context-aware sensing and significantly improves energy profile of the devices. Furthermore, an array-based implementation of IEM is discussed, and resource assessment is performed to verify its suitability for device-based implementation.},
journal = {ACM Trans. Sen. Netw.},
month = mar,
articleno = {23},
numpages = {35},
keywords = {edge mining, precision farming, Fog computing, testbeds, cooperative wireless sensor network, localization}
}

@inproceedings{10.1145/3318216.3363312,
author = {Zhou, Li and Samavatian, Mohammad Hossein and Bacha, Anys and Majumdar, Saikat and Teodorescu, Radu},
title = {Adaptive Parallel Execution of Deep Neural Networks on Heterogeneous Edge Devices},
year = {2019},
isbn = {9781450367332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3318216.3363312},
doi = {10.1145/3318216.3363312},
abstract = {New applications such as smart homes, smart cities, and autonomous vehicles are driving an increased interest in deploying machine learning on edge devices. Unfortunately, deploying deep neural networks (DNNs) on resource-constrained devices presents significant challenges. These workloads are computationally intensive and often require cloud-like resources. Prior solutions attempted to address these challenges by either introducing more design efforts or by relying on cloud resources for assistance.In this paper, we propose a runtime adaptive convolutional neural network (CNN) acceleration framework that is optimized for heterogeneous Internet of Things (IoT) environments. The framework leverages spatial partitioning techniques through fusion of the convolution layers and dynamically selects the optimal degree of parallelism according to the availability of computational resources, as well as network conditions. Our evaluation shows that our framework outperforms state-of-art approaches by improving the inference speed and reducing communication costs while running on wirelessly-connected Raspberry-Pi3 devices. Experimental evaluation shows up to 1.9x ~ 3.7x speedup using 8 devices for three popular CNN models.},
booktitle = {Proceedings of the 4th ACM/IEEE Symposium on Edge Computing},
pages = {195–208},
numpages = {14},
keywords = {parallel execution, edge devices, deep learning, inference},
location = {Arlington, Virginia},
series = {SEC '19}
}

@inproceedings{10.1109/CCGRID.2018.00052,
author = {Al-Jaroodi, Jameela and Mohamed, Nader},
title = {Service-Oriented Architecture for Big Data Analytics in Smart Cities},
year = {2018},
isbn = {9781538658154},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CCGRID.2018.00052},
doi = {10.1109/CCGRID.2018.00052},
abstract = {A smart city has recently become an aspiration for many cities around the world. These cities are looking to apply the smart city concept to improve sustainability, quality of life for residents, and economic development. The smart city concept depends on employing a wide range of advanced technologies to improve the performance of various services and activities such as transportation, energy, healthcare, and education, while at the same time improve the city's resources utilization and initiate new business opportunities. One of the promising technologies to support such efforts is the big data technology. Effective and intelligent use of big data accumulated over time in various sectors can offer many advantages to enhance decision making in smart cities. In this paper we identify the different types of decision making processes involved in smart cities. Then we propose a service-oriented architecture to support big data analytics for decision making in smart cities. This architecture allows for integrating different technologies such as fog and cloud computing to support different types of analytics and decision-making operations needed to effectively utilize available big data. It provides different functions and capabilities to use big data and provide smart capabilities as services that the architecture supports. As a result, different big data applications will be able to access and use these services for varying proposes within the smart city.},
booktitle = {Proceedings of the 18th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing},
pages = {633–640},
numpages = {8},
keywords = {smart city, service-oriented architecture, middleware, fog computing, cloud computing, big data},
location = {Washington, District of Columbia},
series = {CCGrid '18}
}

@inproceedings{10.1145/3301418.3313946,
author = {Cartas, Alejandro and Kocour, Martin and Raman, Aravindh and Leontiadis, Ilias and Luque, Jordi and Sastry, Nishanth and Nu\~{n}ez-Martinez, Jose and Perino, Diego and Segura, Carlos},
title = {A Reality Check on Inference at Mobile Networks Edge},
year = {2019},
isbn = {9781450362757},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3301418.3313946},
doi = {10.1145/3301418.3313946},
abstract = {Edge computing is considered a key enabler to deploy Artificial Intelligence platforms to provide real-time applications such as AR/VR or cognitive assistance. Previous works show computing capabilities deployed very close to the user can actually reduce the end-to-end latency of such interactive applications. Nonetheless, the main performance bottleneck remains in the machine learning inference operation. In this paper, we question some assumptions of these works, as the network location where edge computing is deployed, and considered software architectures within the framework of a couple of popular machine learning tasks. Our experimental evaluation shows that after performance tuning that leverages recent advances in deep learning algorithms and hardware, network latency is now the main bottleneck on end-to-end application performance. We also report that deploying computing capabilities at the first network node still provides latency reduction but, overall, it is not required by all applications. Based on our findings, we overview the requirements and sketch the design of an adaptive architecture for general machine learning inference across edge locations.},
booktitle = {Proceedings of the 2nd International Workshop on Edge Systems, Analytics and Networking},
pages = {54–59},
numpages = {6},
keywords = {Artificial Intelligence, Edge computing},
location = {Dresden, Germany},
series = {EdgeSys '19}
}

@inproceedings{10.1145/3366613.3368120,
author = {Lan, Dapeng and Taherkordi, Amir and Eliassen, Frank and Horn, Geir},
title = {A Survey on Fog Programming: Concepts, State-of-the-Art, and Research Challenges},
year = {2019},
isbn = {9781450370318},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366613.3368120},
doi = {10.1145/3366613.3368120},
abstract = {With the rapid evolution of the Internet of Things (IoT) and the growth of IoT-generated data, cloud computing platforms have been widely used to store and process this type of data. However, cloud computing cannot handle rapidly emerging smart applications with latency-sensitive, high throughput, and high availability and reliability requirements, such as virtual reality and autonomous vehicles. The fog and mobile edge computing paradigms have been proposed to bring the cloud capacity along the network to end devices to address the above concerns. A key development aspect of fog systems is their programming models. Fog programming models and frameworks face challenges that originated from the unique characteristics of fog systems, such as heterogeneity, scalability, and mobility. In this paper, we first study the main characteristics of fog programming, as well as the design requirements of fog programming models with respect to the fog architecture and application types. Then, we survey fog programming models both from research and industry perspectives. Finally, we point out the issues and future challenges in fog programming. The survey framework, presented in this paper, provides useful insights and outlook for the fog programming research and development, inspires further research on fog programming models, and sheds light on the future of programming in this fast-growing computing paradigm.},
booktitle = {Proceedings of the 2nd International Workshop on Distributed Fog Services Design},
pages = {1–6},
numpages = {6},
keywords = {Survey, Internet of Things, Fog Programming Models and Frameworks, Fog Computing},
location = {Davis, CA, USA},
series = {DFSD '19}
}

@article{10.1145/3126501,
author = {Azimi, Iman and Anzanpour, Arman and Rahmani, Amir M. and Pahikkala, Tapio and Levorato, Marco and Liljeberg, Pasi and Dutt, Nikil},
title = {HiCH: Hierarchical Fog-Assisted Computing Architecture for Healthcare IoT},
year = {2017},
issue_date = {October 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {5s},
issn = {1539-9087},
url = {https://doi.org/10.1145/3126501},
doi = {10.1145/3126501},
abstract = {The Internet of Things (IoT) paradigm holds significant promises for remote health monitoring systems. Due to their life- or mission-critical nature, these systems need to provide a high level of availability and accuracy. On the one hand, centralized cloud-based IoT systems lack reliability, punctuality and availability (e.g., in case of slow or unreliable Internet connection), and on the other hand, fully outsourcing data analytics to the edge of the network can result in diminished level of accuracy and adaptability due to the limited computational capacity in edge nodes. In this paper, we tackle these issues by proposing a hierarchical computing architecture, HiCH, for IoT-based health monitoring systems. The core components of the proposed system are 1) a novel computing architecture suitable for hierarchical partitioning and execution of machine learning based data analytics, 2) a closed-loop management technique capable of autonomous system adjustments with respect to patient’s condition. HiCH benefits from the features offered by both fog and cloud computing and introduces a tailored management methodology for healthcare IoT systems. We demonstrate the efficacy of HiCH via a comprehensive performance assessment and evaluation on a continuous remote health monitoring case study focusing on arrhythmia detection for patients suffering from CardioVascular Diseases (CVDs).},
journal = {ACM Trans. Embed. Comput. Syst.},
month = sep,
articleno = {174},
numpages = {20},
keywords = {Fog Computing, Hierarchical Computing, Internet of Things, Machine Learning, MAPE-K, Remote Patient Monitoring}
}

@inproceedings{10.1145/3396474.3396495,
author = {Sriborrirux, Wiroon and Laortum, Peeradach},
title = {Healthcare Center IoT Edge Gateway Based on Containerized Microservices},
year = {2020},
isbn = {9781450377614},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3396474.3396495},
doi = {10.1145/3396474.3396495},
abstract = {The growth of ubiquitous healthcare systems, particularly for general and residential healthcare, is increasing dramatically. One of the most significant components of such systems is the gateway, which acts as a middleware between Internet of Things (IoT) devices and cloud application services. Here, we propose an IoT edge gateway framework based on docker container technology as the legacy virtualization technology to empower microservice architectures for aiding multiple-device real-time monitoring in locations such as nursing homes and residential care centers. The framework is used to identify IoT devices and the gateway itself in home networks for restricting access only to authorized users and non-manipulated devices. We propose the use of state-of-the-art hardware-based security supporting the mutual authentication process with the Elliptic Curve Digital Signature Algorithm as well as integrity protection to validate the device, gateway, and cloud platform integrity to identify manipulation and detect unauthorized changes by signing these data. This approach can prevent man-in-the-middle attacks. As a result, we can implement each service located in this proposed IoT edge gateway framework to enhance capabilities in edge analytics by adding hardened security with the average latency time at 2.373 ms.},
booktitle = {Proceedings of the 2020 4th International Conference on Intelligent Systems, Metaheuristics &amp; Swarm Intelligence},
pages = {24–29},
numpages = {6},
keywords = {Edge Computing, Digital Healthcare, IoT gateway framework, Docker container microservice technology},
location = {Thimphu, Bhutan},
series = {ISMSI '20}
}

@inproceedings{10.1145/3152130.3152140,
author = {Carpio, Francisco and Jukan, Admela and Sanchez, Ana Isabel Mart\'{\i}n and Amla, Nina and Kemper, Nicole},
title = {Beyond Production Indicators: A Novel Smart Farming Application and System for Animal Welfare},
year = {2017},
isbn = {9781450353649},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3152130.3152140},
doi = {10.1145/3152130.3152140},
abstract = {In the last decade, there has been a growing public interest in the welfare of farm animals. These societal and economic factors have led to the development of smart farming applications, but many important features of animal welfare are either missing or underdeveloped in these applications. This paper proposes a novel smart farming system and application framework with an emphasis on animal welfare features for cows and pigs. The framework is based on concepts of openness, transparency and data sharing for all stakeholders which is stark contrast to other existing systems that are closed, often highly proprietary and almost entirely focused on production indicators. The system is based on a novel computing and sensing framework that integrates cloud and fog computing and deploys an Android-based mobile application called SmartHof. The key innovation in the system is the ability to embrace novel computing architectures, while enabling scalable data sharing, analysis and correlation relevant to animal welfare. We show that our system can be used to improve human-animal interactions as well as enhance social interactions between groups of animals in a farm setting, which is of great benefit not only in the context of animal welfare, but also to consumers, veterinarians and policy makers.},
booktitle = {Proceedings of the Fourth International Conference on Animal-Computer Interaction},
articleno = {7},
numpages = {11},
keywords = {Mobile Applications, Cloud computing, Fog computing, Animal Computer Interaction (ACI), Smart Farming, Animal Welfare, Internet of Things (IoT)},
location = {Milton Keynes, United Kingdom},
series = {ACI2017}
}

@inproceedings{10.1145/3286978.3287007,
author = {Ozeer, Umar and Etchevers, Xavier and Letondeur, Lo\"{\i}c and Ottogalli, Fran\c{c}ois-Ga\"{e}l and Sala\"{u}n, Gwen and Vincent, Jean-Marc},
title = {Resilience of Stateful IoT Applications in a Dynamic Fog Environment},
year = {2018},
isbn = {9781450360937},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3286978.3287007},
doi = {10.1145/3286978.3287007},
abstract = {Fog computing provides computing, storage and communication resources at the edge of the network, near the physical world. Subsequently, end devices nearing the physical world can have interesting properties such as short delays, responsiveness, optimized communications and privacy. However, these end devices have low stability and are prone to failures. There is consequently a need for failure management protocols for IoT applications in the Fog. The design of such solutions is complex due to the specificities of the environment, i.e., (i) dynamic infrastructure where entities join and leave without synchronization, (ii) high heterogeneity in terms of functions, communication models, network, processing and storage capabilities, and, (iii) cyber-physical interactions which introduce non-deterministic and physical world's space and time dependent events. This paper presents a fault tolerance approach taking into account these three characteristics of the Fog-IoT environment. Fault tolerance is achieved by saving the state of the application in an uncoordinated way. When a failure is detected, notifications are propagated to limit the impact of failures and dynamically reconfigure the application. Data stored during the state saving process are used for recovery, taking into account consistency with respect to the physical world. The approach was validated through practical experiments on a smart home platform.},
booktitle = {Proceedings of the 15th EAI International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services},
pages = {332–341},
numpages = {10},
keywords = {Cyber-physical Interactions, IoT, Fog Computing, Dynamicity, Heterogeneity, Fault Tolerance},
location = {New York, NY, USA},
series = {MobiQuitous '18}
}

@article{10.1145/3407091,
author = {Anzanpour, Arman and Amiri, Delaram and Azimi, Iman and Levorato, Marco and Dutt, Nikil and Liljeberg, Pasi and Rahmani, Amir M.},
title = {Edge-Assisted Control for Healthcare Internet of Things: A Case Study on PPG-Based Early Warning Score},
year = {2020},
issue_date = {February 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {1},
issn = {2691-1914},
url = {https://doi.org/10.1145/3407091},
doi = {10.1145/3407091},
abstract = {Recent advances in pervasive Internet of Things technologies and edge computing have opened new avenues for development of ubiquitous health monitoring applications. Delivering an acceptable level of usability and accuracy for these healthcare Internet of Things applications requires optimization of both system-driven and data-driven aspects, which are typically done in a disjoint manner. Although decoupled optimization of these processes yields local optima at each level, synergistic coupling of the system and data levels can lead to a holistic solution opening new opportunities for optimization. In this article, we present an edge-assisted resource manager that dynamically controls the fidelity and duration of sensing w.r.t. changes in the patient’s activity and health state, thus fine-tuning the trade-off between energy efficiency and measurement accuracy. The cornerstone of our proposed solution is an intelligent low-latency real-time controller implemented at the edge layer that detects abnormalities in the patient’s condition and accordingly adjusts the sensing parameters of a reconfigurable wireless sensor node. We assess the efficiency of our proposed system via a case study of the photoplethysmography-based medical early warning score system. Our experiments on a real full hardware-software early warning score system reveal up to 49% power savings while maintaining the accuracy of the sensory data.},
journal = {ACM Trans. Internet Things},
month = oct,
articleno = {1},
numpages = {21},
keywords = {Internet of Things, edge-assisted control, wearable electronics, early warning score, Health monitoring, edge computing}
}

@inproceedings{10.1109/CHASE.2017.110,
author = {Str\"{a}ssle, R. and Gerke, S. and Brunschwiler, T. and Temiz, Y. and Weiss, J. and Sridhar, A. and Paredes, S. and Loertscher, E. and Ebejer, N. and Michel, B. and Lee, H.-M. and Alvarado, C. and Faro, I. and Van Kessel, T. and Meghelli, M. and Taubenblatt, M. A. and Zafar, S. and Libsch, F. and Matsumoto, K.},
title = {Internet of the Body and Cognitive Hypervisor},
year = {2017},
isbn = {9781509047215},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CHASE.2017.110},
doi = {10.1109/CHASE.2017.110},
abstract = {Wearables that continuously acquire medically relevant parameters can reduce duration of hospitalizations and derive treatment optimizations for individual patients thus improving the quality of medical treatments. We demonstrate an architecture that includes wearables, edge and cloud computing to provide optimal user interaction and analytics of multiparameter wearable data to accomplish this goal. We also explore the trade-offs of on-wearable processing versus raw data transmission and the use of commercial location monitors to acquire indoor location data.},
booktitle = {Proceedings of the Second IEEE/ACM International Conference on Connected Health: Applications, Systems and Engineering Technologies},
pages = {296–297},
numpages = {2},
keywords = {edge computing, wearable, healthcare},
location = {Philadelphia, Pennsylvania},
series = {CHASE '17}
}

@inproceedings{10.1145/3269961.3269972,
author = {Rahbari, Dadmehr and Nickray, Mohsen and Heydari, Gholamreza},
title = {A Two-Stage Technique for Quick and Low Power Offloading in IoT},
year = {2018},
isbn = {9781450365321},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3269961.3269972},
doi = {10.1145/3269961.3269972},
abstract = {Fog computing (FC) as an extension of cloud computing provides a lot of smart devices at the network edge, which can store and process data near end users. Since FC reduces latency and power consumption, it is suitable for the Internet of Things (IoT) applications in smart cities. In FC, the Mobile Devices (MDs) can offload its heavy tasks to Fog Devices (FDs). The selection of best FD for offloading has serious challenges in the time and energy. In this paper, we present a Module Placement method by Classification and regression tree Algorithm (MPCA). We select the best FDs for modules by MPCA. Initially, if the total power consumption of CPU and memory in MDs is greater than Wi-Fi's power consumption, the offloading will be done. The MPCA's decision parameters for selecting of best FD include authentication, confidentiality, integrity, availability, capacity, speed, and cost. To evaluate our proposed approach, we simulate MPCA and compare it with First-Fit (FF) and local mobile processing methods in Cloud, fog, and MDs. The results show that the proposed method is superior to other compared methods in the average power consumption by 38.41%, response time by 37%, and 13.76% in performance.},
booktitle = {Proceedings of the International Conference on Smart Cities and Internet of Things},
articleno = {4},
numpages = {8},
keywords = {Module placement, Mobile fog computing, Smart City, Internet of Things},
location = {Mashhad, Iran},
series = {SCIOT '18}
}

@inproceedings{10.1145/3278161.3278166,
author = {Ding, Aaron Yi and Janssen, Marijn},
title = {Opportunities for Applications Using 5G Networks: Requirements, Challenges, and Outlook},
year = {2018},
isbn = {9781450365802},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3278161.3278166},
doi = {10.1145/3278161.3278166},
abstract = {The increasing demand for mobile network capacity driven by Internet of Things (IoT) applications results in the need for understanding better the potential and limitations of 5G networks. Vertical application areas like smart mobility, energy networks, industrial IoT applications, and AR/VR enhanced services all pose different requirements on the use of 5G networks. Some applications need low latency, whereas others need high bandwidth or security support. The goal of this paper is to identify the requirements and to understand the limitations for 5G driven applications. We review application areas and list the typical challenges and requirements posed on 5G networks. A main challenge will be to develop a network architecture being able to dynamically adapt to fluctuating traffic patterns and accommodating various technologies such as edge computing, blockchain based distributed ledger, software defined networking, and virtualization. To inspire future research, we reveal open problems and highlight the need for piloting with 5G applications, with tangible steps, to understand the configuration of 5G networks and the use of applications across multiple vertical industries.},
booktitle = {Proceedings of the Seventh International Conference on Telecommunications and Remote Sensing},
pages = {27–34},
numpages = {8},
keywords = {5G systems, edge computing, smart city, IoT, pilot},
location = {Barcelona, Spain},
series = {ICTRS '18}
}

@inproceedings{10.1145/2967413.2967422,
author = {Nawaz, Tahir and Rinner, Bernhard and Ferryman, James},
title = {User-Centric, Embedded Vision-Based Human Monitoring: A Concept and a Healthcare Use Case},
year = {2016},
isbn = {9781450347860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2967413.2967422},
doi = {10.1145/2967413.2967422},
abstract = {In an Internet of Things (IoT) camera-based monitoring application the transmission of images away from the video sensors for processing poses security and privacy risks. Hence, there is a need for an advanced trusted user-centric monitoring system that pushes the application of security and privacy protection closer to the sensor itself and which enables an enhanced control on data privacy. To this end, this white paper proposes a new approach that involves sensor edge computing to enable sensor-level security and privacy protection and allows observed individuals to interact and control their data without impacting on the quality of the data for further processing. Overall, an IoT vision system is presented that employs a network of fixed embedded cameras in a highly trusted manner, possessing both privacy-protecting and data security features. As a potential application, we discuss an Ambient Assisted Living (AAL) healthcare use case demanding privacy and security for outpatients.},
booktitle = {Proceedings of the 10th International Conference on Distributed Smart Camera},
pages = {25–30},
numpages = {6},
keywords = {Edge computing, Privacy and security protection, White paper},
location = {Paris, France},
series = {ICDSC '16}
}

@inproceedings{10.1145/3126686.3126739,
author = {Zhang, Wenxiao and Lin, Sikun and Bijarbooneh, Farshid Hassani and Cheng, Hao Fei and Hui, Pan},
title = {CloudAR: A Cloud-Based Framework for Mobile Augmented Reality},
year = {2017},
isbn = {9781450354165},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3126686.3126739},
doi = {10.1145/3126686.3126739},
abstract = {Computation capabilities of recent mobile devices enable natural feature processing for augmented reality (AR), but the scalability issues are still faced by mobile AR applications. In this paper, we propose CloudAR, a mobile AR framework utilizing the advantages of cloud and edge computing through task offloading. We design an innovative tracking system for mobile devices which provides lightweight tracking with 6 degree of freedom (6DoF) and hides the offloading latency from user»s perception. We also design a multi-object image retrieval pipeline that executes fast and accurate image recognition tasks on servers. Experiments are carried out to evaluate the performance of CloudAR. The mobile AR App built with CloudAR framework runs at 30 frames per second (FPS) on average with precise tracking of only 1~2 pixel errors and accurate image recognition of at least 97% accuracy.},
booktitle = {Proceedings of the on Thematic Workshops of ACM Multimedia 2017},
pages = {194–200},
numpages = {7},
keywords = {mobile systems, augmented reality, cloud computing, image retrieval, tracking, edge computing},
location = {Mountain View, California, USA},
series = {Thematic Workshops '17}
}

@article{10.1145/3239565,
author = {Chen, Min and Li, Wei and Fortino, Giancarlo and Hao, Yixue and Hu, Long and Humar, Iztok},
title = {A Dynamic Service Migration Mechanism in Edge Cognitive Computing},
year = {2019},
issue_date = {April 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {2},
issn = {1533-5399},
url = {https://doi.org/10.1145/3239565},
doi = {10.1145/3239565},
abstract = {Driven by the vision of edge computing and the success of rich cognitive services based on artificial intelligence, a new computing paradigm, edge cognitive computing (ECC), is a promising approach that applies cognitive computing at the edge of the network. ECC has the potential to provide the cognition of users and network environmental information, and further to provide elastic cognitive computing services to achieve a higher energy efficiency and a higher Quality of Experience (QoE) compared to edge computing. This article first introduces our architecture of the ECC and then describes its design issues in detail. Moreover, we propose an ECC-based dynamic service migration mechanism to provide insight into how cognitive computing is combined with edge computing. In order to evaluate the proposed mechanism, a practical platform for dynamic service migration is built up, where the services are migrated based on the behavioral cognition of a mobile user. The experimental results show that the proposed ECC architecture has ultra-low latency and a high user experience, while providing better service to the user, saving computing resources, and achieving a high energy efficiency.},
journal = {ACM Trans. Internet Technol.},
month = apr,
articleno = {30},
numpages = {15},
keywords = {edge computing, mobile cloud computing, service migration, Cognitive computing, cloud computing}
}

@article{10.1145/3230642,
author = {Samie, Farzad and Tsoutsouras, Vasileios and Bauer, Lars and Xydis, Sotirios and Soudris, Dimitrios and Henkel, J\"{o}rg},
title = {<i>Oops</i>: Optimizing Operation-Mode Selection for IoT Edge Devices},
year = {2019},
issue_date = {April 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {2},
issn = {1533-5399},
url = {https://doi.org/10.1145/3230642},
doi = {10.1145/3230642},
abstract = {The massive increase of IoT devices and their collected data raises the question of how to analyze all that data. Edge computing provides a suitable compromise, but the question remains: How much processing should be done locally vs. offloaded to other devices? The diverse application requirements and limited resources at the edge extend the challenges.We propose Oops, an optimization framework to adapt the resource management at runtime distributedly. It orchestrates the IoT devices and adapts their operation mode with respect to their constraints and the gateway’s limited shared resources. Oops reduces runtime overhead significantly while increasing user utility compared to state-of-the-art.},
journal = {ACM Trans. Internet Technol.},
month = mar,
articleno = {22},
numpages = {21},
keywords = {IoT, Internet of Things, resource management, constrained devices, runtime optimization, edge computing}
}

@article{10.1145/3397160,
author = {Deng, Shuiguang and Cheng, Guanjie and Zhao, Hailiang and Gao, Honghao and Yin, Jianwei},
title = {Incentive-Driven Computation Offloading in Blockchain-Enabled E-Commerce},
year = {2020},
issue_date = {February 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {1},
issn = {1533-5399},
url = {https://doi.org/10.1145/3397160},
doi = {10.1145/3397160},
abstract = {Blockchain is regarded as one of the most promising technologies to upgrade e-commerce. This article analyzes the challenges that current e-commerce is facing and introduces a new scenario of e-commerce enabled by blockchain. A framework is proposed for mining tasks in this scenario offloaded onto edge servers based on mobile edge computing. Then, the offloading issue is modeled as a multi-constrained optimization problem, and evolutionary algorithms are utilized and re-designed as solvers. The experimental results validate the efficiency of the framework and algorithms and also show that the lower bound of computation resources exists to obtain the maximum overall revenue.},
journal = {ACM Trans. Internet Technol.},
month = dec,
articleno = {9},
numpages = {19},
keywords = {Blockchain, edge computing, e-commerce, computation offloading}
}

@inproceedings{10.1145/3277893.3277901,
author = {Elmalaki, Salma and Shoukry, Yasser and Srivastava, Mani},
title = {Internet of Personalized and Autonomous Things (IoPAT): Smart Homes Case Study},
year = {2018},
isbn = {9781450360517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3277893.3277901},
doi = {10.1145/3277893.3277901},
abstract = {IoT devices are permeating every corner of our lives today paving the road for more substantial smart systems. Despite their ability to collect and analyze a significant amount of sensory data, traditional IoT typically depends on fixed policies and schedules to enhance user experience. However, fixed policies that do not account for variations in human mood, reactions, and expectations, fail to achieve the promised user experience. In this paper, we propose an architecture for personalized and autonomous IoT systems that weaves personalization and context-awareness into the very fabric of smart systems. By building upon ideas from reinforcement learning, we show---using an example of smart and personalized home services---how the proposed architecture can adapt to human behaviors that are varying between individuals and vary, for the same individual, across time while addressing some of the security and privacy challenges.},
booktitle = {Proceedings of the 1st ACM International Workshop on Smart Cities and Fog Computing},
pages = {35–40},
numpages = {6},
keywords = {Smart Homes, Personalized IoT, Autonomous Systems},
location = {Shenzhen, China},
series = {CitiFog'18}
}

@inproceedings{10.1145/3386901.3389033,
author = {Ben Ali, Ali J. and Hashemifar, Zakieh Sadat and Dantu, Karthik},
title = {Edge-SLAM: Edge-Assisted Visual Simultaneous Localization and Mapping},
year = {2020},
isbn = {9781450379540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386901.3389033},
doi = {10.1145/3386901.3389033},
abstract = {Localization in urban environments is becoming increasingly important and used in tools such as ARCore [11], ARKit [27] and others. One popular mechanism to achieve accurate indoor localization as well as a map of the space is using Visual Simultaneous Localization and Mapping (Visual-SLAM). However, Visual-SLAM is known to be resource-intensive in memory and processing time. Further, some of the operations grow in complexity over time, making it challenging to run on mobile devices continuously. Edge computing provides additional compute and memory resources to mobile devices to allow offloading of some tasks without the large latencies seen when offloading to the cloud. In this paper, we present Edge-SLAM, a system that uses edge computing resources to offload parts of Visual-SLAM. We use ORB-SLAM2 as a prototypical Visual-SLAM system and modify it to a split architecture between the edge and the mobile device. We keep the tracking computation on the mobile device and move the rest of the computation, i.e., local mapping and loop closure, to the edge. We describe the design choices in this effort and implement them in our prototype. Our results show that our split architecture can allow the functioning of the Visual-SLAM system long-term with limited resources without affecting the accuracy of operation. It also keeps the computation and memory cost on the mobile device constant which would allow for deployment of other end applications that use Visual-SLAM.},
booktitle = {Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
pages = {325–337},
numpages = {13},
keywords = {split architecture, visual simultaneous localization and mapping, localization, mobile systems, edge computing, mapping},
location = {Toronto, Ontario, Canada},
series = {MobiSys '20}
}

@inbook{10.1145/3384544.3384611,
author = {Hartner, Raphael and Mezhuyev, Vitaliy and Tschandl, Martin and Bischof, Christian},
title = {Digital Shop Floor Management: A Practical Framework For Implementation},
year = {2020},
isbn = {9781450376655},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384544.3384611},
abstract = {In the context of manufacturing, shop floor management (SFM) is employed to ensure efficient production operations and workflows. Advanced technologies and methods can be used to improve the SFM and achieve close to real-time responsiveness. Even though there is a number of research available for the digitalized SFM (DSFM), a supportive framework for implementation purposes was not considered yet. Consequently, this paper utilizes concepts from related disciplines and research areas to derive an architectural framework for a DSFM. This particular architecture is then implemented to ensure its practicability and foster the understanding of challenges and opportunities. The proposed multi-layer framework and supportive methods can be employed by manufacturing companies to implement a DSFM focused on interoperability, security and low-latency.},
booktitle = {Proceedings of the 2020 9th International Conference on Software and Computer Applications},
pages = {41–45},
numpages = {5}
}

@inproceedings{10.1145/3302505.3310068,
author = {Malekzadeh, Mohammad and Clegg, Richard G. and Cavallaro, Andrea and Haddadi, Hamed},
title = {Mobile Sensor Data Anonymization},
year = {2019},
isbn = {9781450362832},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3302505.3310068},
doi = {10.1145/3302505.3310068},
abstract = {Motion sensors such as accelerometers and gyroscopes measure the instant acceleration and rotation of a device, in three dimensions. Raw data streams from motion sensors embedded in portable and wearable devices may reveal private information about users without their awareness. For example, motion data might disclose the weight or gender of a user, or enable their re-identification. To address this problem, we propose an on-device transformation of sensor data to be shared for specific applications, such as monitoring selected daily activities, without revealing information that enables user identification. We formulate the anonymization problem using an information-theoretic approach and propose a new multi-objective loss function for training deep autoencoders. This loss function helps minimizing user-identity information as well as data distortion to preserve the application-specific utility. The training process regulates the encoder to disregard user-identifiable patterns and tunes the decoder to shape the output independently of users in the training set. The trained autoencoder can be deployed on a mobile or wearable device to anonymize sensor data even for users who are not included in the training dataset. Data from 24 users transformed by the proposed anonymizing autoencoder lead to a promising trade-off between utility and privacy, with an accuracy for activity recognition above 92% and an accuracy for user identification below 7%.},
booktitle = {Proceedings of the International Conference on Internet of Things Design and Implementation},
pages = {49–58},
numpages = {10},
keywords = {deep learning, time series analysis, sensor data privacy, adversarial training, edge computing},
location = {Montreal, Quebec, Canada},
series = {IoTDI '19}
}

@article{10.1145/3284553,
author = {Avgeris, Marios and Dechouniotis, Dimitrios and Athanasopoulos, Nikolaos and Papavassiliou, Symeon},
title = {Adaptive Resource Allocation for Computation Offloading: A Control-Theoretic Approach},
year = {2019},
issue_date = {April 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {2},
issn = {1533-5399},
url = {https://doi.org/10.1145/3284553},
doi = {10.1145/3284553},
abstract = {Although mobile devices today have powerful hardware and networking capabilities, they fall short when it comes to executing compute-intensive applications. Computation offloading (i.e., delegating resource-consuming tasks to servers located at the edge of the network) contributes toward moving to a mobile cloud computing paradigm. In this work, a two-level resource allocation and admission control mechanism for a cluster of edge servers offers an alternative choice to mobile users for executing their tasks. At the lower level, the behavior of edge servers is modeled by a set of linear systems, and linear controllers are designed to meet the system’s constraints and quality of service metrics, whereas at the upper level, an optimizer tackles the problems of load balancing and application placement toward the maximization of the number the offloaded requests. The evaluation illustrates the effectiveness of the proposed offloading mechanism regarding the performance indicators, such as application average response time, and the optimal utilization of the computational resources of edge servers.},
journal = {ACM Trans. Internet Technol.},
month = apr,
articleno = {23},
numpages = {20},
keywords = {linear modeling, Edge computing, feedback control}
}

@inproceedings{10.1145/3410530.3414321,
author = {Ek, Sannara and Portet, Fran\c{c}ois and Lalanda, Philippe and Vega, German},
title = {Evaluation of Federated Learning Aggregation Algorithms: Application to Human Activity Recognition},
year = {2020},
isbn = {9781450380768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3410530.3414321},
doi = {10.1145/3410530.3414321},
abstract = {Pervasive computing promotes the integration of connected electronic devices in our living spaces in order to assist us through appropriate services. Two major developments have gained significant momentum recently: a better use of fog resources and the use of AI techniques. Specifically, interest in machine learning approaches for engineering applications has increased rapidly.  This paradigm seems to fit the pervasive environment well. However, federated learning has been applied so far to specific services and remains largely conceptual. It needs to be tested extensively on pervasive services partially located in the fog. In this paper, we present experiments performed in the domain of Human Activity Recognition on smartphones in order to evaluate existing algorithms.},
booktitle = {Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers},
pages = {638–643},
numpages = {6},
keywords = {federated learning, human activity recognition, edge computing},
location = {Virtual Event, Mexico},
series = {UbiComp-ISWC '20}
}

@inproceedings{10.1145/3366615.3368358,
author = {Bali, Ahmed and Gherbi, Abdelouahed},
title = {Rule Based Lightweight Approach for Resources Monitoring on IoT Edge Devices},
year = {2019},
isbn = {9781450370332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366615.3368358},
doi = {10.1145/3366615.3368358},
abstract = {Edge computing is a recent tendency in the IoT domain that contributes to reduce the reliance on Cloud. This is due to the cost efficiency and the improvement of the system responsivity since services are deployed close to the data source as well as actuator nodes. However, IoT services are created on the top of a diverse and heterogeneous stack of technologies in terms of their representative hardware components. Thus, leading to some kind of barrier to accomplish system interoperability. To mitigate this heterogeneity issue, lightweight virtualization techniques such as containers have been widely adopted for IoT service deployment. However, edge devices (e.g., gateway devices) are likely to be resource-constrained, which in some cases limits their abilities to support the deployment of multiple containers. In fact, this raises the need for an effective management of resources at the edge devices. To achieve that, tools for monitoring resources consumption of container based IoT systems at the network edge level, and to launch notifications in case of any change that requires intervention are of utmost necessity. However, the current efficient monitoring tools are greedy for computing and storage resources; especially when a considerable number of IoT microservices are needed to be deployed on the same gateway. Therefore, they do not meet the constraint of limited resources when scalability is required. This work proposes a lightweight rule-based monitoring approach, taking into consideration resources needed for the monitoring process, especially with the increased number of containers deployed on IoT gateways. Our evaluation shows a significant reduction in the communication of monitoring metrics.},
booktitle = {Proceedings of the 5th International Workshop on Container Technologies and Container Clouds},
pages = {43–48},
numpages = {6},
keywords = {Container, Cluster, Rule, Edge computing, Resource monitoring},
location = {Davis, CA, USA},
series = {WOC '19}
}

@inproceedings{10.1145/3282373.3282400,
author = {Shaaban, Abdelkader Magdy and Schmittner, Christoph and Gruber, Thomas and Mohamed, A. Baith and Quirchmayr, Gerald and Schikuta, Erich},
title = {CloudWoT - A Reference Model for Knowledge-Based IoT Solutions},
year = {2018},
isbn = {9781450364799},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282373.3282400},
doi = {10.1145/3282373.3282400},
abstract = {Internet technology has changed how people work, live, communicate, learn and entertain. The internet adoption is rising rapidly, thus creating a new industrial revolution named "Industry 4.0". Industry 4.0 is the use of automation and data transfer in manufacturing technologies. It fosters several technological concepts, one of these is the Internet of Things (IoT). IoT technology is based on a big network of machines, objects, or people called "things" interacting together to achieve a common goal. These things are continuously generating vast amounts of data. Data understanding, processing, securing and storing are significant challenges in the IoT technology which restricts its development. This paper presents a new reference IoT model for future smart IoT solutions called Cloud Web of Things (CloudWoT). CloudWoT aims to overcome these limitations by combining IoT with edge computing, semantic web, and cloud computing. Additionally, this work is concerned with the security issues which threatens data in IoT application domains.},
booktitle = {Proceedings of the 20th International Conference on Information Integration and Web-Based Applications &amp; Services},
pages = {272–281},
numpages = {10},
keywords = {Semantic Web, IACS, CPPS, CloudWoT, IoT, Edge Computing, Cloud Computing},
location = {Yogyakarta, Indonesia},
series = {iiWAS2018}
}

@inproceedings{10.5555/3395101.3395140,
author = {Campolo, Claudia and Cuzzocrea, Domenico and Genovese, Giacomo and Iera, Antonio and Molinaro, Antonella},
title = {An OMA Lightweight M2M-Compliant MEC Framework to Track Multi-Modal Commuters for MaaS Applications},
year = {2019},
isbn = {9781728129235},
publisher = {IEEE Press},
abstract = {Mobility as a Service (MaaS) implies the integration of different transport services in a unique platform accessible by commuters on demand. Collection and processing of data concerning the mobility of customers is crucial to calculate trips options satisfying users' needs and preferences. In this paper, we propose to exploit Multi-access Edge Computing (MEC) facilities to more efficiently deploy MaaS solutions. Specifically, we design a MEC-based MaaS framework that is fully compliant with the Open Mobile Alliance (OMA) Lightweight Machine-to-Machine (LwM2M) protocol. The OMA LwM2M server hosted in the MEC platform continuously collects data from the commuters, and uses native MEC applications to provide value-added services. The Observe extension of the Constrained Application Protocol (CoAP) is used to reduce energy consumption during data collection from the OMA LwM2M clients installed in the mobile user devices. Preliminary results are collected that show the performance of the proposed MaaS framework, integrated with a mobility generator tool (i.e., SUMO) that emulates the commuter paths.},
booktitle = {Proceedings of the 23rd IEEE/ACM International Symposium on Distributed Simulation and Real Time Applications},
pages = {215–222},
numpages = {8},
keywords = {multi-access edge computing, OMA LwM2M, MaaS, SUMO, CoAP, OSM},
location = {Cosenza, Italy},
series = {DS-RT '19}
}

@article{10.1145/3209659,
author = {Wang, Junjue and Amos, Brandon and Das, Anupam and Pillai, Padmanabhan and Sadeh, Norman and Satyanarayanan, Mahadev},
title = {Enabling Live Video Analytics with a Scalable and Privacy-Aware Framework},
year = {2018},
issue_date = {August 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {3s},
issn = {1551-6857},
url = {https://doi.org/10.1145/3209659},
doi = {10.1145/3209659},
abstract = {We show how to build the components of a privacy-aware, live video analytics ecosystem from the bottom up, starting with OpenFace, our new open-source face recognition system that approaches state-of-the-art accuracy. Integrating OpenFace with interframe tracking, we build RTFace, a mechanism for denaturing video streams that selectively blurs faces according to specified policies at full frame rates. This enables privacy management for live video analytics while providing a secure approach for handling retrospective policy exceptions. Finally, we present a scalable, privacy-aware architecture for large camera networks using RTFace and show how it can be an enabler for a vibrant ecosystem and marketplace of privacy-aware video streams and analytics services.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = jun,
articleno = {64},
numpages = {24},
keywords = {face recognition, edge computing, Privacy mediator, cloudlet, cloud computing}
}

@inbook{10.1145/3219819.3219883,
author = {Diethe, Tom and Holmes, Mike and Kull, Meelis and Perello Nieto, Miquel and Sokol, Kacper and Song, Hao and Tonkin, Emma and Twomey, Niall and Flach, Peter},
title = {Releasing EHealth Analytics into the Wild: Lessons Learnt from the SPHERE Project},
year = {2018},
isbn = {9781450355520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219819.3219883},
abstract = {The SPHERE project is devoted to advancing eHealth in a smart-home context, and supports full-scale sensing and data analysis to enable a generic healthcare service. We describe, from a data-science perspective, our experience of taking the system out of the laboratory into more than thirty homes in Bristol, UK. We describe the infrastructure and processes that had to be developed along the way, describe how we train and deploy Machine Learning systems in this context, and give a realistic appraisal of the state of the deployed systems.},
booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {243–252},
numpages = {10}
}

@article{10.1145/3376919,
author = {Pal, Amitangshu and Kant, Krishna},
title = {Exploiting Proxy Sensing for Efficient Monitoring of Large-Scale Sensor Networks},
year = {2020},
issue_date = {May 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {2},
issn = {1533-5399},
url = {https://doi.org/10.1145/3376919},
doi = {10.1145/3376919},
abstract = {Large networks of IoT devices, each consisting of one or more sensors, are being increasingly deployed for comprehensive real-time monitoring of cyber-physical systems. Such networks form an essential component of the emerging edge computing paradigm and are expected to increase in complexity and size. The physical phenomenon sensed by different sensors (within the same or different IoT devices in close proximity) often have relationships that makes them correlated. This is a form of proxy sensing that can be exploited for achieving better energy efficiency and higher robustness in monitoring. In this article, we explore how a set of sensors can optimize its data collection rates efficiently in a semi-distributed manner and yet provide the advantages of autonomy, relative isolation, and distributed control that is essential in a large-scale network.},
journal = {ACM Trans. Internet Technol.},
month = apr,
articleno = {14},
numpages = {31},
keywords = {Edge computing, proxy sensing, rate adaptation, adaptive sampling, heterogeneous sensing}
}

@inproceedings{10.1145/3205977.3205989,
author = {Ahmad, Tahir and Morelli, Umberto and Ranise, Silvio and Zannone, Nicola},
title = {A Lazy Approach to Access Control as a Service (ACaaS) for IoT: An AWS Case Study},
year = {2018},
isbn = {9781450356664},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3205977.3205989},
doi = {10.1145/3205977.3205989},
abstract = {The Internet of Things (IoT) is receiving considerable attention from both industry and academia because of the new business models that it enables and the new security and privacy challenges that it generates. Major Cloud Service Providers (CSPs) have proposed platforms to support IoT by combining cloud and edge computing. However, the security mechanisms available in the cloud have been extended to IoT with some shortcomings with respect to the management and enforcement of access control policies. Access Control as a Service (ACaaS) is emerging as a solution to overcome these difficulties. The paper proposes a lazy approach to ACaaS that allows the specification and management of policies independently of the CSP while leveraging its enforcement mechanisms. We demonstrate the approach by investigating (also experimentally) alternative deployments in the IoT platform offered by Amazon Web Services on a realistic smart lock solution.},
booktitle = {Proceedings of the 23nd ACM on Symposium on Access Control Models and Technologies},
pages = {235–246},
numpages = {12},
keywords = {attribute-based access control, internet of things, edge computing, IoT platforms, policy specification and management},
location = {Indianapolis, Indiana, USA},
series = {SACMAT '18}
}

@inproceedings{10.1145/3069383.3069385,
author = {Kahvazadeh, Sarang and Souza, Vitor B. and Masip-Bruin, Xavi and Marn-Tordera, Eva and Garcia, Jordi and Diaz, Rodrigo},
title = {Securing Combined Fog-to-Cloud System Through SDN Approach},
year = {2017},
isbn = {9781450349345},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3069383.3069385},
doi = {10.1145/3069383.3069385},
abstract = {Future IoT services execution may benefit from combining resources at cloud and at the edge. To that end, new architectures should be proposed to handle IoT services in a coordinated way at either the edge of the network, the cloud, or both. Reacting to that need, the Fog-to-Cloud concept has been recently proposed. A key aspect in the F2C design refers to security, since F2C raises security issues besides those yet unsolved in fog and cloud. Thus, we envision the need for new security strategies to handle all components in the F2C architecture. In this paper we propose an SDN-based (mater/slave) security architecture leveraging a centralized controller on the cloud, and distributed controllers at the edge of the network. We argue that the proposed architecture brings more security and privacy to the cloud users by reducing the distance between them and, therefore, reducing the risks of the so called man-in-the-middle attacks. The proposed security architecture is analyzed in some critical infrastructure scenarios in order to illustrate their potential benefits.},
booktitle = {Proceedings of the 4th Workshop on CrossCloud Infrastructures &amp; Platforms},
articleno = {2},
numpages = {6},
keywords = {cloud computing, security, Fog-to-Cloud computing, fog computing, SDN, critical infrastructures, IoT},
location = {Belgrade, Serbia},
series = {Crosscloud'17}
}

@article{10.1145/3381014,
author = {Al Hossain, Forsad and Lover, Andrew A. and Corey, George A. and Reich, Nicholas G. and Rahman, Tauhidur},
title = {FluSense: A Contactless Syndromic Surveillance Platform for Influenza-Like Illness in Hospital Waiting Areas},
year = {2020},
issue_date = {March 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {1},
url = {https://doi.org/10.1145/3381014},
doi = {10.1145/3381014},
abstract = {We developed a contactless syndromic surveillance platform FluSense that aims to expand the current paradigm of influenza-like illness (ILI) surveillance by capturing crowd-level bio-clinical signals directly related to physical symptoms of ILI from hospital waiting areas in an unobtrusive and privacy-sensitive manner. FluSense consists of a novel edge-computing sensor system, models and data processing pipelines to track crowd behaviors and influenza-related indicators, such as coughs, and to predict daily ILI and laboratory-confirmed influenza caseloads. FluSense uses a microphone array and a thermal camera along with a neural computing engine to passively and continuously characterize speech and cough sounds along with changes in crowd density on the edge in a real-time manner. We conducted an IRB-approved 7 month-long study from December 10, 2018 to July 12, 2019 where we deployed FluSense in four public waiting areas within the hospital of a large university. During this period, the FluSense platform collected and analyzed more than 350,000 waiting room thermal images and 21 million non-speech audio samples from the hospital waiting areas. FluSense can accurately predict daily patient counts with a Pearson correlation coefficient of 0.95. We also compared signals from FluSense with the gold standard laboratory-confirmed influenza case data obtained in the same facility and found that our sensor-based features are strongly correlated with laboratory-confirmed influenza trends.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = mar,
articleno = {1},
numpages = {28},
keywords = {Contactless Sensing, Crowd Behavior Mining, Influenza Surveillance, Edge Computing}
}

@inproceedings{10.1145/3325413.3329787,
author = {Hu, Zhiming and Tarakji, Ahmad Bisher and Raheja, Vishal and Phillips, Caleb and Wang, Teng and Mohomed, Iqbal},
title = {DeepHome: Distributed Inference with Heterogeneous Devices in the Edge},
year = {2019},
isbn = {9781450367714},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3325413.3329787},
doi = {10.1145/3325413.3329787},
abstract = {Manufacturers are adding intelligent capabilities (e.g. voice assistants, gesture sensing, facial recognition) to home devices at a rapid pace, and this is leading to an explosion of data generated at the edge. Traditional wisdom calls for offloading data to the cloud for further processing as local devices only have limited computational resources. However, we argue that when we consider the aggregate processing capability of all devices in the home, there is an opportunity for processing data inside the home. This has the potential to offer users with stronger privacy guarantees and potentially lower latencies. In this paper, we present a performance comparison between the capabilities of mobile phones and new hardware designed for Deep Learning Inference - the Coral TPU and the NVIDIA Jetson Nano. We also describe a new distributed inference system, named DeepHome, that can distribute the machine learning inference tasks to multiple heterogeneous devices in the home. We discuss various issues related to doing processing in an in-home context and present initial performance results from our working system.},
booktitle = {The 3rd International Workshop on Deep Learning for Mobile Systems and Applications},
pages = {13–18},
numpages = {6},
keywords = {distributed inference, machine learning, edge computing},
location = {Seoul, Republic of Korea},
series = {EMDL '19}
}

@inproceedings{10.1145/3171592.3171606,
author = {Rahman, Fatin Hamadah and Au, Thien Wan and Newaz, S. H. Shah and Suhaili, Wida Susanty},
title = {Trustworthiness in Fog: A Fuzzy Approach},
year = {2017},
isbn = {9781450353663},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3171592.3171606},
doi = {10.1145/3171592.3171606},
abstract = {Trust management issue in cloud domain has been a persistent research topic discussed among scholars. Similar issue is bound to occur in the surfacing fog domain. Although fog and cloud are relatively similar, evaluating trust in fog domain is more challenging than in cloud. Fog's high mobility support, distributive nature, and closer distance to end user means that they are likely to operate in vulnerable environments. Unlike cloud, fog has little to no human intervention, and lack of redundancy. Hence, it could experience downtime at any given time. Thus it is harder to trust fogs given their unpredictable status. These distinguishing factors, combined with the existing factors used for trust evaluation in cloud can be used as metrics to evaluate trust in fog. This paper discusses a use case of a campus scenario with several fog servers, and the metrics used in evaluating the trustworthiness of the fog servers. While fuzzy logic method is used to evaluate the trust, the contribution of this study is the identification of fuzzy logic configurations that could alter the trust value of a fog.},
booktitle = {Proceedings of the 2017 VI International Conference on Network, Communication and Computing},
pages = {207–211},
numpages = {5},
keywords = {trust evaluation, fuzzy logic, Keywords - Fog computing},
location = {Kunming, China},
series = {ICNCC 2017}
}

@inproceedings{10.1145/3109761.3158388,
author = {Dautov, Rustem and Distefano, Salvatore},
title = {Three-Level Hierarchical Data Fusion through the IoT, Edge, and Cloud Computing},
year = {2017},
isbn = {9781450352437},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3109761.3158388},
doi = {10.1145/3109761.3158388},
abstract = {The Internet of Things (IoT) has embraced a 'vertical' off-loading model, where avalanches of raw data generated by numerous edge devices are continuously pushed through the network to a remote processing location, such as a datacenter or a cloud. In this rather unbalanced architecture, edge devices are typically not expected to perform sophisticated data processing and analytics, and data fusion takes place remotely from the original source of data. As a result, the underlying network and the remote datacenter have to handle increased amounts of unstructured raw data, which, in turn, may affect the overall performance and decrease reaction times. As a potential solution to these shortcomings, this paper introduces a distributed hierarchical data fusion architecture for the IoT networks, consisting of edge devices, network and communications units, and cloud platforms. According to the proposed approach, different data sources are combined at each level of the IoT hierarchy to produce timely and accurate results by utilising computational capabilities of intermediate nodes. This way, mission-critical decisions, as demonstrated by the presented smart healthcare scenario, are taken with minimum time delay, as soon as necessary information is generated and collected. The initial evaluation suggests that the proposed approach enables fine-grained decision taking at different data fusion levels, and, as a result, improves the overall performance and reaction time.},
booktitle = {Proceedings of the 1st International Conference on Internet of Things and Machine Learning},
articleno = {1},
numpages = {5},
keywords = {internet of things, edge computing, cloud computing, data fusion, complex event processing, distributed architecture},
location = {Liverpool, United Kingdom},
series = {IML '17}
}

@article{10.1145/3408319,
author = {Xu, Xiaolong and Huang, Qihe and Zhang, Yiwen and Li, Shancang and Qi, Lianyong and Dou, Wanchun},
title = {An LSH-Based Offloading Method for IoMT Services in Integrated Cloud-Edge Environment},
year = {2021},
issue_date = {January 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {3s},
issn = {1551-6857},
url = {https://doi.org/10.1145/3408319},
doi = {10.1145/3408319},
abstract = {Benefiting from the massive available data provided by Internet of multimedia things (IoMT), enormous intelligent services requiring information of various types to make decisions are emerging. Generally, the IoMT devices are equipped with limited computing power, interfering with the process of computation-intensive services. Currently, to satisfy a wide range of service requirements, the novel computing paradigms, i.e., cloud computing and edge computing, can potentially be integrated for service accommodation. Nevertheless, the private information (i.e., location, service type, etc.) in the services is prone to spilling out during service offloading in the cloud-edge computing. To avoid privacy leakage while improving service utility, including the service response time and energy consumption for service executions, a <underline>L</underline>ocality-sensitive-hash (LSH)-based <underline>o</underline>ffloading <underline>m</underline>ethod, named LOM, is devised. Specifically, LSH is leveraged to encrypt the feature information for the services offloaded to the edge servers with the intention of privacy preservation. Eventually, comparative experiments are conducted to verify the effectiveness of LOM with respect to promoting service utility.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = jan,
articleno = {94},
numpages = {19},
keywords = {cloud-edge computing, LSH, service offloading, IoMT, privacy preservation}
}

@inproceedings{10.1145/3330089.3330121,
author = {Mateen, Ahmed and Zhu, Qingsheng and Afsar, Salman},
title = {Comparitive Analysis of Manual vs Automotive Testing for Software Quality},
year = {2018},
isbn = {9781450361019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3330089.3330121},
doi = {10.1145/3330089.3330121},
abstract = {Success and failure of Software depend upon the quality of a software selection of an appropriate model for development of the product. In previous research many techniques were used to check the quality of software. But it is still a challenge for developers to select which technique may be best suited for quality of software. Quality attribute requirements such as those for performance, security, modifiability, reliability, and usability have a considerable influence on the software architecture of a system. Architects need to understand their designs in terms of quality attributes. Software quality assurance (SQA) consists of a means of monitoring the software engineering processes and methods used to ensure quality. The methods by which this is accomplished are varied and may include ensuring conformance to one or more standards. Both manual and automated testing offer benefits and disadvantages. In manual testing (as the name suggests), test cases are executed manually (by a human, that is) without any support from tools or scripts. But with automated testing, test cases are executed with the assistance of tools, scripts, and software.},
booktitle = {Proceedings of the 7th International Conference on Software Engineering and New Technologies},
articleno = {21},
numpages = {7},
keywords = {Cloud Computing, Fog Computing, 5 G Network, Network Retrieval, Radio Access Network},
location = {Hammamet, Tunisia},
series = {ICSENT 2018}
}

@inproceedings{10.1145/3369740.3372752,
author = {Patel, Yashwant Singh and Banerjee, Sourasekhar and Misra, Rajiv and Das, Sajal K.},
title = {Low-Latency Energy-Efficient Cyber-Physical Disaster System Using Edge Deep Learning},
year = {2020},
isbn = {9781450377515},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3369740.3372752},
doi = {10.1145/3369740.3372752},
abstract = {Reported works on cyber-physical disaster systems (CPDS) deal with the assessment of loss and damage aftermath of a large-scale disaster such as earthquake, wildfire, and cyclone, etc. involves collecting data from the IoT devices sent to the cloud data centers for analysis, often causes high bandwidth usage with substantial delay. In our work, we have shown to eliminate bandwidth cost and reducing latency substantially suitable for post-disaster response for rescue operations. We propose a low-latency and energy-efficient CPDS applying cloud-IoT-edge by bringing intelligence and infer-encing proximity to the disaster site to detect the disaster events in real-time and inform to the rescue teams. The edge computing model of CPDS uses convolutional neural network (CNN) with MobileNetV2 lightweight model and gradient weighted class activation mapping (Grad-CAM++) to locate and quantify degree of the damage into classes- severe, mild, and no damage. We implemented CPDS on a real-world laboratory testbed that comprises resource-constrained edge devices (Raspberry Pi, smartphones, and PCs) and docker-based containerization of deep learning models and analyzed the computational complexity. With the rigorous experiments of the proposed approach, we evaluated the performance in terms of classification accuracy, energy saving, and end-to-end (E2E) delay comparing with the current state-of-the-art approaches.},
booktitle = {Proceedings of the 21st International Conference on Distributed Computing and Networking},
articleno = {34},
numpages = {6},
keywords = {Energy efficiency, Edge computing, Deep learning, Disaster damage assessment, Cyber-physical systems, Containerization},
location = {Kolkata, India},
series = {ICDCN 2020}
}

@article{10.1145/3358696,
author = {Tang, Yibin and Wang, Ying and Li, Huawei and Li, Xiaowei},
title = {MV-Net: Toward Real-Time Deep Learning on Mobile GPGPU Systems},
year = {2019},
issue_date = {December 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {4},
issn = {1550-4832},
url = {https://doi.org/10.1145/3358696},
doi = {10.1145/3358696},
abstract = {Recently the development of deep learning has been propelling the sheer growth of vision and speech applications on lightweight embedded and mobile systems. However, the limitation of computation resource and power delivery capability in embedded platforms is recognized as a significant bottleneck that prevents the systems from providing real-time deep learning ability, since the inference of deep convolutional neural networks (CNNs) and recurrent neural networks (RNNs) involves large quantities of weights and operations. Particularly, how to provide quality-of-services (QoS)-guaranteed neural network inference ability in the multitask execution environment of multicore SoCs is even more complicated due to the existence of resource contention. In this article, we present a novel deep neural network architecture, MV-Net, which provides performance elasticity and contention-aware self-scheduling ability for QoS enhancement in mobile computing systems. When the constraints of QoS, output accuracy, and resource contention status of the system change, MV-Net can dynamically reconfigure the corresponding neural network propagation paths and thus achieves an effective tradeoff between neural network computational complexity and prediction accuracy via approximate computing. The experimental results show that (1) MV-Net significantly improves the performance flexibility of current CNN models and makes it possible to provide always-guaranteed QoS in a multitask environment, and (2) it satisfies the quality-of-results (QoR) requirement, outperforming the baseline implementation significantly, and improves the system energy efficiency at the same time.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = oct,
articleno = {35},
numpages = {25},
keywords = {energy efficiency, Edge computing, approximate computing, online scheduling, deep learning}
}

@article{10.1145/3191764,
author = {Schaule, Florian and Johanssen, Jan Ole and Bruegge, Bernd and Loftness, Vivian},
title = {Employing Consumer Wearables to Detect Office Workers' Cognitive Load for Interruption Management},
year = {2018},
issue_date = {March 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {1},
url = {https://doi.org/10.1145/3191764},
doi = {10.1145/3191764},
abstract = {Office workers' productivity and well-being are reduced by interruptions, especially if they occur during an inconvenient moment. Interruptions in phases of high cognitive load are more disruptive than in phases of low cognitive load. Based on an explorative study, we suppose the presence of social codes that signal office workers' interruptibility. We propose a system that utilizes the cognitive load of an office worker to indicate situations suitable for interruptions. The cognitive load is inferred from office workers' physiological state measured by a consumer smartwatch. The system adapts an externally mounted smart device to indicate if the office worker is interruptible. To predict the cognitive load, we trained a classifier with ten office workers and achieved an accuracy between 66% and 86%. In order to validate the classifier's accurateness in an office setting, we performed a verification study with five office workers: We systematically triggered interruptions for each subject over an interval of half a day of office work. The classifier was able to infer the level of cognitive load for three office workers. This result supports our hypotheses that inferring cognitive load using a consumer smartwatch is a viable concept.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = mar,
articleno = {32},
numpages = {20},
keywords = {Productivity, Interruption Management System, Social Code, Automatic Interruptibility Measurement, Wearable Devices, Explorative Study, Office Environment, Cognitive Load}
}

@inproceedings{10.1145/3378679.3394529,
author = {Zhao, Yuchen and Haddadi, Hamed and Skillman, Severin and Enshaeifar, Shirin and Barnaghi, Payam},
title = {Privacy-Preserving Activity and Health Monitoring on Databox},
year = {2020},
isbn = {9781450371322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3378679.3394529},
doi = {10.1145/3378679.3394529},
abstract = {Activity recognition using deep learning and sensor data can help monitor activities and health conditions of people who need assistance in their daily lives. Deep Neural Network (DNN) models to infer the activities require data collected by in-home sensory devices. These data are often sent to a centralised cloud to be used for training the model. Centralising the data introduces privacy risks. The collected data contain sensitive information about the subjects. The cloud-based approach increases the risk that the data be stored and reused for other purposes without the owner's control. We propose a system that uses edge devices to implement activity and health monitoring locally and applies federated learning to facilitate the training process. The devices use the Databox platform to manage sensor data collected in people's homes, conduct activity recognition locally, and collaboratively train a DNN model without transferring the collected data into the cloud. We illustrate the applicability of the processing time of activity recognition on edge devices. We use a hierarchical model in which a global model is generated in the cloud, without requiring the raw data, and local models are trained on edge devices. The activity inference accuracy of the global model converges to a sufficient level after a few rounds of communication between edge devices and the cloud.},
booktitle = {Proceedings of the Third ACM International Workshop on Edge Systems, Analytics and Networking},
pages = {49–54},
numpages = {6},
keywords = {edge computing, federated learning, activity recognition},
location = {Heraklion, Greece},
series = {EdgeSys '20}
}

@article{10.1145/3381004,
author = {Wu, Yuezhong and Lin, Qi and Jia, Hong and Hassan, Mahbub and Hu, Wen},
title = {Auto-Key: Using Autoencoder to Speed Up Gait-Based Key Generation in Body Area Networks},
year = {2020},
issue_date = {March 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {1},
url = {https://doi.org/10.1145/3381004},
doi = {10.1145/3381004},
abstract = {With the rising popularity of wearable devices and sensors, shielding Body Area Networks (BANs) from eavesdroppers has become an urgent problem to solve. Since the conventional key distribution systems are too onerous for resource-constrained wearable sensors, researchers are pursuing a new light-weight key generation approach that enables two wearable devices attached at different locations of the user body to generate an identical key simultaneously simply from their independent observations of user gait. A key challenge for such gait-based key generation lies in matching the bits of the keys generated by independent devices despite the noisy sensor measurements, especially when the devices are located far apart on the body affected by different sources of noise. To address the challenge, we propose a novel machine learning framework, called Auto-Key, that uses an autoencoder to help one device predict the gait observations at another distant device attached to the same body and generate the key using the predicted sensor data. We prototype the proposed method and evaluate it using a public acceleration dataset collected from 15 real subjects wearing accelerometers attached to seven different locations of the body. Our results show that, on average, Auto-Key increases the matching rate of independently generated bits from two sensors attached at two different locations by 16.5%, which speeds up the successful generation of fully-matching symmetric keys at independent wearable sensors by a factor of 1.9. In the proposed framework, a subject-specific model can be trained with 50% fewer data and 88% less time by retraining a pre-trained general model when compared to training a new model from scratch. The reduced training complexity makes Auto-Key more practical for edge computing, which provides better privacy protection to biometric and behavioral data compared to cloud-based training.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = mar,
articleno = {32},
numpages = {23},
keywords = {Body Sensor Networks, Machine Learning, Device Pairing, Transfer learning, Wearable Communications, Autoencoder, Autonomic Symmetric Key Generation, Biometric Key Generation, Body Area Networks}
}

@inproceedings{10.1145/3297280.3297477,
author = {Maamar, Zakaria and Baker, Thar and Faci, Noura and Ugljanin, Emir and Khafajiy, Mohammed Al and Bur\'{e}gio, Vanilson},
title = {Towards a Seamless Coordination of Cloud and Fog: Illustration through the Internet-of-Things},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297280.3297477},
doi = {10.1145/3297280.3297477},
abstract = {With the increasing popularity of the Internet-of-Things (IoT), organizations are revisiting their practices as well as adopting new ones so they can deal with an ever-growing amount of sensed and actuated data that IoT-compliant things generate. Some of these practices are about the use of cloud and/or fog computing. The former promotes "anything-as-a-service" and the latter promotes "process data next to where it is located". Generally presented as competing models, this paper discusses how cloud and fog could work hand-in-hand through a seamless coordination of their respective "duties". This coordination stresses out the importance of defining where the data of things should be sent (either cloud, fog, or cloud&amp;fog concurrently) and in what order (either cloud then fog, fog then cloud, or fog&amp;cloud concurrently). Applications' concerns with data such as latency, sensitivity, and freshness dictate both the appropriate recipients and the appropriate orders. For validation purposes, a healthcare-driven IoT application along with an in-house testbed, that features real sensors and fog and cloud platforms, have permitted to carry out different experiments that demonstrate the technical feasibility of the coordination model.},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
pages = {2008–2015},
numpages = {8},
keywords = {fog, healthcare, cloud, internet-of-things, coordination},
location = {Limassol, Cyprus},
series = {SAC '19}
}

@inproceedings{10.1145/3377170.3377276,
author = {Cheng, Wenbo and Sun, Qibo and Zhang, Yasheng},
title = {Edge Assisted Object Detection for Mobile Application},
year = {2019},
isbn = {9781450376631},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377170.3377276},
doi = {10.1145/3377170.3377276},
abstract = {Object detection for mobile devices is meaningful especially in the field of IoT. Limited by computing power and network transmission, it's challenging to get high accuracy in mobile object detection. To solve this question, this article designs a system that enables high accuracy object detection running at 30fps for 720p videos. The system employs the object tracking technique, uses the caching technique, decouples the rendering pipeline from the offloading pipeline, and uses dynamic RoI encoding technique to get high detection accuracy. The result of the experiment shows that it can get 88% detection success rate. And it can also increase the detection accuracy by 17.7% and decrease the bandwidth by 52.6%.},
booktitle = {Proceedings of the 2019 7th International Conference on Information Technology: IoT and Smart City},
pages = {206–211},
numpages = {6},
keywords = {object tracking, edge computing, cache, Object detection},
location = {Shanghai, China},
series = {ICIT 2019}
}

@inproceedings{10.1145/3083187.3083192,
author = {Wang, Junjue and Amos, Brandon and Das, Anupam and Pillai, Padmanabhan and Sadeh, Norman and Satyanarayanan, Mahadev},
title = {A Scalable and Privacy-Aware IoT Service for Live Video Analytics},
year = {2017},
isbn = {9781450350020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3083187.3083192},
doi = {10.1145/3083187.3083192},
abstract = {We present OpenFace, our new open-source face recognition system that approaches state-of-the-art accuracy. Integrating OpenFace with inter-frame tracking, we build RTFace, a mechanism for denaturing video streams that selectively blurs faces according to specified policies at full frame rates. This enables privacy management for live video analytics while providing a secure approach for handling retrospective policy exceptions. Finally, we present a scalable, privacy-aware architecture for large camera networks using RTFace.},
booktitle = {Proceedings of the 8th ACM on Multimedia Systems Conference},
pages = {38–49},
numpages = {12},
keywords = {Cloud Computing, Privacy Mediator, Face Recognition, Privacy Protection, Cloudlet, Edge Computing},
location = {Taipei, Taiwan},
series = {MMSys'17}
}

@article{10.1145/3351286,
author = {Amiri, Delaram and Anzanpour, Arman and Azimi, Iman and Levorato, Marco and Liljeberg, Pasi and Dutt, Nikil and Rahmani, Amir M.},
title = {Context-Aware Sensing via Dynamic Programming for Edge-Assisted Wearable Systems},
year = {2020},
issue_date = {April 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {2},
issn = {2691-1957},
url = {https://doi.org/10.1145/3351286},
doi = {10.1145/3351286},
abstract = {Healthcare applications supported by the Internet of Things enable personalized monitoring of a patient in everyday settings. Such applications often consist of battery-powered sensors coupled to smart gateways at the edge layer. Smart gateways offer several local computing and storage services (e.g., data aggregation, compression, local decision making), and also provide an opportunity for implementing local closed-loop optimization of different parameters of the sensor layer, particularly energy consumption. To implement efficient optimization methods, information regarding the context and state of patients need to be considered to find opportunities to adjust energy to demanded accuracy. Edge-assisted optimization can manage energy consumption of the sensor layer but may also adversely affect the quality of sensed data, which could compromise the reliable detection of health deterioration risk factors. In this article, we propose two approaches: myopic and Markov decision processes (MDPs)—to consider both energy constraints and risk factor requirements for achieving a twofold goal: energy savings while satisfying accuracy requirements of abnormality detection in a patient’s vital signs. Vital signs, including heart rate, respiration rate, and oxygen saturation, are extracted from a photoplethysmogram signal and errors of extracted features are compared to a ground truth that is modeled as a Gaussian distribution. We control the sensor’s sensing energy to minimize the power consumption while meeting a desired level of satisfactory detection performance. We present experimental results on realistic case studies using a reconfigurable photoplethysmogram sensor in an IoT system, and show that compared to nonadaptive methods, myopic reduces an average of 16.9% in sensing energy consumption with the maximum probability of abnormality misdetection on the order of 0.17 in a 24-hour health monitoring system. In addition, over 4 weeks of monitoring, we demonstrate that our MDP policy can extend the battery life on average of more than 2x while fulfilling the same average probability of misdetection compared to the myopic method. We illustrate results comparing myopic, MDP, and nonadaptive methods to monitor 14 subjects over 1 month.},
journal = {ACM Trans. Comput. Healthcare},
month = mar,
articleno = {7},
numpages = {25},
keywords = {Health monitoring, energy efficiency, abnormality detection, edge/fog computing, edge-assisted control, wearable electronics, Internet of Things, context awareness}
}

@inproceedings{10.1145/3132479.3132484,
author = {Du, Wenwen and Xing, Kai and Gong, Haihua},
title = {Smart Phone Based Phubbing Walking Detection and Safety Warning},
year = {2017},
isbn = {9781450355285},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3132479.3132484},
doi = {10.1145/3132479.3132484},
abstract = {As the increasing popularity of smart phones, the phenomenon phubbing (phone and snubbing) walking, a distracted walking behavior much like conventional addictions, poses a rising concern on pedestrian safety. As reported, the typical American checks his or her smart-phone once every six-and-a-half minutes, or 150 times daily. By Liberty Mutual Insurance, it is found that 60 percent of people surveyed said they often drafted emails or updated their Facebook status on the move, even though 70 percent knew full well the risks of striding into oncoming traffic unawares.},
booktitle = {Proceedings of the Workshop on Smart Internet of Things},
articleno = {9},
numpages = {6},
location = {San Jose, California},
series = {SmartIoT '17}
}

@inproceedings{10.5555/3408352.3408621,
author = {Datta, Kamalika and Dutt, Arko and Zaky, Ahmed and Chand, Umesh and Singh, Devendra and Li, Yida and Huang, Jackson Chun-Yang and Thean, Aaron and Aly, Mohamed M Sabry},
title = {Fledge: Flexible Edge Platforms Enabled by in-Memory Computing},
year = {2020},
isbn = {9783981926347},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
abstract = {The proliferation of advanced analytics and artificial intelligence has been driven by huge volumes of data that are mostly generated at the edge. Simultaneously, there is a rising demand to perform analytics on edge platforms (i.e., near-sensor data analytics). However, conventional architectures of such platforms may not execute the targeted applications in an energy-efficient manner. Emerging near and in-memory computing paradigms can increase the energy efficiency of edge platforms by relying on emerging logic and memory devices. More importantly, these paradigms enable the possibility of performing computations on unconventional platforms, namely flexible computing systems. In this paper, we explore the benefits of in-memory computing at the edge on a flexible substrate enabled by thin-film transistors (TFTs) and resistive RAM (RRAM). As a case study, we consider bio-signal processing application workloads, i.e., compressive sensing and anomaly detection. We model the device, circuit, and architecture of our targeted platform and evaluate the corresponding system-level performance. Preliminary results indicate that in-memory computing enabled by flexible electronic devices enables a new class of edge platforms with lower power consumption, compared to that of rigid TFT devices.},
booktitle = {Proceedings of the 23rd Conference on Design, Automation and Test in Europe},
pages = {1181–1186},
numpages = {6},
keywords = {flexible electronics, RRAM, thin-film transistor, edge computing},
location = {Grenoble, France},
series = {DATE '20}
}

@inproceedings{10.1145/3331052.3332473,
author = {Kaur, Kuljeet and Garg, Sahil and Kaddoum, Georges and Ahmed, Syed Hassan and Jayakody, Dushantha Nalin K.},
title = {En-OsCo: Energy-Aware Osmotic Computing Framework Using Hyper-Heuristics},
year = {2019},
isbn = {9781450368056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3331052.3332473},
doi = {10.1145/3331052.3332473},
abstract = {The proliferation of the Internet of Things (IoT) has paved the way for many cloud based applications such as smart grid, healthcare, traffic management, finance, etc. In this vein, the need of transferring large data-streams to remote data centers is a key concern for modern Cloud-based IoT paradigms. This disrupts the remote Cloud Computing model, moving applications, data and computing resources to the logical extremes of the network. Thus, to handle streaming data in IoT environments, an efficient IoT-based computing model that can dynamically handle the interplay between Cloud and Edge data centers is required. In this direction, a recent paradigm, popularly known as Osmotic Computing, has emerged to ensure the acceptable performance of widely dispersed services. However, the burden of data-offloading across multiple data centers usually leads to a consequent increase in their energy consumption which in-turn will affect the overall Quality of Service (QoS) of the IoT-based applications. Keeping focus on all these issues, a consolidated decision making framework for Osmotic Computing, i.e., En-OsCo, is designed to ensure the energy-aware dynamic management of resources. The proposed framework incorporates four significant contributions: i) Resource monitoring of Edge data centers using Extended Kalman Filter, ii) Optimal dispatch of incoming services to the Edge/Cloud setup using Hyper-heuristics, iii) Minimizing the energy consumption of underlying data centers and reducing the service latency, and iv) Reducing the search space of Hyper-heuristics by keeping track of previously made decisions using Universal Streaming Monitoring. Further, in order to validate the efficacy of the proposed En-OsCo framework, ContainerCloudSim has been used in combination of HyFlex on PlanetLab datasets. The obtained results validate the purpose of the proposed scheme in minimizing the overall energy consumption of the computing setup while considerably reducing the latency.},
booktitle = {Proceedings of the ACM MobiHoc Workshop on Pervasive Systems in the IoT Era},
pages = {19–24},
numpages = {6},
keywords = {Cloud Computing, and Osmotic Computing, Latency Minimization, Energy Minimization, Edge Computing, Hyper-heuristics, Extended Kalman Filter},
location = {Catania, Italy},
series = {PERSIST-IoT '19}
}

@inproceedings{10.1145/3204949.3204952,
author = {Flores, Huber and Hui, Pan and Tarkoma, Sasu and Li, Yong and Anagnostopoulos, Theodoros and Kostakos, Vassilis and Luo, Chu and Su, Xiang},
title = {Sensorclone: A Framework for Harnessing Smart Devices with Virtual Sensors},
year = {2018},
isbn = {9781450351928},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3204949.3204952},
doi = {10.1145/3204949.3204952},
abstract = {IoT services hosted by low-power devices rely on the cloud infrastructure to propagate their ubiquitous presence over the Internet. A critical challenge for IoT systems is to ensure continuous provisioning of IoT services by overcoming network breakdowns, hardware failures, and energy constraints. To overcome these issues, we propose a cloud-based framework namely SensorClone, which relies on virtual devices to improve IoT resilience. A virtual device is the digital counterpart of a physical device that has learned to emulate its operations from sample data collected from the physical one. SensorClone exploits the collected data of low-power devices to create virtual devices in the cloud. SensorClone then can opportunistically migrate virtual devices from the cloud into other devices, potentially underutilized, with higher capabilities and closer to the edge of the network, e.g., smart devices. Through a real deployment of our SensorClone in the wild, we identify that virtual devices can be used for two purposes, 1) to reduce the energy consumption of physical devices by duty cycling their service provisioning between the physical device and the virtual representation hosted in the cloud, and 2) to scale IoT services at the edge of the network by harnessing temporal periods of underutilization of smart devices. To evaluate our framework, we present a use case of a virtual sensor created from an IoT service of temperature. From our results, we verify that it is possible to achieve unlimited availability up to 90% and substantial power efficiency under acceptable levels of quality of service. Our work makes contributions towards improving IoT scalability and resilience by using virtual devices.},
booktitle = {Proceedings of the 9th ACM Multimedia Systems Conference},
pages = {328–338},
numpages = {11},
keywords = {cloud computing, internet of things, edge computing, opportunistic migration, resilience, virtual sensor},
location = {Amsterdam, Netherlands},
series = {MMSys '18}
}

@inproceedings{10.1145/3316781.3317933,
author = {Prabakaran, Bharath Srinivas and Rehman, Semeen and Shafique, Muhammad},
title = {XBioSiP: A Methodology for Approximate Bio-Signal Processing at the Edge},
year = {2019},
isbn = {9781450367257},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3316781.3317933},
doi = {10.1145/3316781.3317933},
abstract = {Bio-signals exhibit high redundancy, and the algorithms for their processing are inherently error resilient. This property can be leveraged to improve the energy-efficiency of IoT-Edge (wearables) through the emerging trend of approximate computing. This paper presents XBioSiP, a novel methodology for approximate bio-signal processing that employs two quality evaluation stages, during the pre-processing and bio-signal processing stages, to determine the approximation parameters. It thereby achieves high energy savings while satisfying the user-determined quality constraint. Our methodology achieves, up to 19\texttimes{} and 22\texttimes{} reduction in the energy consumption of a QRS peak detection algorithm for 0% and &lt; 1% loss in peak detection accuracy, respectively.},
booktitle = {Proceedings of the 56th Annual Design Automation Conference 2019},
articleno = {184},
numpages = {6},
keywords = {Wearables, Multipliers, IoT, Bio-Signal, Hardware Design, Healthcare, Arithmetic Units, Energy-Efficiency, Approximate Computing, Edge Computing, Adders, ECG},
location = {Las Vegas, NV, USA},
series = {DAC '19}
}

@article{10.1145/3134842,
author = {Samie, Farzad and Tsoutsouras, Vasileios and Bauer, Lars and Xydis, Sotirios and Soudris, Dimitrios and Henkel, J\"{o}rg},
title = {Distributed Trade-Based Edge Device Management in Multi-Gateway IoT},
year = {2018},
issue_date = {July 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
issn = {2378-962X},
url = {https://doi.org/10.1145/3134842},
doi = {10.1145/3134842},
abstract = {The Internet-of-Things (IoT) envisions an infrastructure of ubiquitous networked smart devices offering advanced monitoring and control services. The current art in IoT architectures utilizes gateways to enable application-specific connectivity to IoT devices. In typical configurations, IoT gateways are shared among several IoT edge devices. Given the limited available bandwidth and processing capabilities of an IoT gateway, the service quality (SQ) of connected IoT edge devices must be adjusted over time not only to fulfill the needs of individual IoT device users but also to tolerate the SQ needs of the other IoT edge devices sharing the same gateway. However, having multiple gateways introduces an interdependent problem, the binding, i.e., which IoT device shall connect to which gateway.In this article, we jointly address the binding and allocation problems of IoT edge devices in a multigateway system under the constraints of available bandwidth, processing power, and battery lifetime. We propose a distributed trade-based mechanism in which after an initial setup, gateways negotiate and trade the IoT edge devices to increase the overall SQ. We evaluate the efficiency of the proposed approach with a case study and through extensive experimentation over different IoT system configurations regarding the number and type of the employed IoT edge devices. Experiments show that our solution improves the overall SQ by up to 56% compared to an unsupervised system. Our solution also achieves up to 24.6% improvement on overall SQ compared to the state-of-the-art SQ management scheme, while they both meet the battery lifetime constraints of the IoT devices.},
journal = {ACM Trans. Cyber-Phys. Syst.},
month = jun,
articleno = {17},
numpages = {25},
keywords = {Internet-of-Things, edge computing, computation offloading, constrained devices, IoT, distributed resource allocation}
}

@inproceedings{10.1145/3063386.3063771,
author = {Catlett, Charles E. and Beckman, Peter H. and Sankaran, Rajesh and Galvin, Kate Kusiak},
title = {Array of Things: A Scientific Research Instrument in the Public Way: Platform Design and Early Lessons Learned},
year = {2017},
isbn = {9781450349895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3063386.3063771},
doi = {10.1145/3063386.3063771},
abstract = {The "Array of Things" (AoT) project aims to create an urban- scale instrument for research and development across many disciplines. The concept is to exploit Internet of Things (IoT) technologies to build an instrument analogous to an array telescope, where many identical detectors spread over an area work as a unit. AoT, then, is an IoT-enabled "telescope" pointed at the city. With support from the National Science Foundation, the University of Chicago, Argonne National Laboratory, the City of Chicago, and industry the project has adapted an Argonne- developed resilient sensor-hosting platform, Waggle, for urban installations. The project will install 500 units, or "nodes," by late 2018, with installation in phases to allow for technology improvements based on evaluation of early installations as well as to enable one or more insertion points for component upgrades and expansions, such as emerging sensors. This paper describes the initial stages of the project, focusing on lessons learned in areas ranging from resilient technical design to manufacturing to privacy policies and public engagement.},
booktitle = {Proceedings of the 2nd International Workshop on Science of Smart City Operations and Platforms Engineering},
pages = {26–33},
numpages = {8},
keywords = {edge computing, data dissemination, wireless sensor networks, distributed systems, urban sensing},
location = {Pittsburgh, Pennsylvania},
series = {SCOPE '17}
}

@inproceedings{10.1145/3411170.3411242,
author = {Bujari, Armir and Bergamini, Claudio and Corradi, Antonio and Foschini, Luca and Palazzi, Claudio E. and Sabbioni, Andrea},
title = {A Geo-Distributed Architectural Approach Favouring Smart Tourism Development in the 5G Era},
year = {2020},
isbn = {9781450375597},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411170.3411242},
doi = {10.1145/3411170.3411242},
abstract = {The fast-paced evolution of ICT technology is revolutionizing our every day life, endowing us with a seamless digital assistant accessible through smart-devices. In this context, even the way we approach tourism and holidays has undergone many changes. In fact, most of us nowadays exploit smart devices to plan, book and manage the experience. This different approach to tourism is often called Smart Tourism and it is acquiring more and more importance for business, public administrations, and tourists themselves. The idea behind our proposal is to further enhance existing structure and services of a city, promoting and encouraging the smart tourism concept while satisfying the ever increasing necessity, dynamicity and stringent Quality of Service (QoS) requirements future application scenarios embody. To this end, we propose a conceptual architectural model following a Mobile Edge Computing (MEC) approach, exploiting virtualization and multiple geographically distributed Function as a Service (FaaS) edge clouds equipped with storage capabilities. While preserving the general aspect of our study and without loss of generality, we envision a reference scenario where users consume and produce data that are geographically bound to a location of interest. This modus operandi could help unlock smart tourism potential, focusing on local communal phenomena, harvesting socio-technical data which would otherwise not be possible on a global scale through traditional centralized information systems. Along with the proposal, we discuss some preliminary evaluation of the envisioned platform, outlining some research directions.},
booktitle = {Proceedings of the 6th EAI International Conference on Smart Objects and Technologies for Social Good},
pages = {12–17},
numpages = {6},
keywords = {publish-subscribe, NFV, Mobile edge computing, Function as a Service, location-based services, 5G},
location = {Antwerp, Belgium},
series = {GoodTechs '20}
}

@inproceedings{10.1145/3132479.3132491,
author = {Zhang, Peng and Shi, Xiang and Khan, Samee U.},
title = {Can Quantitative Finance Benefit from IoT?},
year = {2017},
isbn = {9781450355285},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3132479.3132491},
doi = {10.1145/3132479.3132491},
abstract = {The Internet of Things (IoT) is a novel paradigm that communicates information among smart devices that are connected to the Internet. In this context, such devices would leverage our understanding and capabilities of big data, deep analysis and artificial intelligence to solve problems in real-time. The IoT paradigm has successfully benefited many applications in the social sciences and industries. However, in the rise of IoT, there is at least one question that has been left unanswered: Can Quantitative Finance (QF) benefit from IoT? The QF is a field that extends sophisticated mathematical models and utilizes advanced computer techniques to link with global finance markets. By taking market and social information as input, a QF model can derive profitable insights and control the risk to make trading decisions. Today, many Internet-based techniques are extensively employed in the field as: (a) market and social data is provided via Internet; (b) big data infrastructures are built in the Cloud; and (c) deep learning tools are accessible in Internet. Even trading models and strategies could be exerted through Internet. In this paper, we will provide an overview of challenges and opportunities presented by this new paradigm in the QF industry. To unlock the potential of IoT, a system architecture, termed QuantCloud, is proposed for modern quantitative trading firms in the field.},
booktitle = {Proceedings of the Workshop on Smart Internet of Things},
articleno = {12},
numpages = {6},
keywords = {quantitative finance, cloud computing, internet of things, big data},
location = {San Jose, California},
series = {SmartIoT '17}
}

@inproceedings{10.1145/2677017.2677019,
author = {Bohez, Steven and De Coninck, Elias and Verbelen, Tim and Simoens, Pieter and Dhoedt, Bart},
title = {Enabling Component-Based Mobile Cloud Computing with the AIOLOS Middleware},
year = {2014},
isbn = {9781450332323},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2677017.2677019},
doi = {10.1145/2677017.2677019},
abstract = {Currently, mobile and wearable devices (such as smartphones and tablets) and cloud computing are converging in the new, rapidly growing field of mobile cloud computing. Emerging distributed cloud architectures such as edge clouds can be used to support and scale out resource-intensive, low-latency mobile applications. However, at the moment, a lot of burden is put on the application developer in order to develop and deploy distributed cloud-enabled mobile applications. Therefore, we present AIOLOS: an integrated middleware platform that supports transparent distributed deployment and scaling among mobile devices and cloud infrastructures. To evaluate the middleware, we show experimental results of AIOLOS using a complex 3D mapping use case.},
booktitle = {Proceedings of the 13th Workshop on Adaptive and Reflective Middleware},
articleno = {2},
numpages = {6},
keywords = {mobile cloud computing, OSGi, middleware},
location = {Bordeaux, France},
series = {ARM '14}
}

@inproceedings{10.1145/3312614.3312644,
author = {Farahani, Bahar and Barzegari, Mojtaba and Aliee, Fereidoon Shams},
title = {Towards Collaborative Machine Learning Driven Healthcare Internet of Things},
year = {2019},
isbn = {9781450366403},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3312614.3312644},
doi = {10.1145/3312614.3312644},
abstract = {The relationship between technology and healthcare due to the rise of Intelligent Internet of Things (IoT) and the rapid public embracement of medical-grade wearables has been dramatically transformed in the past few years. Powered by IoT, technology brought disruptive changes and unique opportunities to the healthcare industry including personalized services, tailored content, improved availability and accessibility, and cost-effective delivery. Despite these exciting advancements in transition from clinic-centric to patient-centric healthcare, many challenges still need to be tackled. The key to successfully unlock and enable this digital shift is adopting a holistic architecture to provide high-level of quality in attributes such as latency, availability, and real-time analytics processing. In this paper, we discuss applicability of Intelligent IoT based on Collaborative Machine Learning in healthcare and medicine by presenting a holistic multi-layer architecture. This solution enables real-time actionable insights which ultimately improves decision-making powers of patients and healthcare providers. The feasibility of such architecture is investigated by a case study, ECG-based arrhythmia detection, based on deep learning and Convolutional Neural Network (CNN) methods distributed across endpoint IoT Devices, Edge (Fog) nodes, and Cloud servers.},
booktitle = {Proceedings of the International Conference on Omni-Layer Intelligent Systems},
pages = {134–140},
numpages = {7},
keywords = {Machine Learning, Internet of Things, Health},
location = {Crete, Greece},
series = {COINS '19}
}

@article{10.1145/3365224,
author = {Wang, Hongfei and Li, Jianwen and He, Kun},
title = {Hierarchical Ensemble Reduction and Learning for Resource-Constrained Computing},
year = {2019},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {1},
issn = {1084-4309},
url = {https://doi.org/10.1145/3365224},
doi = {10.1145/3365224},
abstract = {Generic tree ensembles (such as Random Forest, RF) rely on a substantial amount of individual models to attain desirable performance. The cost of maintaining a large ensemble could become prohibitive in applications where computing resources are stringent. In this work, a hierarchical ensemble reduction and learning framework is proposed. Experiments show our method consistently outperforms RF in terms of both accuracy and retained ensemble size. In other words, ensemble reduction is achieved with enhancement in accuracy rather than degradation. The method can be executed efficiently, up to &gt;590\texttimes{} time reduction than a recent ensemble reduction work. We also developed Boolean logic encoding techniques to directly tackle multiclass problems. Moreover, our framework bridges the gap between software-based ensemble methods and hardware computing in the IoT era. We developed a novel conversion paradigm that supports the automatic deployment of &gt;500 trees on a chip. Our proposed method reduces power consumption and overall area utilization by &gt;21.5% and &gt;62%, respectively, comparing with RF. The hierarchical approach provides rich opportunities to balance between the computation (training and response time), the hardware resource (memory and energy), and accuracy.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = dec,
articleno = {12},
numpages = {21},
keywords = {edge computing, hardware implementation, Boolean logic, hardware and energy efficiency, hierarchical learning, Ensemble reduction, machine learning, logic minimization}
}

@inproceedings{10.1145/2991561.2991575,
author = {Soto, Jos\'{e} Angel Carvajal and Jentsch, Marc and Preuveneers, Davy and Ilie-Zudor, Elisabeth},
title = {CEML: Mixing and Moving Complex Event Processing and Machine Learning to the Edge of the Network for IoT Applications},
year = {2016},
isbn = {9781450348140},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2991561.2991575},
doi = {10.1145/2991561.2991575},
abstract = {The Internet of Things (IoT) is a growing field which is expected to generate and collect data everywhere at any time. Highly scalable cloud analytics systems are frequently being used to handle this data explosion. However, the ubiquitous nature of the IoT data imposes new technical and non-technical requirements which are difficult to address with a cloud deployment. To solve these problems, we need a new set of development technologies such as Distributed Data Mining and Ubiquitous Data Mining targeted and optimized towards IoT applications. In this paper, we present the Complex Event Machine Learning framework which proposes a set of tools for automatic distributed machine learning in (near-) real-time, automatic continuous evaluation tools, and automatic rules management for deployment of rules. These features are implemented for a deployment at the edge of the network instead of the cloud. We evaluate and validate our approach with a well-known classification problem.},
booktitle = {Proceedings of the 6th International Conference on the Internet of Things},
pages = {103–110},
numpages = {8},
keywords = {Internet of Things, Edge Computing, Complex Event Processing, Stream Mining, Machine Learning},
location = {Stuttgart, Germany},
series = {IoT'16}
}

@article{10.1145/3392156,
author = {Aral, Atakan and Erol-Kantarci, Melike and Brandi\'{c}, Ivona},
title = {Staleness Control for Edge Data Analytics},
year = {2020},
issue_date = {June 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {2},
url = {https://doi.org/10.1145/3392156},
doi = {10.1145/3392156},
abstract = {A new generation of cyber-physical systems has emerged with a large number of devices that continuously generate and consume massive amounts of data in a distributed and mobile manner. Accurate and near real-time decisions based on such streaming data are in high demand in many areas of optimization for such systems. Edge data analytics bring processing power in the proximity of data sources, reduce the network delay for data transmission, allow large-scale distributed training, and consequently help meeting real-time requirements. Nevertheless, the multiplicity of data sources leads to multiple distributed machine learning models that may suffer from sub-optimal performance due to the inconsistency in their states. In this work, we tackle the insularity, concept drift, and connectivity issues in edge data analytics to minimize its accuracy handicap without losing its timeliness benefits. To this end, we propose an efficient model synchronization mechanism for distributed and stateful data analytics. Staleness Control for Edge Data Analytics (SCEDA) ensures the high adaptability of synchronization frequency in the face of an unpredictable environment by addressing the trade-off between the generality and timeliness of the model. Making use of online reinforcement learning, SCEDA has low computational overhead, automatically adapts to changes, and does not require additional data monitoring.},
journal = {Proc. ACM Meas. Anal. Comput. Syst.},
month = jun,
articleno = {38},
numpages = {24},
keywords = {concept drift, non-stationarity, data stream processing, reinforcement learning, staleness control, edge computing}
}

@inproceedings{10.1145/3131704.3131709,
author = {Yu, Meihua and Ma, Yun and Liu, Xuanzhe and Huang, Gang and Chen, Xiangqun},
title = {AgileRabbit: A Feedback-Driven Offloading Middleware for Smartwatch Apps},
year = {2017},
isbn = {9781450353137},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3131704.3131709},
doi = {10.1145/3131704.3131709},
abstract = {With the rapid development of wearable devices such as smartwatches, we are brought to a new era of wearable computing. Due to limited computational capability, storage, and battery capacity, wearable devices can hardly execute computation-intensive tasks. The mainstream approach to overcoming these limitations is computation offloading, i.e., offloading the tasks to mobile devices or the remote cloud servers. However, computation offloading cannot improve performance or save power consumption under all conditions. For example, offloading may not be worth in the case of very poor network conditions. To address the issue, in this paper, we propose AgileRabbit, a feedback-driven middleware of computation offloading for smartwatch apps. We design an offloading decision algorithm using the feedback data with a given objective i.e., minimizing the task completion time, or minimizing the total power consumption of smartwatches and mobile devices. With the assistance of AgileRabbit, computation-intensive tasks in smartwatch apps can be well scheduled and assigned to the proper computation node. We implement a speech recognition application on Android Wear platform and deploy it on AgileRabbit to validate the effectiveness of our approach. Evaluation results show that AgileRabbit can significantly improve the performance and save power consumption while incurring small overheads.},
booktitle = {Proceedings of the 9th Asia-Pacific Symposium on Internetware},
articleno = {6},
numpages = {10},
keywords = {Middleware, Feedback-Driven, Computation Offloading, Smartwatch Applications},
location = {Shanghai, China},
series = {Internetware'17}
}

@inproceedings{10.1145/3381991.3395618,
author = {Bhatt, Smriti and Sandhu, Ravi},
title = {ABAC-CC: Attribute-Based Access Control and Communication Control for Internet of Things},
year = {2020},
isbn = {9781450375689},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3381991.3395618},
doi = {10.1145/3381991.3395618},
abstract = {Internet of Things (IoT) is revolutionizing the capabilities of the Internet with billions of connected devices in the cyberspace. These devices are commonly referred to as smart things enabling smart environments, such as Smart Home, Smart Health, Smart Transportation, and overall Smart Communities, together with key enabling technologies like Cloud Computing, Artificial Intelligence (AI) and Machine Learning (ML). Security and privacy are major concerns for today's diverse autonomous IoT ecosystem. Autonomous things and a large amount of data associated with things have fueled significant research in IoT access control and privacy in both academia and industry. To enable futuristic IoT with sustainable growth, dynamic access and communication control framework that adequately addresses security and privacy issues in IoT is inevitable. In this paper, we analyze the access and communication control requirements in Cloud-Enabled IoT (CE-IoT) and propose an attribute-based framework for access control and communication control, known as ABAC-CC, to secure accesses and communications (data flow) between various entities in the IoT architecture. We also introduce a novel Attribute-Based Communication Control (ABCC) model, which focuses on securing communications and data flow in IoT and enables users to define privacy policies using attributes of various entities. Furthermore, we analyze the applicability of ABAC-CC in specific IoT application domains, and finally, we present future research directions in the context of Cloud and Edge computing enabled IoT platforms.},
booktitle = {Proceedings of the 25th ACM Symposium on Access Control Models and Technologies},
pages = {203–212},
numpages = {10},
keywords = {attribute-based communication control, internet of things, attributes, message attributes, cloud-enabled iot, communication control},
location = {Barcelona, Spain},
series = {SACMAT '20}
}

@inbook{10.1145/3300061.3300116,
author = {Liu, Luyang and Li, Hongyu and Gruteser, Marco},
title = {Edge Assisted Real-Time Object Detection for Mobile Augmented Reality},
year = {2019},
isbn = {9781450361699},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3300061.3300116},
abstract = {Most existing Augmented Reality (AR) and Mixed Reality (MR) systems are able to understand the 3D geometry of the surroundings but lack the ability to detect and classify complex objects in the real world. Such capabilities can be enabled with deep Convolutional Neural Networks (CNN), but it remains difficult to execute large networks on mobile devices. Offloading object detection to the edge or cloud is also very challenging due to the stringent requirements on high detection accuracy and low end-to-end latency. The long latency of existing offloading techniques can significantly reduce the detection accuracy due to changes in the user's view. To address the problem, we design a system that enables high accuracy object detection for commodity AR/MR system running at 60fps. The system employs low latency offloading techniques, decouples the rendering pipeline from the offloading pipeline, and uses a fast object tracking method to maintain detection accuracy. The result shows that the system can improve the detection accuracy by 20.2%-34.8% for the object detection and human keypoint detection tasks, and only requires 2.24ms latency for object tracking on the AR device. Thus, the system leaves more time and computational resources to render virtual elements for the next frame and enables higher quality AR/MR experiences.},
booktitle = {The 25th Annual International Conference on Mobile Computing and Networking},
articleno = {25},
numpages = {16}
}

@inproceedings{10.1145/2594368.2594383,
author = {Ha, Kiryong and Chen, Zhuo and Hu, Wenlu and Richter, Wolfgang and Pillai, Padmanabhan and Satyanarayanan, Mahadev},
title = {Towards Wearable Cognitive Assistance},
year = {2014},
isbn = {9781450327930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2594368.2594383},
doi = {10.1145/2594368.2594383},
abstract = {We describe the architecture and prototype implementation of an assistive system based on Google Glass devices for users in cognitive decline. It combines the first-person image capture and sensing capabilities of Glass with remote processing to perform real-time scene interpretation. The system architecture is multi-tiered. It offers tight end-to-end latency bounds on compute-intensive operations, while addressing concerns such as limited battery capacity and limited processing capability of wearable devices. The system gracefully degrades services in the face of network failures and unavailability of distant architectural tiers.},
booktitle = {Proceedings of the 12th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {68–81},
numpages = {14},
keywords = {cyber foraging, cloudlet, cloud computing, virtual machine, cloud offload, google glass, wearable computing, mobile computing},
location = {Bretton Woods, New Hampshire, USA},
series = {MobiSys '14}
}

@inproceedings{10.1145/3083187.3084017,
author = {Chatzopoulos, Dimitris and Bermejo, Carlos and Huang, Zhanpeng and Butabayeva, Arailym and Zheng, Rui and Golkarifard, Morteza and Hui, Pan},
title = {Hyperion: A Wearable Augmented Reality System for Text Extraction and Manipulation in the Air},
year = {2017},
isbn = {9781450350020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3083187.3084017},
doi = {10.1145/3083187.3084017},
abstract = {We develop Hyperion a Wearable Augmented Reality (WAR) system based on Google Glass to access text information in the ambient environment. Hyperion is able to retrieve text content from users' current view and deliver the content to them in different ways according to their context. We design four work modalities for different situations that mobile users encounter in their daily activities. In addition, user interaction interfaces are provided to adapt to different application scenarios. Although Google Glass may be constrained by its poor computational capabilities and its limited battery capacity, we utilize code-level offloading to companion mobile devices to improve the runtime performance and the sustainability of WAR applications. System experiments show that Hyperion improves users ability to be aware of text information around them. Our prototype indicates promising potential of converging WAR technology and wearable devices such as Google Glass to improve people's daily activities.},
booktitle = {Proceedings of the 8th ACM on Multimedia Systems Conference},
pages = {284–295},
numpages = {12},
keywords = {AR, Google Glass, WAR, offloading, smart-glass, wearable},
location = {Taipei, Taiwan},
series = {MMSys'17}
}

@inproceedings{10.1145/3345768.3355906,
author = {Pratap, Ajay and Concone, Federico and Nadendla, Venkata Sriram Siddhardh and Das, Sajal K.},
title = {Three-Dimensional Matching Based Resource Provisioning for the Design of Low-Latency Heterogeneous IoT Networks},
year = {2019},
isbn = {9781450369046},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3345768.3355906},
doi = {10.1145/3345768.3355906},
abstract = {Internet-of-Things (IoT) is a networking architecture where promising, intelligent services are designed via leveraging information from multiple heterogeneous sources of data within the network. However, the availability of such information in a timely manner requires processing and communication of raw data collected from these sources. Therefore, the economic feasibility of IoT-enabled networks relies on the efficient allocation of both computational and communication resources within the network. Since fog computing and 5G cellular networks approach this problem independently, there is a need for joint resource-provisioning of both communication and computational resources in the networks. As the solution to this problem, we propose a novel three-dimensional matching based resource provisioning algorithm that minimizes average service latency in the presence of various resource constraints, task deadlines and non-identical preferences at IoT devices, fog access points (FAPs) and small-cell access points (SAPs) in 5G networks. We prove the stability and termination of the proposed algorithm and also demonstrate that our proposed algorithm outperforms other state-of-the-art algorithms through both, simulation and real-world experiments on the laboratory test-bed.},
booktitle = {Proceedings of the 22nd International ACM Conference on Modeling, Analysis and Simulation of Wireless and Mobile Systems},
pages = {79–86},
numpages = {8},
keywords = {fog, sap, 5g, matching, iot, resource provisioning, prb},
location = {Miami Beach, FL, USA},
series = {MSWIM '19}
}

@article{10.1145/3336121,
author = {Tariq, Umair Ullah and Ali, Haider and Liu, Lu and Panneerselvam, John and Zhai, Xiaojun},
title = {Energy-Efficient Static Task Scheduling on VFI-Based NoC-HMPSoCs for Intelligent Edge Devices in Cyber-Physical Systems},
year = {2019},
issue_date = {December 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {6},
issn = {2157-6904},
url = {https://doi.org/10.1145/3336121},
doi = {10.1145/3336121},
abstract = {The interlinked processing units in modern Cyber-Physical Systems (CPS) creates a large network of connected computing embedded systems. Network-on-Chip (NoC)-based Multiprocessor System-on-Chip (MPSoC) architecture is becoming a de facto computing platform for real-time applications due to its higher performance and Quality-of-Service (QoS). The number of processors has increased significantly on the multiprocessor systems in CPS; therefore, Voltage Frequency Island (VFI) has been recently adopted for effective energy management mechanism in the large-scale multiprocessor chip designs. In this article, we investigated energy-efficient and contention-aware static scheduling for tasks with precedence and deadline constraints on intelligent edge devices deploying heterogeneous VFI-based NoC-MPSoCs (VFI-NoC-HMPSoC) with DVFS-enabled processors. Unlike the existing population-based optimization algorithms, we proposed a novel population-based algorithm called ARSH-FATI that can dynamically switch between explorative and exploitative search modes at run-time. Our static scheduler ARHS-FATI collectively performs task mapping, scheduling, and voltage scaling. Consequently, its performance is superior to the existing state-of-the-art approach proposed for homogeneous VFI-based NoC-MPSoCs. We also developed a communication contention-aware Earliest Edge Consistent Deadline First (EECDF) scheduling algorithm and gradient descent--inspired voltage scaling algorithm called Energy Gradient Decent (EGD). We introduced a notion of Energy Gradient (EG) that guides EGD in its search for island voltage settings and minimize the total energy consumption.We conducted the experiments on eight real benchmarks adopted from Embedded Systems Synthesis Benchmarks (E3S). Our static scheduling approach ARSH-FATI outperformed state-of-the-art technique and achieved an average energy-efficiency of ∼24% and ∼30% over CA-TMES-Search and CA-TMES-Quick, respectively.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = oct,
articleno = {66},
numpages = {22},
keywords = {mapping, heterogeneous, DAG, energy-efficiency, task, contention, VFI-NoC-HMPSoCs, CPS, scheduling, SNS}
}

@inproceedings{10.1145/2955193.2955207,
author = {Ricart, Glenn},
title = {Slicing in Locavore Infrastructures},
year = {2016},
isbn = {9781450342209},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2955193.2955207},
doi = {10.1145/2955193.2955207},
abstract = {A Locavore Infrastructure is one which has all of its elements in high-bandwidth and low-latency proximity. It typically combines edge computing elements with an adjacent access network. The growing number of communicating devices and things creates a large and often steady demand for collecting and integrating local information in a Locavore Infrastructure. Slices of this infrastructure can provide architectural advantages in security, meeting performance expectations, and billing. Dynamic slices can provide some of the same kinds of surge capabilities for which traditional cloud computing is prized. Slices can be implemented using a variety of orchestration techniques.},
booktitle = {Proceedings of the 4th Workshop on Distributed Cloud Computing},
articleno = {4},
numpages = {6},
keywords = {internet of things, infrastructure hypervisor, slicing, edge, slices, locavore, edge security},
location = {Chicago, Illinois},
series = {DCC '16}
}

@inproceedings{10.1145/3297280.3297474,
author = {Gonzalez-Aparicio, Maria Teresa and Younas, Muhammad and Tuya, Javier and Casado, Rub\'{e}n},
title = {Evaluation of ACE Properties of Traditional SQL and NoSQL Big Data Systems},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297280.3297474},
doi = {10.1145/3297280.3297474},
abstract = {Traditional SQL and NoSQL big data systems are the backbone for managing data in cloud, fog and edge computing. This paper develops a new system and adopts the TPC-DS industry standard benchmark in order to evaluate three key properties, availability, consistency and efficiency (ACE) of SQL and NoSQL systems. The contributions of this work are manifold. It evaluates and analyses the tradeoff between the ACE properties. It provides insight into the NoSQL systems and how they can be improved to be sustainable for a more wide range of applications. The evaluation shows that SQL provides stronger consistency, but at the expense of low efficiency and availability. NoSQL provides better efficiency and availability but lacks support for stronger consistency. In order for NoSQL systems to be more sustainable they need to implement transactional schemes that enforce stronger consistency as well as better efficiency and availability.},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
pages = {1988–1995},
numpages = {8},
keywords = {big data, Riak, TPC-DS, SQL, data consistency, NoSQL},
location = {Limassol, Cyprus},
series = {SAC '19}
}

@inproceedings{10.1145/3408127.3408176,
author = {Huang, Yongfeng and Lin, Jianping and Wang, Guijin and Ding, Zijian and Sun, Li},
title = {A Multi-Dilation Convolution Neural Network for Atrial Fibrillation Detection},
year = {2020},
isbn = {9781450376877},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3408127.3408176},
doi = {10.1145/3408127.3408176},
abstract = {Atrial fibrillation (AF) is the most common cardiac arrhythmia whose management requires long-term automatic monitoring. The incidence of AF increases with age, causing high risks of stroke and increased morbidity and mortality. In this article, we propose a multi-dilation CNN (convolution neural network) for Atrial fibrillation detection. Our proposed model is provided with the ability to extract multi-scale features with fewer parameters by designing MSDC (multi-scale dilation convolution) blocks. The evaluation is performed on the MIT-BIH Atrial Fibrillation Database, and our multi-dilation CNN composed of MSDC blocks outperforms other methods with a sensitivity of 99.45% and specificity of 99.61%. Compared to ResNet the state of art method before, our model performs better with only a quarter parameter size of Reset, which is useful for the implementation of edge computing-based deep learning network on wearable ECG devices.},
booktitle = {Proceedings of the 2020 4th International Conference on Digital Signal Processing},
pages = {136–140},
numpages = {5},
keywords = {dilation convolution, wearable ECG devices, Atrial fibrillation, ResNet},
location = {Chengdu, China},
series = {ICDSP 2020}
}

@inproceedings{10.5555/3213200.3213208,
author = {Rajaei, Hassan and Mirzaei, Farbod},
title = {IoT, Smart Homes, and Zigbee Simulation},
year = {2018},
isbn = {9781510860155},
publisher = {Society for Computer Simulation International},
address = {San Diego, CA, USA},
abstract = {Internet of Things (IoT) is predicted to connect more than 50 billion devices to each other via the Internet by 2020. Smart homes and buildings are primary targets to continuously monitor the connected devices, collect data, process them, and provide feedback where and when it is needed. In this chain process of IoT, there are numerous nontrivial communications and computational issues. In this paper, we focus on smart homes and specifically on ZigBee, as a smart data collection element. We view several topologies and configurations using ZigBee connectivity in a typical smart home. In addition, we report a simulation study to shed some light on how ZigBee networks perform. To transfer the huge amount of collected data from smart homes in a timely manner and process it, we use the Fifth Generation (5G) of wireless network, and for processing the data we use Mobile Edge Computing (MEC) interacted with cloud.},
booktitle = {Proceedings of the Communications and Networking Symposium},
articleno = {8},
numpages = {10},
keywords = {wireless network, zigbee, performance, IoT (internet of things), bluetooth},
location = {Baltimore, Maryland},
series = {CNS '18}
}

@article{10.1145/3331147,
author = {Li, Xiaoming and Xu, Guangquan and Zheng, Xi and Liang, Kaitai and Panaousis, Emmanouil and Li, Tao and Wang, Wei and Shen, Chao},
title = {Using Sparse Representation to Detect Anomalies in Complex WSNs},
year = {2019},
issue_date = {December 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {6},
issn = {2157-6904},
url = {https://doi.org/10.1145/3331147},
doi = {10.1145/3331147},
abstract = {In recent years, wireless sensor networks (WSNs) have become an active area of research for monitoring physical and environmental conditions. Due to the interdependence of sensors, a functional anomaly in one sensor can cause a functional anomaly in another sensor, which can further lead to the malfunctioning of the entire sensor network. Existing research work has analysed faulty sensor anomalies but fails to show the effectiveness throughout the entire interdependent network system. In this article, a dictionary learning algorithm based on a non-negative constraint is developed, and a sparse representation anomaly node detection method for sensor networks is proposed based on the dictionary learning. Through experiment on a specific thermal power plant in China, we verify the robustness of our proposed method in detecting abnormal nodes against four state of the art approaches and proved our method is more robust. Furthermore, the experiments are conducted on the obtained abnormal nodes to prove the interdependence of multi-layer sensor networks and reveal the conditions and causes of a system crash.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = oct,
articleno = {64},
numpages = {18},
keywords = {Dependency relationships networks, Sparse Representation, WSNs, anomaly detection}
}

@article{10.1145/3402524,
author = {M\"{a}kitalo, Niko and Flores-Martin, Daniel and Flores, Huber and Lagerspetz, Eemil and Christophe, Francois and Ihantola, Petri and Babazadeh, Masiar and Hui, Pan and Murillo, Juan Manuel and Tarkoma, Sasu and Mikkonen, Tommi},
title = {Human Data Model: Improving Programmability of Health and Well-Being Data for Enhanced Perception and Interaction},
year = {2020},
issue_date = {November 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {4},
issn = {2691-1957},
url = {https://doi.org/10.1145/3402524},
doi = {10.1145/3402524},
abstract = {Today, an increasing number of systems produce, process, and store personal and intimate data. Such data has plenty of potential for entirely new types of software applications, as well as for improving old applications, particularly in the domain of smart healthcare. However, utilizing this data, especially when it is continuously generated by sensors and other devices, with the current approaches is complex—data is often using proprietary formats and storage, and mixing and matching data of different origin is not easy. Furthermore, many of the systems are such that they should stimulate interactions with humans, which further complicates the systems. In this article, we introduce the Human Data Model—a new tool and a programming model for programmers and end users with scripting skills that help combine data from various sources, perform computations, and develop and schedule computer-human interactions. Written in JavaScript, the software implementing the model can be run on almost any computer either inside the browser or using Node.js. Its source code can be freely downloaded from GitHub, and the implementation can be used with the existing IoT platforms. As a whole, the work is inspired by several interviews with professionals, and an online survey among healthcare and education professionals, where the results show that the interviewed subjects almost entirely lack ideas on how to benefit the ever-increasing amount of data measured of the humans. We believe that this is because of the missing support for programming models for accessing and handling the data, which can be satisfied with the Human Data Model.},
journal = {ACM Trans. Comput. Healthcare},
month = sep,
articleno = {26},
numpages = {39},
keywords = {ubiquitous computing, Human Data Model, Internet of Things, Mobile computing, data management, pervasive computing, data mashups, IoT, programmable world, wearable computers}
}

@article{10.1145/3092819.3092823,
author = {Cardellini, Valeria and Grassi, Vincenzo and Lo Presti, Francesco and Nardelli, Matteo},
title = {Optimal Operator Replication and Placement for Distributed Stream Processing Systems},
year = {2017},
issue_date = {March 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {4},
issn = {0163-5999},
url = {https://doi.org/10.1145/3092819.3092823},
doi = {10.1145/3092819.3092823},
abstract = {Exploiting on-the-fly computation, Data Stream Processing (DSP) applications are widely used to process unbounded streams of data and extract valuable information in a near real-time fashion. As such, they enable the development of new intelligent and pervasive services that can improve our everyday life. To keep up with the high volume of daily produced data, the operators that compose a DSP application can be replicated and placed on multiple, possibly distributed, computing nodes, so to process the incoming data flow in parallel. Moreover, to better exploit the abundance of diffused computational resources (e.g., Fog computing), recent trends investigate the possibility of decentralizing the DSP application placement.In this paper, we present and evaluate a general formulation of the optimal DSP replication and placement (ODRP) as an integer linear programming problem, which takes into account the heterogeneity of application requirements and infrastructural resources. We integrate ODRP as prototype scheduler in the Apache Storm DSP framework. By leveraging on the DEBS 2015 Grand Challenge as benchmark application, we show the benefits of a joint optimization of operator replication and placement and how ODRP can optimize different QoS metrics, namely response time, internode traffic, cost, availability, and a combination thereof.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = may,
pages = {11–22},
numpages = {12}
}

@inproceedings{10.1145/3282308.3282320,
author = {Dobaj, J\"{u}rgen and Iber, Johannes and Krisper, Michael and Kreiner, Christian},
title = {A Microservice Architecture for the Industrial Internet-Of-Things},
year = {2018},
isbn = {9781450363877},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282308.3282320},
doi = {10.1145/3282308.3282320},
abstract = {With the introduction of Internet-of-Things (IoT) and cyber-physical system (CPS) concepts the industrial automation sector is undergoing enormous change towards highly interconnected and globally distributed automation systems. Following this trend the industry is facing interoperability challenges between devices and systems, which origin in the market and technology fragmentation of the past years. However, established integration techniques from the IoT domain cannot be fully adapted in industrial Internet-of-Things (IIoT) environments due to stricter dependability and real time constraints.Since design patterns offer a practical means to gain a deeper understanding of the problem domain, patterns are applied in this paper to develop a software architecture that is suitable for the deployment in the upcoming IIoT environments. The resulting software architecture combines ideas from the IoT world, industrial automation systems, as well as modern information technology (IT) and cloud architectures. Its lightweight and flexible design, along with the support of state-of-the-art development approaches (containerization, continuous integration (CI), continuous deployment (CD)) make the architecture equally suitable for the deployment on cloud, fog and edge devices. All in all, these features facilitate the deployment of services and communication protocols on device level, to enable the transparent and automatic integration of heterogenous devices and protocols, on demand.},
booktitle = {Proceedings of the 23rd European Conference on Pattern Languages of Programs},
articleno = {11},
numpages = {15},
keywords = {Industry 4.0, CPS, SoA, IIoT, IoT, Microservice, Software Architecture, Industrial Automation, Patterns},
location = {Irsee, Germany},
series = {EuroPLoP '18}
}

@article{10.1145/3230641,
author = {Feng, Jun and Yang, Laurence T. and Zhang, Ronghao},
title = {Practical Privacy-Preserving High-Order Bi-Lanczos in Integrated Edge-Fog-Cloud Architecture for Cyber-Physical-Social Systems},
year = {2019},
issue_date = {April 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {2},
issn = {1533-5399},
url = {https://doi.org/10.1145/3230641},
doi = {10.1145/3230641},
abstract = {Smart environments, also referred to as cyber-physical-social systems (CPSSs), are expected to significantly benefit from the integration of edge, fog, and cloud for intelligence service flexibility, efficiency, and cost saving. High-order Bi-Lanczos method has emerged as a powerful tool serving as multi-dimensional data processing, such as prevailing feature extraction, classification, and clustering of high-order data, in CPSSs. However, integrated edge-fog-cloud architecture is open and users have very limited control; how to carry out big data processing without compromising the security and privacy is a challenging issue in edge-fog-cloud-assisted smart applications. In this work, we propose a novel and practical privacy-preserving high-order Bi-Lanczos scheme in integrated edge-fog-cloud architectural paradigm for smart environments. More precisely, we first propose a privacy-preserving big data processing model using the synergy of edge, fog, and cloud. The proposed model enables edge, fog, and cloud to cooperatively complete big data processing without compromising users’ privacy for large-scale tensor data in CPSSs. Subsequently, making use of the model, we present a privacy-preserving high-order Bi-Lanczos scheme. Finally, we theoretically and empirically analyze the security and efficiency of the proposed privacy-preserving high-order Bi-Lanczos scheme based on an intelligent surveillance system case study. And the results demonstrate that the proposed scheme provides a privacy-preserving and efficient way of computations in integrated edge-fog-cloud paradigm for smart environments.},
journal = {ACM Trans. Internet Technol.},
month = mar,
articleno = {26},
numpages = {18},
keywords = {cyber-physical-social systems, edge-fog-cloud computing, privacy preservation, Smart environments, tensor, high-order Bi-Lanczos}
}

@inproceedings{10.1145/2649563.2649577,
author = {Al Ali, Rima and Gerostathopoulos, Ilias and Gonzalez-Herrera, Inti and Juan-Verdejo, Adrian and Kit, Michal and Surajbali, Bholanathsingh},
title = {An Architecture-Based Approach for Compute-Intensive Pervasive Systems in Dynamic Environments},
year = {2014},
isbn = {9781450330596},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2649563.2649577},
doi = {10.1145/2649563.2649577},
abstract = {Distributed systems have continued to evolve and we note two important trends: the dramatically increasing level of dynamism in contemporary distributed systems and the convergence of mobile computing with cloud computing. The end result is that it is very difficult to achieve the required level of scalability and dependability in a systematic way when considering pervasive systems that are software- and compute-intensive and whose functionality is typically augmented by static cloud infrastructure resources. This work discusses relevant challenges and requirements for integrating cloud computing with pervasive systems operating in dynamic environments. We present a set of requirements using a holistic case study and describe a framework approach to address these requirements.},
booktitle = {Proceedings of the 2nd International Workshop on Hot Topics in Cloud Service Scalability},
articleno = {3},
numpages = {6},
location = {Dublin, Ireland},
series = {HotTopiCS '14}
}

@inproceedings{10.1145/2993412.3004852,
author = {D\'{\i}az, Jessica and P\'{e}rez, Jennifer and P\'{e}rez, Jorge and Garbajosa, Juan},
title = {Conceptualizing a Framework for Cyber-Physical Systems of Systems Development and Deployment},
year = {2016},
isbn = {9781450347815},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2993412.3004852},
doi = {10.1145/2993412.3004852},
abstract = {Cyber-physical systems (CPS) refer to the next generation of embedded ICT systems that are interconnected, collaborative and that provide users and businesses with a wide range of smart applications and services. Software in CPS applications ranges from small systems to large systems, aka. Systems of Systems (SoS), such as smart grids and cities. CPSoS require managing massive amounts of data, being aware of their emerging behavior, and scaling out to progressively evolve and add new systems. Cloud computing supports processing and storing massive amounts of data, hosting and delivering services, and configuring self-provisioned resources. Therefore, cloud computing is the natural candidate to solve CPSoS needs. However, the diversity of platforms and the low-level cloud programming models make difficult to find a common solution for the development and deployment of CPSoS. This paper presents the architectural foundations of a cloud-centric framework for automating the development and deployment of CPSoS service applications to converge towards a common open service platform for CPSoS applications. This framework relies on the well-known qualities of the microservices architecture style, the autonomic computing paradigm, and the model-driven software development approach. Its implementation and validation is on-going at two European and national projects.},
booktitle = {Proccedings of the 10th European Conference on Software Architecture Workshops},
articleno = {1},
numpages = {7},
keywords = {microservices, model-driven development, software architecture, cloud computing, cyber-physical systems},
location = {Copenhagen, Denmark},
series = {ECSAW '16}
}

@inproceedings{10.1145/3345252.3345279,
author = {Pe\v{s}i\'{c}, Sa\v{s}a and To\v{s}i\'{c}, Milenko and Ikovi\'{c}, Ognjen and Radovanovi\'{c}, Milo\v{s} and Ivanovi\'{c}, Mirjana and Bo\v{s}kovi\'{c}, Dragan},
title = {Conceptualizing a Collaboration Framework between Blockchain Technology and the Internet of Things},
year = {2019},
isbn = {9781450371490},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3345252.3345279},
doi = {10.1145/3345252.3345279},
abstract = {The Internet of Things (IoT) system is a concept that binds together multiple deployments of heterogenous distributed and decentralized systems. In such systems it is very hard to keep track of user data, enforce complex privacy policies, ensure safe data storage and sharing, as well as employ an efficient mechanism for process and resource management. Blockchain is a technology that emerged in 2008 with Bitcoin, and has proven to be effective in solving these problems. IoT applications are distributed by nature. Hence, distributed ledger technology (DLT) such as blockchain has the potential to play a significant role in how devices communicate in IoT. This paper will address these issues by introducing the high-level concept of blockchain as a service or BCaaS - a blockchain-based framework for internal and external collaboration throughout the IoT ecosystem. It will also discuss current problems with IoT and blockchain technologies integration, as well as how to overcome them.},
booktitle = {Proceedings of the 20th International Conference on Computer Systems and Technologies},
pages = {56–61},
numpages = {6},
keywords = {Blockchain, framework, Internet of Things},
location = {Ruse, Bulgaria},
series = {CompSysTech '19}
}

@inproceedings{10.1145/3288599.3288635,
author = {Du, Bowen and Lu, Chris Xiaoxuan and Kan, Xuan and Wu, Kai and Luo, Man and Hou, Jianfeng and Li, Kai and Kanhere, Salil and Shen, Yiran and Wen, Hongkai},
title = {HydraDoctor: Real-Time Liquids Intake Monitoring by Collaborative Sensing},
year = {2019},
isbn = {9781450360944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3288599.3288635},
doi = {10.1145/3288599.3288635},
abstract = {Water has been widely acknowledged as an essential part of all living things. It is the fundamental necessity for all life's activities and most biochemical reactions in human body are executed in water. Therefore, the type and quantity of liquid intake everyday have a critical impact on individuals' health. In this paper, we demonstrate HydraDoctor, a real-time liquids intake monitoring system which is able to detect drinking activities, classify the categories of liquids and estimate the amount of intake. The system runs on multiple platforms including a smartwatch to detect the motion of hands and a smartglass to capture the images of mugs. A smartphone is also used as an edge computing platform and a remote server is designed for computationally intensive image processing. In HydraDoctor, multiple state-of-the-art machine learning techniques are applied: a Support Vector Machine (SVM)-based classifier is proposed to achieve accurate and efficient liquids intake monitoring, which is trained to detect the hand raising action. Both of them are well optimized to enable in-situ processing on smartwatch. To provide more robust and detailed monitoring, the smartglass is also incorporated and trigged to capture a short video clip in the front of the user when potential drinking activity is detected. The smartglass will send the video clip to the remote server via its companion smartphone and a Faster-RCNN is performed on the server to confirm the detected drinking activity and identify the type of intake liquid. According to our evaluation on the real-world experiments, HydraDoctor achieves very high accuracy both in drinking activity detection and types of liquids classification, whose accuracy is 85.64% and 84% respectively.},
booktitle = {Proceedings of the 20th International Conference on Distributed Computing and Networking},
pages = {213–217},
numpages = {5},
keywords = {liquid identification, activity recognition, liquid intake monitor},
location = {Bangalore, India},
series = {ICDCN '19}
}

@inproceedings{10.1145/3404555.3404640,
author = {Zhang, Zhen and Li, Hongqiang and Gong, Zheng and Jin, Rize and Chung, Tae-Sun},
title = {A Compatible ECG Diagnosis Cloud Computing Framework and Prototype Application},
year = {2020},
isbn = {9781450377089},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3404555.3404640},
doi = {10.1145/3404555.3404640},
abstract = {The ECG signal analysis and diagnosis algorithms have been studied for decades. There are some state of art algorithms that have been developed. In this paper, we proposed a compatible ECG automatic diagnosis Cloud Computing framework in order to integrate these exist algorithms. On the other hand, there are many studies regarding the IoT based health diagnosis system. But there are few of that aiming at the personal use health monitor and diagnose. Basing on our proposed framework, users can diagnose their heart health status by themselves conveniently anywhere and anytime through the mobile application. The ECG character automatic classification computing algorithm is compatible for Python and MATLAB by introducing the hybrid programming technic on the cloud computing side. So that, it is easy for researchers to integrate their developed algorithm into this framework to build an application quickly. We developed a prototype application as well to verify the availability of this framework.},
booktitle = {Proceedings of the 2020 6th International Conference on Computing and Artificial Intelligence},
pages = {135–139},
numpages = {5},
keywords = {Compatible, prototype application, cloud computing framework, ECG automatic diagnosis, python and MATLAB hybrid programming},
location = {Tianjin, China},
series = {ICCAI '20}
}

@inproceedings{10.1145/3396956.3396989,
author = {Pinheiro Junior, Luiz and Alexandra Cunha, Maria and Janssen, Marijn and Matheus, Ricardo},
title = {Towards a Framework for Cloud Computing Use by Governments: Leaders, Followers and Laggers},
year = {2020},
isbn = {9781450387910},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3396956.3396989},
doi = {10.1145/3396956.3396989},
abstract = {There are large varieties of governmental organizations using clouds in different ways. The purpose of this article is to explore and classify the types of public organizations using cloud computing. This will help to improve our understanding of cloud adoption and use by governments. For this, a systematic review of literature on cloud government (CloudGov) was performed by searching for articles in several databases. The review resulted into the main elements of the framework for classifying cloud use. In addition, using diffusion of innovation and institutional theory a categorization of public organizations was made. When applying the CloudGov framework empirically in government organizations, we identified three types of organizations: Leaders, Followers and Laggers. The types differ in various ways including their technology expertise, attitude towards innovation and level of political support. In further research, we recommend investigating which drivers influence the type of CloudGov users and generalize the framework to other contexts.},
booktitle = {The 21st Annual International Conference on Digital Government Research},
pages = {155–163},
numpages = {9},
keywords = {CloudGov, Cloud Computing, Adoption, Use, Framework, Government},
location = {Seoul, Republic of Korea},
series = {dg.o '20}
}

@inproceedings{10.1145/3026724.3026736,
author = {Li, Yuhong and Bj\"{o}rck, Fredrik and Xue, Haoyue},
title = {IoT Architecture Enabling Dynamic Security Policies},
year = {2016},
isbn = {9781450347969},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3026724.3026736},
doi = {10.1145/3026724.3026736},
abstract = {The Internet of Things (IoT) architecture is expected to evolve into a model containing various open systems, integrated environments, and platforms, which can be programmed and can provide secure services on demand. However, not much effort has been devoted towards the security of such an IoT architecture. In this paper, we present an IoT architecture that supports deploying dynamic security policies for IoT services. In this approach, IoT devices, gateways, and data are open and programmable to IoT application developers and service operators. Fine-grained security policies can be programmed and dynamically adjusted according to users' requirements, devices' capabilities and networking environments. The implementation and test results show that new security policies can be created and deployed rapidly and demonstrate the feasibility of the architecture.},
booktitle = {Proceedings of the 4th International Conference on Information and Network Security},
pages = {50–54},
numpages = {5},
keywords = {Software-defined networking (SDN), Internet of Things (IoT)},
location = {Kuala Lumpur, Malaysia},
series = {ICINS '16}
}

@article{10.1145/3387918,
author = {Zhao, Zhuoran and Barijough, Kamyar Mirzazad and Gerstlauer, Andreas},
title = {Network-Level Design Space Exploration of Resource-Constrained Networks-of-Systems},
year = {2020},
issue_date = {July 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {4},
issn = {1539-9087},
url = {https://doi.org/10.1145/3387918},
doi = {10.1145/3387918},
abstract = {Driven by recent advances in networking and computing technologies, distributed application scenarios are increasingly deployed on resource-constrained processing platforms. This includes networked embedded and cyber-physical systems as well as edge computing in mobile applications and the Internet of Things (IoT). In such resource-constrained Networks-of-Systems (NoS), computation and communication workloads need to be carefully co-optimized yet are tightly coupled. How to optimally partition and schedule application tasks among an appropriately designed NoS architecture requires a simultaneous consideration of design parameters from applications and processing platforms all the way to network configurations. Traditionally, however, systems and networks are designed in isolation and combined in an ad hoc manner, which ignores joint effects and optimization opportunities. To systematically explore and optimize NoS design spaces, a higher level of design abstraction on top of traditional system and network design is required.In this article, we propose a novel network-level design methodology for resource-constrained NoS optimization and design space exploration. A key component in such a design flow is fast yet accurate network/system co-simulation to rapidly evaluate NoS parameters with high fidelity. We first introduce a novel NoS simulator (NoSSim) that integrates source-level simulation models of applications with a host-compiled system simulation platform and a reconfigurable network simulation backplane to accurately capture system and network interactions. The co-simulation platform is further combined with model generation tools and a multi-objective genetic search algorithm to provide a comprehensive and fully automated NoS design space exploration framework. Finally, we apply our network-level design flow on several state-of-art IoT/mobile design case studies. Results show that NoSSim can achieve more than 86% simulation accuracy on average as compared to a real-world edge device cluster, where sensitivities to various design parameters are faithfully captured with high fidelity. When applying our network-level design space exploration methodology, design decisions are automatically optimized, where non-obvious NoS configurations are discovered outperforming manually designed solutions by more than 45%.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = jun,
articleno = {22},
numpages = {26},
keywords = {design space exploration, Source-level simulation, networks-of-systems}
}

@article{10.1145/3379506,
author = {Bhatia, Munish and Kaur, Simranpreet and Sood, Sandeep K.},
title = {IoT-Inspired Smart Toilet System for Home-Based Urine Infection Prediction},
year = {2020},
issue_date = {July 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {3},
issn = {2691-1957},
url = {https://doi.org/10.1145/3379506},
doi = {10.1145/3379506},
abstract = {The healthcare industry is the premier domain that has been significantly influenced by incorporation of Internet of Things (IoT) technology resulting in smart healthcare application. Inspired by the enormous potential of IoT technology, this research provides a framework for an IoT-based smart toilet system, which enables home-based determination of Urinary Infection (UI) efficaciously. The overall system comprises a four-layered architecture for monitoring and predicting infection in urine. The layers include the Urine Acquisition, Urine Analyzation, Temporal Extraction, and Temporal Prediction layers, which enable an individual to monitor his or her health on daily basis and predict UI so that precautionary measures can be taken at early stages. Moreover, probabilistic quantification of urine infection in the form of Degree of Infectiousness (DoI) and Infection Index Value (IIV) were performed for infection prediction based on a temporal Artificial Neural Network. In addition, the presence of UI is displayed to the user based on a Self-Organized Mapping technique. For validation purposes, numerous experimental simulations were performed on four individuals for 60 days. Results were compared with different state-of-the-art techniques for measuring the overall efficiency of the proposed system.},
journal = {ACM Trans. Comput. Healthcare},
month = may,
articleno = {14},
numpages = {25},
keywords = {smart toilet system, Internet of Things, temporal prediction, SOM visualization}
}

@inproceedings{10.1145/3357150.3357395,
author = {Kr\'{o}l, Micha\l{} and Mastorakis, Spyridon and Oran, David and Kutscher, Dirk},
title = {Compute First Networking: Distributed Computing Meets ICN},
year = {2019},
isbn = {9781450369701},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3357150.3357395},
doi = {10.1145/3357150.3357395},
abstract = {Modern distributed computing frameworks and domain-specific languages provide a convenient and robust way to structure large distributed applications and deploy them on either data center or edge computing environments. The current systems suffer however from the need for a complex underlay of services to allow them to run effectively on existing Internet protocols. These services include centralized schedulers, DNS-based name translation, stateful load balancers, and heavy-weight transport protocols. In contrast, ICN-oriented remote invocation methodologies provide an attractive match for current distributed programming languages by supporting both functional programming and stateful objects such as Actors. In this paper we design a computation graph representation for distributed programs, realize it using Conflict-free Replicated Data Types (CRDTs) as the underlying data structures, and employ RICE (Remote Method Invocation for ICN) as the execution environment. We show using NDNSim simulations that it provides attractive benefits in simplicity, performance, and failure resilience.},
booktitle = {Proceedings of the 6th ACM Conference on Information-Centric Networking},
pages = {67–77},
numpages = {11},
keywords = {thunks, in-network processing, naming, Information Centric Networks, Named Data Networking},
location = {Macao, China},
series = {ICN '19}
}

@inproceedings{10.1145/3054977.3054982,
author = {Li, Xin and Wang, Huazhe and Yu, Ye and Qian, Chen},
title = {An IoT Data Communication Framework for Authenticity and Integrity},
year = {2017},
isbn = {9781450349666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3054977.3054982},
doi = {10.1145/3054977.3054982},
abstract = {Internet of Things has been widely applied in everyday life, ranging from transportation, healthcare, to smart homes. As most IoT devices carry constrained resources and limited storage capacity, sensing data need to be transmitted to and stored at resource-rich platforms, such as a cloud. IoT applications retrieve sensing data from the cloud for analysis and decision-making purposes. Ensuring the authenticity and integrity of the sensing data is essential for the correctness and safety of IoT applications. We summarize the new challenges of the IoT data communication framework with authenticity and integrity and argue that existing solutions cannot be easily adopted. We present two solutions, called Dynamic Tree Chaining (DTC) and Geometric Star Chaining (GSC) that provide authenticity, integrity, sampling uniformity, system efficiency, and application flexibility to IoT data communication. Extensive simulations and prototype emulation experiments driven by real IoT data show that the proposed system is more efficient than alternative solutions in terms of time and space.},
booktitle = {Proceedings of the Second International Conference on Internet-of-Things Design and Implementation},
pages = {159–170},
numpages = {12},
keywords = {IoT, Partial Data Retrieval, Sampling, Cloud, Authentication},
location = {Pittsburgh, PA, USA},
series = {IoTDI '17}
}

@inproceedings{10.1145/3369740.3372767,
author = {Krishnaswamy, Dilip},
title = {Performance Considerations for Edge Blockchain Systems in Emerging 5G Data Networks},
year = {2020},
isbn = {9781450377515},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3369740.3372767},
doi = {10.1145/3369740.3372767},
abstract = {As edge computing applications become increasingly relevant to society, data processing and storage requirements are expected to increase at the 5G networked edge. At the same time, with the emergence of blockchain and distributed ledger technologies, one can provide support for trust, immutability, and transparency to share information among networked entities at the edge and in the cloud in 5G networks. A performance model for a permissioned private blockchain platform is developed. Depending on the latency sensitivity and throughput requirements of a 5G edge application, different possibilities are explored to provide support for blockchain technology at the edge. In particular, applications to 5G use-cases are considered, and lazy ledger decoupling between the 5G edge and the 5G cloud is proposed to meet edge latency constraints.},
booktitle = {Proceedings of the 21st International Conference on Distributed Computing and Networking},
articleno = {47},
numpages = {6},
keywords = {Throughput, Blockchain Systems, 5G Data Network, 5G Edge Data Centers, Latency, Edge Processing, Distributed Ledger Technology},
location = {Kolkata, India},
series = {ICDCN 2020}
}

@inproceedings{10.1145/3075564.3076259,
author = {Llewellynn, Tim and Fern\'{a}ndez-Carrobles, M. Milagro and Deniz, Oscar and Fricker, Samuel and Storkey, Amos and Pazos, Nuria and Velikic, Gordana and Leufgen, Kirsten and Dahyot, Rozenn and Koller, Sebastian and Goumas, Georgios and Leitner, Peter and Dasika, Ganesh and Wang, Lei and Tutschku, Kurt},
title = {BONSEYES: Platform for Open Development of Systems of Artificial Intelligence: Invited Paper},
year = {2017},
isbn = {9781450344876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3075564.3076259},
doi = {10.1145/3075564.3076259},
abstract = {The Bonseyes EU H2020 collaborative project aims to develop a platform consisting of a Data Marketplace, a Deep Learning Toolbox, and Developer Reference Platforms for organizations wanting to adopt Artificial Intelligence. The project will be focused on using artificial intelligence in low power Internet of Things (IoT) devices ("edge computing"), embedded computing systems, and data center servers ("cloud computing"). It will bring about orders of magnitude improvements in efficiency, performance, reliability, security, and productivity in the design and programming of systems of artificial intelligence that incorporate Smart Cyber-Physical Systems (CPS). In addition, it will solve a causality problem for organizations who lack access to Data and Models. Its open software architecture will facilitate adoption of the whole concept on a wider scale. To evaluate the effectiveness, technical feasibility, and to quantify the real-world improvements in efficiency, security, performance, effort and cost of adding AI to products and services using the Bonseyes platform, four complementary demonstrators will be built. Bonseyes platform capabilities are aimed at being aligned with the European FI-PPP activities and take advantage of its flagship project FIWARE. This paper provides a description of the project motivation, goals and preliminary work.},
booktitle = {Proceedings of the Computing Frontiers Conference},
pages = {299–304},
numpages = {6},
keywords = {Smart Cyber-Physical Systems, Deep Learning, Data marketplace, Internet of things},
location = {Siena, Italy},
series = {CF'17}
}

@inproceedings{10.1145/3231053.3231055,
author = {Usman, Muhammad and Asghar, Muhammad Rizwan and Granelli, Fabrizio and Qaraqe, Khalid},
title = {Integrating Smart City Applications in 5G Networks},
year = {2018},
isbn = {9781450364287},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3231053.3231055},
doi = {10.1145/3231053.3231055},
abstract = {Typical smart city applications generally require two different communications infrastructures, a wide area cellular network to provide connectivity and long-range communications and efficient communication strategies for transmitting short data packets, particularly in case of Internet of Things (IoT) devices. The cellular infrastructure is optimized for high data rates and large data sizes while IoT devices mostly exchange small data packets with high energy efficiency and low data rates. To fully exploit both communication infrastructures together, different strategies related to 5G and Device-to-Device (D2D) communications are proposed in literature. In this paper, we survey these strategies and provide useful considerations for seamless integration of smart city applications in 5G networks. Moreover, we present smart city scenarios, their communication requirements and the potential impact on the life of citizens. Finally, we elaborate big data impact on smart cities with possible security and privacy concerns.},
booktitle = {Proceedings of the 2nd International Conference on Future Networks and Distributed Systems},
articleno = {2},
numpages = {5},
keywords = {smart city, internet-of-things, D2D communications, 5G networks},
location = {Amman, Jordan},
series = {ICFNDS '18}
}

@inproceedings{10.1109/CHASE.2017.121,
author = {Li, Peilong and Xu, Chen and Luo, Yan and Cao, Yu and Mathew, Jomol and Ma, Yunsheng},
title = {Carenet: Building Regulation-Compliant Home-Based Healthcare Services with Software-Defined Infrastructure},
year = {2017},
isbn = {9781509047215},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CHASE.2017.121},
doi = {10.1109/CHASE.2017.121},
abstract = {Healthcare network and computing infrastructure is rapidly changing from closed environments to open environments that incorporate new devices and new application scenarios. Home-based healthcare is such an example of leveraging pervasive sensors and analyzing sensor data (often in real-time) to guide therapy or intervene. In this paper, we address the challenges in regulatory compliance when designing and deploying healthcare applications on a heterogeneous cloud environment. We propose the CareNet framework, consisting of a set of APIs and secure data transmission mechanisms, to facilitate the specification of home-based healthcare services running on the software-defined infrastructure (SDI). This work is a collaboration among computer scientists, medical researchers, healthcare IT and healthcare providers, and its goal is to reduce the gap between the availability of SDI and meeting regulatory compliance in healthcare applications. Our prototype demonstrates the feasibility of the framework and serves as testbed for novel experimental studies of emerging healthcare applications.},
booktitle = {Proceedings of the Second IEEE/ACM International Conference on Connected Health: Applications, Systems and Engineering Technologies},
pages = {373–382},
numpages = {10},
keywords = {home-based healthcare, XaaS, CORD, software-defined infrastructure, HIPAA compliance},
location = {Philadelphia, Pennsylvania},
series = {CHASE '17}
}

@inproceedings{10.1145/3364544.3364826,
author = {Anjana, M. S. and Ramesh, Maneesha Vinodini and Devidas, Aryadevi Remanidevi and Athira, K.},
title = {Fractal IoT: A Scalable IoT Framework for Energy Management in Connected Buildings},
year = {2019},
isbn = {9781450370158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3364544.3364826},
doi = {10.1145/3364544.3364826},
abstract = {Reported status of traditional energy and renewable energy resources indicate that their shortage is increasing at a rate twice that of the energy demand. This has motivated researchers to explore techniques for efficient, systematic management of energy. In this work we propose a fractal IoT architecture for smart community to addressed the challenges such as variation of energy availability, accessibility and demand. The architecture is deployed and tested in several scenarios such as Smart Building Smart Grid and Microgrid. A solar Microgrid setup is installed in a tribal village in Kerala, India consisting of 42 homes. This paper explains how the different features are integrated to develop smart buildings, and self-sustainable autonomous neighborhood's using these multiple case studies. The experimental result shows that the system is able to achieve the IoT features such as adaptability, interoperability and scalability by providing consistent performance in the hostel buildings with 800 occupants as well as homes totaling of 126 occupants in the tribal village.},
booktitle = {Proceedings of the 1st ACM International Workshop on Technology Enablers and Innovative Applications for Smart Cities and Communities},
pages = {10–17},
numpages = {8},
keywords = {Smart Building, self-sustainable community, IoT Framework, connected buildings, energy management, Microgrid},
location = {New York, NY, USA},
series = {TESCA'19}
}

@inproceedings{10.1145/3286680.3286684,
author = {Valcarenghi, L. and Martini, B. and Antevski, K. and Bernardos, C. J. and Landi, G. and Capitani, M. and Mangues-Bafalluy, J. and Martinez, R. and Baranda, J. and Pascual, I. and Ksentini, A. and Chiasserini, C. F. and Malandrino, F. and Li, Xi and Andrushko, D. and Tomakh, Konstantin},
title = {A Framework for Orchestration and Federation of 5G Services in a Multi-Domain Scenario},
year = {2018},
isbn = {9781450360838},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3286680.3286684},
doi = {10.1145/3286680.3286684},
abstract = {This paper presents the design of the 5GT Service Orchestrator (SO), which is one of the key components of the 5G-TRANSFORMER (5GT) system for the deployment of vertical services. Depending on the requests from verticals, the 5GT-SO offers service or resource orchestration and federation. These functions include all tasks related to coordinating and providing the vertical with an integrated view of services and resources from multiple administrative domains. In particular, service orchestration entails managing end-to-end services that are split into various domains based on requirements and availability. Federation entails managing administrative relations at the interface between the SOs belonging to different domains and handling abstraction of services. The SO key functionalities, architecture, interfaces, as well as two sample use cases for service federation and service and resource orchestration are presented. Results for the latter use case show that a vertical service is deployed in the order of minutes.},
booktitle = {Proceedings of the Workshop on Experimentation and Measurements in 5G},
pages = {19–24},
numpages = {6},
keywords = {federation, end-to-end service orchestration, NFV, 5G, mobile transport},
location = {Heraklion, Greece},
series = {EM-5G'18}
}

@inproceedings{10.1145/3230833.3232800,
author = {Samaila, Musa G. and Sequeiros, Jo\~{a}o B. F. and Freire, M\'{a}rio M. and In\'{a}cio, Pedro R. M.},
title = {Security Threats and Possible Countermeasures in IoT Applications Covering Different Industry Domains},
year = {2018},
isbn = {9781450364485},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3230833.3232800},
doi = {10.1145/3230833.3232800},
abstract = {The world is witnessing the emerging role of Internet of Things (IoT) as a technology that is transforming different industries, global community and its economy. Currently a plethora of interconnected smart devices have been deployed for diverse pervasive applications and services, and billions more are expected to be connected to the Internet in the near future. The potential benefits of IoT include improved quality of life, convenience, enhanced energy efficiency, and more productivity. Alongside these potential benefits, however, come increased security risks and potential for abuse. Arguably, this is partly because many IoT start-ups and electronics hobbyists lack security expertise, and some established companies do not make security a priority in their designs, and hence they produce IoT devices that are often ill-equipped in terms of security. In this paper, we discuss different IoT application areas, and identify security threats in IoT architecture. We consider security requirements and present typical security threats for each of the application domains. Finally, we present several possible security countermeasures, and introduce the IoT Hardware Platform Security Advisor (IoT-HarPSecA) framework, which is still under development. IoT-HarPSecA is aimed at facilitating the design and prototyping of secure IoT devices.},
booktitle = {Proceedings of the 13th International Conference on Availability, Reliability and Security},
articleno = {16},
numpages = {9},
keywords = {Security framework, Security, IoT-HarPSecA, Security requirements, Internet of Things, Application domains},
location = {Hamburg, Germany},
series = {ARES 2018}
}

@article{10.1145/3417987,
author = {Waheed, Nazar and He, Xiangjian and Ikram, Muhammad and Usman, Muhammad and Hashmi, Saad Sajid and Usman, Muhammad},
title = {Security and Privacy in IoT Using Machine Learning and Blockchain: Threats and Countermeasures},
year = {2020},
issue_date = {February 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3417987},
doi = {10.1145/3417987},
abstract = {Security and privacy of users have become significant concerns due to the involvement of the Internet of Things (IoT) devices in numerous applications. Cyber threats are growing at an explosive pace making the existing security and privacy measures inadequate. Hence, everyone on the Internet is a product for hackers. Consequently, Machine Learning (ML) algorithms are used to produce accurate outputs from large complex databases, where the generated outputs can be used to predict and detect vulnerabilities in IoT-based systems. Furthermore, Blockchain (BC) techniques are becoming popular in modern IoT applications to solve security and privacy issues. Several studies have been conducted on either ML algorithms or BC techniques. However, these studies target either security or privacy issues using ML algorithms or BC techniques, thus posing a need for a combined survey on efforts made in recent years addressing both security and privacy issues using ML algorithms and BC techniques. In this article, we provide a summary of research efforts made in the past few years, from 2008 to 2019, addressing security and privacy issues using ML algorithms and BC techniques in the IoT domain. First, we discuss and categorize various security and privacy threats reported in the past 12 years in the IoT domain. We then classify the literature on security and privacy efforts based on ML algorithms and BC techniques in the IoT domain. Finally, we identify and illuminate several challenges and future research directions using ML algorithms and BC techniques to address security and privacy issues in the IoT domain.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {122},
numpages = {37},
keywords = {cybersecurity, Blockchain, Internet of Things, machine learning}
}

@article{10.1145/3320075,
author = {Li, Wei and Chang, Xiaomin and Cao, Junwei and Yang, Ting and Sun, Yaojie and Zomaya, Albert Y.},
title = {A Sustainable and User-Behavior-Aware Cyber-Physical System for Home Energy Management},
year = {2019},
issue_date = {October 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {4},
issn = {2378-962X},
url = {https://doi.org/10.1145/3320075},
doi = {10.1145/3320075},
abstract = {There is a growing trend for employing cyber-physical systems to help smart homes improve the comfort of residents. However, a residential cyber-physical system is different from a common cyber-physical system since it directly involves human interaction, which is full of uncertainty. The existing solutions could be effective for performance enhancement in some cases when no inherent and dominant human factors are involved. Besides, the rapidly rising interest in the deployments of cyber-physical systems at home does not normally integrate with energy management schemes, which is a central issue that smart homes have to face. In this article, we propose a cyber-physical-system-based energy management framework to enable a sustainable-edge computing paradigm while meeting the needs of home energy management and residents. This framework aims to enable the full use of renewable energy while reducing electricity bills for households. A prototype system was implemented using real-world hardware. The experiment results demonstrated that renewable energy is fully capable of supporting the reliable running of home appliances most of the time and electricity bills could be cut by up to 60% when our proposed framework was employed.},
journal = {ACM Trans. Cyber-Phys. Syst.},
month = sep,
articleno = {37},
numpages = {24},
keywords = {scheduling, renewable energy, energy management, Cyber-physical system, human interaction}
}

@inproceedings{10.1145/2968456.2974004,
author = {Samie, Farzad and Bauer, Lars and Henkel, J\"{o}rg},
title = {IoT Technologies for Embedded Computing: A Survey},
year = {2016},
isbn = {9781450344838},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2968456.2974004},
doi = {10.1145/2968456.2974004},
abstract = {Emergence of Internet-of-Things brings a whole new class of applications and higher efficiency for existing services. Application-specific requirements, as well as connectivity and communication ability of devices have introduced new challenges for IoT applications.This paper provides an overview of IoT technologies required from an embedded design perspective and specific properties associated with IoT in embedded systems' landscape. We investigate essential technologies for development of IoT systems, existing trends, and its distinguishing properties. By discussing the key characteristics, main application domains, and major research issues in IoT, this paper provides a comprehensive IoT perspective for embedded system design.},
booktitle = {Proceedings of the Eleventh IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis},
articleno = {8},
numpages = {10},
location = {Pittsburgh, Pennsylvania},
series = {CODES '16}
}

@inproceedings{10.1145/3386164.3387295,
author = {Paudel, Nilakantha and Neupane, Ram C.},
title = {A General Architecture for a Real-Time Monitoring System Based on the Internet of Things},
year = {2019},
isbn = {9781450376617},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386164.3387295},
doi = {10.1145/3386164.3387295},
abstract = {Recently there has been significant progress in the real-time monitoring system based on the Internet of Things (IoT). The use rate of IoT has been increasing exponentially because of its enormous application in different areas, with many of them are yet to be explored. This paper explains how to design an IoT system and describes its working mechanism. We present a general architecture of the real-time monitoring system using IoT and related services. We successfully implement our proposed architecture for a single domain. Then, we describe how to use the proposed architecture to monitor the different real-time contextual domains. Also, we present ideas on how to plug the data from a third-party application into the proposed architecture.},
booktitle = {Proceedings of the 2019 3rd International Symposium on Computer Science and Intelligent Control},
articleno = {38},
numpages = {12},
keywords = {Real Time monitoring system, Big Data Computation, IoT, Standard Architecture, Internet of Things, Context Base System},
location = {Amsterdam, Netherlands},
series = {ISCSIC 2019}
}

@inproceedings{10.1145/3241403.3241449,
author = {Mass, Jakob and Chang, Chii and Srirama, Satish Narayana},
title = {Context-Aware Edge Process Management for Mobile Thing-to-Fog Environment},
year = {2018},
isbn = {9781450364836},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3241403.3241449},
doi = {10.1145/3241403.3241449},
abstract = {Service-oriented Workflow Management Systems (WfMS) have been utilised as an efficient solution to manage the objects and activities involved in Internet of Things (IoT) systems. As researchers have identified the drawbacks of the conventional centralised architecture which relies on the distant, central management server for managing all processes, recent IoT systems architectures have started including mechanisms for distributing computational or networking processes and decision making at the edge network, where the front-end IoT devices are located. We term processes involved in this paradigm as Edge Processes. Managing Edge Processes faces challenges when the involved IoT devices are moving. Specifically, improper timing of executing processes &amp; their subtasks will cause the waste of resources such as battery consumption. Hence, edge processes require adaptive scheduling schemes to increase efficiency and reduce waste of resources. In this paper, we propose an edge process management system architecture together with an adaptive task scheduling scheme which addresses the described issue.},
booktitle = {Proceedings of the 12th European Conference on Software Architecture: Companion Proceedings},
articleno = {44},
numpages = {7},
keywords = {internet of mobile things, task scheduling, edge process management},
location = {Madrid, Spain},
series = {ECSA '18}
}

@inproceedings{10.1145/3427423.3427442,
author = {Pramukantoro, Eko Sakti and Gofuku, Akio},
title = {Prototype of Multi-Layer Personal Cardiac Monitoring System for Data Interoperability Problem},
year = {2020},
isbn = {9781450376051},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3427423.3427442},
doi = {10.1145/3427423.3427442},
abstract = {Personal monitoring of heart conditions offers an advantage as a prevention mechanism for cardiovascular disease. This system can be developed using a wearable sensor device along with IoT approach. However, the data interoperability problem often arises in attempt to develop an IoT-based system. Data interoperability comes from different data formats to save the data that are produced by health sensor devices. The current solution can be either cloud or edge-based middleware which both have their own merits and drawbacks. This study offers multi-layer monitoring heart conditions that combines cloud and edge-based middleware to solve data interoperability. The middleware on the edge layer performs data normalization using the JSON format and Restful API standard to transfer data to communicate with an IoT application. On the other hand, at the cloud side, it provides heterogeneous data storage with the ability to store various health data formats.},
booktitle = {Proceedings of the 5th International Conference on Sustainable Information Engineering and Technology},
pages = {84–89},
numpages = {6},
keywords = {cloud application, cardiovascular disease, interoperability, IoT},
location = {Malang, Indonesia},
series = {SIET '20}
}

@inproceedings{10.1145/2968219.2979129,
author = {Viroli, Mirko and Casadei, Roberto and Pianini, Danilo},
title = {On Execution Platforms for Large-Scale Aggregate Computing},
year = {2016},
isbn = {9781450344623},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2968219.2979129},
doi = {10.1145/2968219.2979129},
abstract = {Aggregate computing is proposed as a computational model and associated toolchain to engineer adaptive large-scale situated systems, including IoT and wearable computing systems. Though originated in the context of WSN-like (peer-to-peer and fully distributed) systems, we argue it is a model that can transparently fit a variety of execution platforms (decentralised, server-mediated, cloud/fog-oriented), due to its ability of declaratively designing systems by global-level abstractions: it opens the possibility of intrinsically supporting forms of load balancing, elasticity and toleration of medium- and long-term changes of computational infrastructures. To ground the discussion, we present ongoing work in the context of scafi, a language and platform support for computational fields based on the Scala programming language and Akka actor framework.},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct},
pages = {1321–1326},
numpages = {6},
keywords = {large-scale systems, execution platforms, internet of things, aggregate computing, cloud computing},
location = {Heidelberg, Germany},
series = {UbiComp '16}
}

@article{10.1145/3428152,
author = {Can, Yekta Said and Ersoy, Cem},
title = {Privacy-Preserving Federated Deep Learning for Wearable IoT-Based Biomedical Monitoring},
year = {2021},
issue_date = {February 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {1},
issn = {1533-5399},
url = {https://doi.org/10.1145/3428152},
doi = {10.1145/3428152},
abstract = {IoT devices generate massive amounts of biomedical data with increased digitalization and development of the state-of-the-art automated clinical data collection systems. When combined with advanced machine learning algorithms, the big data could be useful to improve the health systems for decision-making, diagnosis, and treatment. Mental healthcare is also attracting attention, since most medical problems can be associated with mental states. Affective computing is among the emerging biomedical informatics fields for automatically monitoring a person’s mental state in ambulatory environments by using physiological and physical signals. However, although affective computing applications are promising to improve our daily lives, before analyzing physiological signals, privacy issues and concerns need to be dealt with. Federated learning is a promising candidate for developing high-performance models while preserving the privacy of individuals. It is a privacy protection solution that stores model parameters instead of the data itself and abides by the data protection laws such as EU General Data Protection Regulation (GDPR) and California Consumer Privacy Act (CCPA). We applied federated learning to heart activity data collected with smart bands for stress-level monitoring in different events. We achieved encouraging results for using federated learning in IoT-based wearable biomedical monitoring systems by preserving the privacy of the data.},
journal = {ACM Trans. Internet Technol.},
month = jan,
articleno = {21},
numpages = {17},
keywords = {federated learning, data protection, PPG, Privacy-preserving, stress detection, smartwatch, deep learning, affective computing}
}

@article{10.1145/3027947.3027953,
author = {Qadir, Junaid and Sathiaseelan, Arjuna and Wang, Liang and Crowcroft, Jon},
title = {“Resource Pooling” for Wireless Networks: Solutions for the Developing World},
year = {2016},
issue_date = {October 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {4},
issn = {0146-4833},
url = {https://doi.org/10.1145/3027947.3027953},
doi = {10.1145/3027947.3027953},
abstract = {We live in a world in which there is a great disparity between the lives of the rich and the poor. Technology offers great promise in bridging this gap. In particular, wireless technology unfetters developing communities from the constraints of infrastructure providing a great opportunity to leapfrog years of neglect and technological waywardness. In this paper, we highlight the role of resource pooling for wireless networks in the developing world. Resource pooling involves (i) abstracting a collection of networked resources to behave like a single unified resource pool and (ii) developing mechanisms for shifting load between the various parts of the unified resource pool. The popularity of resource pooling stems from its ability to provide resilience, high utilization, and flexibility at an acceptable cost. We show that ``resource pooling'', which is very popular in its various manifestations, is the key unifying principle underlying a diverse number of successful wireless technologies (such as white space networking, community networks, etc.). We discuss various applications of resource pooled wireless technologies and provide a discussion on open issues.},
journal = {SIGCOMM Comput. Commun. Rev.},
month = dec,
pages = {30–35},
numpages = {6},
keywords = {Network design principles, Resource pooling}
}

@article{10.1145/3394956,
author = {Sahoo, Kshira Sagar and Puthal, Deepak},
title = {SDN-Assisted DDoS Defense Framework for the Internet of Multimedia Things},
year = {2020},
issue_date = {January 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {3s},
issn = {1551-6857},
url = {https://doi.org/10.1145/3394956},
doi = {10.1145/3394956},
abstract = {The Internet of Things is visualized as a fundamental networking model that bridges the gap between the cyber and real-world entity. Uniting the real-world object with virtualization technology is opening further opportunities for innovation in nearly every individual’s life. Moreover, the usage of smart heterogeneous multimedia devices is growing extensively. These multimedia devices that communicate among each other through the Internet form a unique paradigm called the Internet of Multimedia Things (IoMT). As the volume of the collected data in multimedia application increases, the security, reliability of communications, and overall quality of service need to be maintained. Primarily, distributed denial of service attacks unveil the pervasiveness of vulnerabilities in IoMT systems. However, the Software Defined Network (SDN) is a new network architecture that has the central visibility of the entire network, which helps to detect any attack effectively. In this regard, the combination of SDN and IoMT, termed SD-IoMT, has the immense ability to improve the network management and security capabilities of the IoT system. This article proposes an SDN-assisted two-phase detection framework, namely SD-IoMT-Protector, in which the first phase utilizes the entropy technique as the detection metric to verify and alert about the malicious traffic. The second phase has trained with an optimized machine learning technique for classifying different attacks. The outcomes of the experimental results signify the usefulness and effectiveness of the proposed framework for addressing distributed denial of service issues of the SD-IoMT system.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = dec,
articleno = {98},
numpages = {18},
keywords = {security, IoMT, machine learning, Control plane, entropy, SDN}
}

@inproceedings{10.1145/3109761.3109780,
author = {Aljebry, Dalal F. and Tahir, Sabeen},
title = {Internet of Things Routing Technique Survey},
year = {2017},
isbn = {9781450352437},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3109761.3109780},
doi = {10.1145/3109761.3109780},
abstract = {Internet of Things (IoTs) consists of small devices with wireless links, sensing, and computation. Many routing, energy management, and data distribution techniques have been particularly designed for IoTs where efficient routing is a critical issue. The main focus is the routing techniques that might vary depending on the whole network structure. In this paper, we offer a review of the state-of-the-art routing techniques in IoTs. We first highlight the routing challenges in IoTs followed by a complete survey of variant routing techniques. Overall, the routing techniques are classified into two groups based on the network architecture: the clustering and non-clustering techniques. Moreover, these techniques can be categorized into sub-techniques. We also emphasize the benefits of IoTs and performance issues of all routing technique. The survey paper concludes with possible future recommendations.},
booktitle = {Proceedings of the 1st International Conference on Internet of Things and Machine Learning},
articleno = {19},
numpages = {7},
keywords = {energy efficiency, IoT, routing, instability network, network lifetime},
location = {Liverpool, United Kingdom},
series = {IML '17}
}

@article{10.1145/3115934,
author = {Messaoudi, Farouk and Ksentini, Adlen and Simon, Gwendal and Bertin, Philippe},
title = {Performance Analysis of Game Engines on Mobile and Fixed Devices},
year = {2017},
issue_date = {October 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {4},
issn = {1551-6857},
url = {https://doi.org/10.1145/3115934},
doi = {10.1145/3115934},
abstract = {Mobile gaming is an emerging concept wherein gamers are using mobile devices, like smartphones and tablets, to play best-seller games. Compared to dedicated gaming boxes or PCs, these devices still fall short of executing newly complex 3D video games with a rich immersion. Three novel solutions, relying on cloud computing infrastructure, namely, computation offloading, cloud gaming, and client-server architecture, will represent the next generation of game engine architecture aiming at improving the gaming experience. The basis of these aforementioned solutions is the distribution of the game code over different devices (including set-top boxes, PCs, and servers). In order to know how the game code should be distributed, advanced knowledge of game engines is required. By consequence, dissecting and analyzing game engine performances will surely help to better understand how to move in these new directions (i.e., distribute game code), which is so far missing in the literature. Aiming at filling this gap, we propose in this article to analyze and evaluate one of the famous engines in the market, that is, “Unity 3D.” We begin by detailing the architecture and the game logic of game engines. Then, we propose a test-bed to evaluate the CPU and GPU consumption per frame and per module for nine representative games on three platforms, namely, a stand-alone computer, embedded systems, and web players. Based on the obtained results and observations, we build a valued graph of each module, composing the Unity 3D architecture, which reflects the internal flow and CPU consumption. Finally, we made a comparison in terms of CPU consumption between these architectures.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = sep,
articleno = {57},
numpages = {28},
keywords = {Computation offloading, rendering, unity 3D, cloud gaming, games}
}

@inproceedings{10.1145/3267357.3267362,
author = {Arias-Cabarcos, Patricia and Almen\'{a}rez, Florina and D\'{\i}az-S\'{a}nchez, Daniel and Mar\'{\i}n, Andr\'{e}s},
title = {FRiCS: A Framework for Risk-Driven Cloud Selection},
year = {2018},
isbn = {9781450359887},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3267357.3267362},
doi = {10.1145/3267357.3267362},
abstract = {Our devices and interactions in a world where physical and digital realities are more and more blended, generate a continuum of multimedia data that needs to be stored, shared and processed to provide services that enrich our daily lives. Cloud computing plays a key role in these tasks, dissolving resource allocation and computational boundaries, but it also requires advanced security mechanisms to protect the data and provide privacy guarantees. Therefore, security assurance must be evaluated before offloading tasks to a cloud provider, a process which is currently manual, complex and inadequate for dynamic scenarios. However, though there are many tools for evaluating cloud providers according to quality of service criteria, automated categorization and selection based on risk metrics is still challenging. To address this gap, we present FRiCS, a Framework for Risk-driven Cloud Selection, which contributes with: 1) a set of cloud security metrics and risk-based weighting policies, 2) distributed components for metric extraction and aggregation, and 3) decision-making plugins for ranking and selection. We have implemented the whole system and conducted a case-study validation based on public cloud providers' security data, showing the benefits of the proposed approach.},
booktitle = {Proceedings of the 2nd International Workshop on Multimedia Privacy and Security},
pages = {18–26},
numpages = {9},
keywords = {risk-driven security, cloud computing, decision making, cloud-based multimedia systems, security metrics},
location = {Toronto, Canada},
series = {MPS '18}
}

@inproceedings{10.1145/3383923.3383970,
author = {Amasha, Mohamed A. and Areed, Marwa F. and Alkhalaf, Salem and Abougalala, Rania A. and Elatawy, Safaa M. and Khairy, Dalia},
title = {The Future of Using Internet of Things (LoTs) and Context-Aware Technology in E-Learning},
year = {2020},
isbn = {9781450375085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3383923.3383970},
doi = {10.1145/3383923.3383970},
abstract = {In the recent era, the Internet of Things (IoTs) has been estimated to play an essential role in e-learning and context-aware technology. The IoTs is the next technological jump that will introduce good improvements to various aspects of the educational field, such as e-learning and u-learning. Moreover, the reproduction and adoption of IoTs applications have provided global opportunities and challenges for e-learning. This paper. The main purpose of this the present study is to determine the perceptions of Damietta university students toward the effects of IoT technology and examines the impact of (IoTs) usage on students' academic performance. The sample was made of 235university students using a questionnaire survey. Of the participants, (n1=115; 48.93%) were male, (n2=120; 51.06%) were female. A majority of the participants reported that the IoTs technology will affect in future of e-learning and education practices. The students obtained the highest mean score on the item "has changed this issue and allows us to make digital posters with photos, sound, video content and hyperlinks, as well as enables us to distribute them electronically with others" (4.09 ± 1.084), and mean score exceed (4.05 ± 1.095) on the item "can improve tutoring itself and conveys propelled charge to the physical environment and frameworks". Our finding of this study revealed that IoTs will be involved in e-learning and education practices.},
booktitle = {Proceedings of the 2020 9th International Conference on Educational and Information Technology},
pages = {114–123},
numpages = {10},
keywords = {Internet of Things (IoTs), E-learning, context-aware},
location = {Oxford, United Kingdom},
series = {ICEIT 2020}
}

@inproceedings{10.1145/3437378.3444366,
author = {Buzachis, Alina and Boruta, Daiana and Villari, Massimo and Spillner, Josef},
title = {Modeling and Emulation of an Osmotic Computing Ecosystem Using OsmoticToolkit},
year = {2021},
isbn = {9781450389563},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3437378.3444366},
doi = {10.1145/3437378.3444366},
abstract = { Digital services are increasingly becoming cyber-physical and osmotic, combining Cloud resources with Fog, Edge, and IoT devices. This trend can be observed in the e-health domain or in smart city applications where the location of software deployments and data processing matters. Before such applications go live, careful planning with real system emulation is necessary. We claim that the OsmoticToolkit, although in the early stages, is the first emulation environment designed to address this challenge. In this paper, we introduce the emulator’s functionalities and validate experimentally with an e-health scenario, using a reference deployment of a microservice-based hospital application. The experimental results carried out show its effectiveness providing valuable support for understanding the impact on resources, workloads, and Quality of Service requirements within Cloud-Edge/Fog-IoT scenarios while preserving the users’ Service Level Agreements (SLAs). },
booktitle = {2021 Australasian Computer Science Week Multiconference},
articleno = {9},
numpages = {9},
keywords = {SDN, Osmotic Computing, Orchestration, Microservices, Emulation, Deployment, Cloud Computing},
location = {Dunedin, New Zealand},
series = {ACSW '21}
}

@inproceedings{10.1145/3373724.3373727,
author = {Ng, Lai Xing and Ng, Jamie and Tang, Keith T. W. and Li, Liyuan and Rice, Mark and Wan, Marcus},
title = {Using Visual Intelligence to Automate Maintenance Task Guidance and Monitoring on a Head-Mounted Display},
year = {2019},
isbn = {9781450372350},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3373724.3373727},
doi = {10.1145/3373724.3373727},
abstract = {Maintenance is a required process in many commercial domains. Commonly, paper-based instruction manuals are digitised to improve accessibility to maintenance information. Among the different forms of digital media, augmented reality (AR) combined with machine learning has the potential to provide real-time user guidance and interaction. In this paper, we present an Augmented Reality Visual Intelligence (ARVI) framework, which combines visual perception with cognitive task reasoning to monitor user performance and provide contextualised guidance for maintenance tasks. The framework is implemented in Microsoft Hololens for a wheel removal operation. The implemented software can recognise aspects of the environment, objects and a user's hands, as well as infer the task being completed. The evaluation of visual perception models for object detection using a single task video for training obtained relatively high F1 scores, and a small-scale usability study reported some positive feedback on the application development.},
booktitle = {Proceedings of the 2019 5th International Conference on Robotics and Artificial Intelligence},
pages = {70–75},
numpages = {6},
keywords = {Automated task guidance, Task monitoring, Head-mounted displays, Cognitive visual intelligence, Augmented reality},
location = {Singapore, Singapore},
series = {ICRAI '19}
}

@article{10.1145/3419634,
author = {Bansal, Maggi and Chana, Inderveer and Clarke, Siobh\'{a}n},
title = {A Survey on IoT Big Data: Current Status, 13 V’s Challenges, and Future Directions},
year = {2020},
issue_date = {February 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3419634},
doi = {10.1145/3419634},
abstract = {Driven by the core technologies, i.e., sensor-based autonomous data acquisition and the cloud-based big data analysis, IoT automates the actuation of data-driven intelligent actions on the connected objects. This automation enables numerous useful real-life use-cases, such as smart transport, smart living, smart cities, and so on. However, recent industry surveys reflect that data-related challenges are responsible for slower growth of IoT in recent years. For this reason, this article presents a systematic and comprehensive survey on IoT Big Data (IoTBD) with the aim to identify the uncharted challenges for IoTBD. This article analyzes the state-of-the-art academic works in IoT and big data management across various domains and proposes a taxonomy for IoTBD management. Then, the survey explores the IoT portfolio of major cloud vendors and provides a classification of vendor services for the integration of IoT and IoTBD on their cloud platforms. After that, the survey identifies the IoTBD challenges in terms of 13 V’s challenges and envisions IoTBD as “Big Data 2.0.” Then the survey provides comprehensive analysis of recent works that address IoTBD challenges by highlighting their strengths and weaknesses to assess the recent trends and future research directions. Finally, the survey concludes with discussion on open research issues for IoTBD.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {131},
numpages = {59},
keywords = {IoT big data, IoT big data survey, big data 2.0, cloud IoT services, cloud computing in IoT, V’s challenges for IoT big data}
}

@article{10.1145/3355283,
author = {Ma, Meiyi and Preum, Sarah M. and Ahmed, Mohsin Y. and T\"{a}rneberg, William and Hendawi, Abdeltawab and Stankovic, John A.},
title = {Data Sets, Modeling, and Decision Making in Smart Cities: A Survey},
year = {2019},
issue_date = {February 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {2},
issn = {2378-962X},
url = {https://doi.org/10.1145/3355283},
doi = {10.1145/3355283},
abstract = {Cities are deploying tens of thousands of sensors and actuators and developing a large array of smart services. The smart services use sophisticated models and decision-making policies supported by Cyber Physical Systems and Internet of Things technologies. The increasing number of sensors collects a large amount of city data across multiple domains. The collected data have great potential value, but has not yet been fully exploited. This survey focuses on the domains of transportation, environment, emergency and public safety, energy, and social sensing. This article carefully reviews both the data sets being collected across 14 smart cities and the state-of-the-art work in modeling and decision making methodologies. The article also points out the characteristics, challenges faced today, and those challenges that will be exacerbated in the future. Key data issues addressed include heterogeneity, interdisciplinary, integrity, completeness, real-timeliness, and interdependencies. Key decision making issues include safety and service conflicts, security, uncertainty, humans in the loop, and privacy.},
journal = {ACM Trans. Cyber-Phys. Syst.},
month = nov,
articleno = {14},
numpages = {28},
keywords = {data sets, Smart city, modeling, decision making, integrating services}
}

@inproceedings{10.1145/3241403.3241463,
author = {Boudko, Svetlana and Abie, Habtamu},
title = {An Evolutionary Game for Integrity Attacks and Defences for Advanced Metering Infrastructure},
year = {2018},
isbn = {9781450364836},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3241403.3241463},
doi = {10.1145/3241403.3241463},
abstract = {Smart grids are complex cyber-physical systems that face many security challenges. Advanced Metering Infrastructure (AMI), which is one of the main components of the smart grid, represents an important branch of services with increasing deployments that also introduce new security risks. The nodes of AMIs are featured as resource-constrained. Therefore, security attacks including data integrity attacks on AMIs are of serious concern and require efficient selection of protective strategies. In this paper, we propose an evolutionary game framework that models integrity attacks and defenses in an AMI. The aim of this framework is to study possible behaviors of adversaries and to define how the AMI nodes can adaptively select their strategies with maximum payoffs of the nodes. We present a case study and illustrate how the framework can be applied to investigate the integrity threats in AMI systems. We show the evolution process, based on the replicator dynamic.},
booktitle = {Proceedings of the 12th European Conference on Software Architecture: Companion Proceedings},
articleno = {58},
numpages = {7},
keywords = {data integrity, evolutionary game theory, security, game theory, advanced metering infrastructure, smart meters},
location = {Madrid, Spain},
series = {ECSA '18}
}

@inproceedings{10.1145/3361758.3361759,
author = {Saleh, Mohammed and Khdour, Thair and Qasaymeh, Mahmoud},
title = {Analysis of AMI, Smart Metering Deployment and Big Data Management Challenges},
year = {2019},
isbn = {9781450372466},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3361758.3361759},
doi = {10.1145/3361758.3361759},
abstract = {Sustainability, rise of consumer power, IOT, Cloud Computing and digitalization era are major factors driving the fourth industrial revolution. Electric energy stakeholders are automating technological and business processes to the new requirements of the energy sector. Deploying the right combination of AI, Advanced Metering Infrastructure and Big Data Analysis, will increase efficiency and self-optimize operations. The emerging markets including the Middle East will deploy nearly 250 million meters, representing an investment of almost $35bn. The GCC increasing appetite power generating capacity is 157 GW; which is almost half the total Middle East and North Africa power generating capacity Smart Grid market in Gulf Council Countries will top US$ 1.68 billion by 2026. In addition, GCC is projected to spend US$137 Billion to increase its power generating capacity, Transmission and Distribution by 69 MW within five years. This research focus on the analysis of AMI and smart metering deployment and challenges in GCC region.},
booktitle = {Proceedings of the 3rd International Conference on Big Data and Internet of Things},
pages = {3–7},
numpages = {5},
keywords = {Digital Utility, Smart Grid, AMI},
location = {Melbourn, VIC, Australia},
series = {BDIOT 2019}
}

@article{10.1145/3351242,
author = {Radu, Valentin and Henne, Maximilian},
title = {Vision2Sensor: Knowledge Transfer Across Sensing Modalities for Human Activity Recognition},
year = {2019},
issue_date = {September 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {3},
url = {https://doi.org/10.1145/3351242},
doi = {10.1145/3351242},
abstract = {Mobile and wearable sensing devices are pervasive, coming packed with a growing number of sensors. These are supposed to provide direct observations about user activity and context to intelligent systems, and are envisioned to be at the core of smart buildings, towards habitat automation to suit user needs. However, much of this enormous sensing capability is currently wasted, instead of being tapped into, because developing context recognition systems requires substantial amount of labeled sensor data to train models on. Sensor data is hard to interpret and annotate after collection, making it difficult and costly to generate large training sets, which is now stalling the adoption of mobile sensing at scale. We address this fundamental problem in the ubicomp community (not having enough training data) by proposing a knowledge transfer framework, Vision2Sensor, which opportunistically transfers information from an easy to interpret and more advanced sensing modality, vision, to other sensors on mobile devices. Activities recognised by computer vision in the camera field of view are synchronized with inertial sensor data to produce labels, which are then used to dynamically update a mobile sensor based recognition model. We show that transfer learning is also beneficial to identifying the best Convolutional Neural Network for vision based human activity recognition for our task. The performance of a proposed network is first evaluated on a larger dataset, followed by transferring the pre-trained model to be fine-tuned on our five class activity recognition task. Our sensor based Deep Neural Network is robust to withstand substantial degradation of label quality, dropping just 3% in accuracy on induced degradation of 15% to vision generated labels. This indicates that knowledge transfer between sensing modalities is achievable even with significant noise introduced by the labeling modality. Our system operates in real-time on embedded computing devices, ensuring user data privacy by performing all the computations in the local network.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {84},
numpages = {21},
keywords = {knowledge transfer, smart camera, computer vision, transfer learning, sensing, smartphone}
}

@article{10.1109/TNET.2019.2936759,
author = {He, Qing and Dan, Gyorgy and Fodor, Viktoria},
title = {Joint Assignment and Scheduling for Minimizing Age of Correlated Information},
year = {2019},
issue_date = {October 2019},
publisher = {IEEE Press},
volume = {27},
number = {5},
issn = {1063-6692},
url = {https://doi.org/10.1109/TNET.2019.2936759},
doi = {10.1109/TNET.2019.2936759},
abstract = {Age of information has been recently proposed to quantify the freshness of information, e.g., in cyber-physical systems, where it is of critical importance. Motivated by wireless camera networks where multi-view image processing is required, in this paper we propose to extend the concept of age of information to capture packets carrying correlated data. We consider a system consisting of wireless camera nodes with overlapping fields of view and a set of processing nodes, and address the problem of the joint optimization of processing node assignment and camera transmission scheduling, so as to minimize the maximum peak age of information from all sources. We formulate the multi-view age minimization MVAM problem, and prove its NP-hardness under the two widely used interference models as well as with given candidate transmitting groups. We provide fundamental results including tractable cases and optimality conditions of the MVAM problem for two baseline scenarios. To solve MVAM efficiently, we develop an optimization algorithm based on a decomposition approach. Numerical results show that by employing our approach the maximum peak age is significantly reduced in comparison to a traditional centralized solution with minimum-time scheduling.},
journal = {IEEE/ACM Trans. Netw.},
month = oct,
pages = {1887–1900},
numpages = {14}
}

@inproceedings{10.1109/CHASE.2017.120,
author = {Wu, Xiaopei and Dunne, Robert and Yu, Zhifeng and Shi, Weisong},
title = {STREMS: A Smart Real-Time Solution toward Enhancing EMS Prehospital Quality},
year = {2017},
isbn = {9781509047215},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CHASE.2017.120},
doi = {10.1109/CHASE.2017.120},
abstract = {Emergency medical service (EMS) systems are public services that provide quick response, transportation as well as appropriate emergency medical care to the emergent patient. For EMS, every second is critical. Unfortunately, current EMS systems have many challenges: lack effective communication between EMS providers and hospital professionals, less attention on care quality and limited resources of medical equipment and personnel. Motivated by this, in this paper, we explore the use of wearable sensing, smart mobile device as well as video technology to propose STREMS: an efficient smart real-time prehospital communication system for EMS. Specifically, we first introduce a cost-effective wearable physiological sensing solution to support multi-dimensional telemetry monitoring for an ambulance operating at as Basic Life Support, a type of EMS service level without sophisticated medical equipment or paramedics. Then we propose to build a cloud-based real-time data sharing platform, enabling automated streaming all gathered prehospital data (e.g., vital signs, EKG and image/short videos about accident scene) to the hospital prior to ambulance arrival, thus giving a more complete figure about the incoming patient. This can significantly decrease the handoff time and improve the efficiency at the hospital. Additionally, a live point to point video communication is proposed to support EMS telemedicine to enhance prehospital care quality through directly video conversation to assist EMS providers in consultation, triage, early medical examination and treatment. We implemented STREMS as an Android mobile app and evaluated its feasibility over the broadband cellular network in the city of Detroit. In a moving context, our results demonstrate STREMS can successfully deliver 100% of emergency data to the hospital in less than 1.5s, on average 0.75s for reporting a new case and 0.05s for health data. As the live video with 1280 \texttimes{} 720 pixel resolution, STREMS only works when the vehicle speed is less than 40MPH.},
booktitle = {Proceedings of the Second IEEE/ACM International Conference on Connected Health: Applications, Systems and Engineering Technologies},
pages = {365–372},
numpages = {8},
keywords = {wearable sensing, real-time prehospital communication, emergency medical service (EMS), prehospital care quality},
location = {Philadelphia, Pennsylvania},
series = {CHASE '17}
}

@inproceedings{10.5555/3408352.3408751,
author = {Jie, Chen and Loi, Igor and Benini, Luca and Rossi, Davide},
title = {Energy-Efficient Two-Level Instruction Cache Design for an Ultra-Low-Power Multi-Core Cluster},
year = {2020},
isbn = {9783981926347},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
abstract = {High Energy efficiency and high performance are the key regiments for Internet of Things (IoT) edge devices. Exploiting cluster of multiple programmable processors has recently emerged as a suitable solution to address this challenge. However, one of the main power bottlenecks for multi-core architectures is the instruction cache memory. We propose a two-level structure based on Standard Cell Memories (SCMs) which combines a private instruction cache (L1) per-core and a low-latency (only one cycle latency) shared instruction cache (L1,5). We present a detailed comparison of performance and energy efficiency for different instruction cache architectures. Our system-level analysis shows that the proposed design improves upon both state-of-the art private and shared cache architectures and balances well performance with energy-efficacy. On average, when executing a set of real-life IoT applications, our multi-level cache improves performance and energy efficiency both by 10% with respect to the private instruction cache system, and improves energy efficiency by 15% and 7% with a performance loss of only 2% with respect to the shared instruction cache. Besides, relaxed timing makes two-level instruction cache an attractive choice for aggressive implementation, with more slack for convergence in physical design.},
booktitle = {Proceedings of the 23rd Conference on Design, Automation and Test in Europe},
pages = {1734–1739},
numpages = {6},
keywords = {instruction cache, energy efficiency, relaxed-timing, parallel architecture},
location = {Grenoble, France},
series = {DATE '20}
}

@inproceedings{10.1145/3363347.3363361,
author = {Naucke, Jakob and Hunt, Hamish and Crawford, Jack and Steffinlongo, Enrico and Masters, Oliver and Bergamaschi, Flavio},
title = {Homomorphically Securing AI at the Edge},
year = {2019},
isbn = {9781450370134},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3363347.3363361},
doi = {10.1145/3363347.3363361},
abstract = {Edge devices are becoming increasingly pervasive in everyday life. These devices have become more computationally capable allowing for more complex AI reasoning at the edge. Subsequently, there is a need for protecting data to comply with privacy laws and confidentiality regulations. In this paper, we demonstrate the applicability of homomorphic encryption for protecting the data of AI-enabled cameras at the edge by implementing our solution on a commercial edge device. Our solution comprises a local homomorphic key-value database on an edge device populated by an AI camera; permitting the service of homomorphic search to be performed directly on the edge device. We characterize our implementation demonstrating linear behavior with respect to the database size that the edge device can support. Good enough performance is known to be difficult to achieve when employing homomorphic encryption. Our results are encouraging as we achieved solutions considered to be homomorphically fast, for example, linear performance of 1.28 seconds per database entry at over 256 bits of security. This amounts to a query being processed on a database of 200 entries in ~ 5 minutes.},
booktitle = {Proceedings of the First International Workshop on Challenges in Artificial Intelligence and Machine Learning for Internet of Things},
pages = {32–38},
numpages = {7},
keywords = {information retrieval, homomorphic encryption, security and privacy, homomorphic computation, edge networks, IoT},
location = {New York, NY, USA},
series = {AIChallengeIoT'19}
}

@inproceedings{10.1145/3147213.3147228,
author = {Jonathan, Albert and Chandra, Abhishek and Weissman, Jon},
title = {Locality-Aware Load Sharing in Mobile Cloud Computing},
year = {2017},
isbn = {9781450351492},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3147213.3147228},
doi = {10.1145/3147213.3147228},
abstract = {The past few years have seen a growing number of mobile and sensor applications that rely on Cloud support. The role of the Cloud is to allow these resource-limited devices to offload and execute some of their compute-intensive tasks in the Cloud for energy saving and/or faster processing. However, such offloading to the Cloud may result in high network overhead which is not suitable for many mobile/sensor applications that require low latency. So, people have looked at an alternative Cloud design whose resources are located at the edge of the Internet, called Edge Cloud. Although the use of Edge Cloud can mitigate the offloading overhead, the computational power and network bandwidth of Edge Cloud's resources are typically much more limited compared to the centralized Cloud and hence are more sensitive to workload variation (e.g., due to CPU or I/O contention). In this paper, we propose a locality-aware load sharing technique that allows edge resources to share their workload in order to maintain the low latency requirement of Mobile-Cloud applications. Specifically, we study how to determine which edge nodes should be used to share the workload with and how much of the workload should be shared to each node. Our experiments show that our locality-aware load sharing technique is able to maintain low average end-to-end latency of mobile applications with low latency variation, while achieving good utilization of resources in the presence of a dynamic workload.},
booktitle = {Proceedings of The10th International Conference on Utility and Cloud Computing},
pages = {141–150},
numpages = {10},
keywords = {edge cloud, mobile-cloud computing, load sharing},
location = {Austin, Texas, USA},
series = {UCC '17}
}

@inproceedings{10.1145/3369985.3370039,
author = {Zhang, Ganghong and Huo, Chao and Yuan, Jianan},
title = {Deep Learning Chips: Challenges and Opportunities for Ubiquitous Power Internet of Things},
year = {2019},
isbn = {9781450372589},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3369985.3370039},
doi = {10.1145/3369985.3370039},
abstract = {Tasks of Ubiquitous Power Internet of Things run through the power generation, transmission, transformation, distribution, electricity use and other links, requiring advanced communication, artificial intelligence, big data and other technologies. Deep learning chips provide computational power for algorithm execution and data processing, which are indispensable foundations and basic components for intelligent terminals. Therefore, this paper summarizes the challenges and opportunities faced by deep learning chips in the construction of ubiquitous power Internet of Things. Firstly, the four parts of ubiquitous power Internet of Things including terminal layer, network layer, platform layer and application layer are described. Secondly, the key technologies of deep learning technology and deep neural network accelerator involved in deep learning chips are summarized. Finally, the research work of deep learning chips for ubiquitous power Internet of Things is surveyed. The main functions and existing problems are discussed, and the future research work is proposed.},
booktitle = {Proceedings of the 5th International Conference on Communication and Information Processing},
pages = {305–312},
numpages = {8},
keywords = {deep neural network, ubiquitous power internet of things, intelligent terminal, deep learning chips},
location = {Chongqing, China},
series = {ICCIP '19}
}

@inproceedings{10.1145/3194452.3194475,
author = {Velev, Dimiter and Zlateva, Plamena and Zong, Xuejun},
title = {Challenges of 5G Usability in Disaster Management},
year = {2018},
isbn = {9781450364195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194452.3194475},
doi = {10.1145/3194452.3194475},
abstract = {In recent years, there is a registered increase in the number and intensity of disasters caused by natural phenomena or human activities around the world. Such calamities adversely affect social relations, economic growth and sustainable development of the countries. Although many information systems for disaster management try to reduce the possible aftereffects of disasters and assess the damages, not always they are capable of handling the consequences in the right way regardless of the advanced information technologies used. Recently all technical achievements are being planned and focused on the forthcoming 5G technology with its numerous possible applications in different aspects of real life. The aim of the paper is to investigate the 5G usability in disasters and how this technology could improve the management of the negative consequences.},
booktitle = {Proceedings of the 2018 International Conference on Computing and Artificial Intelligence},
pages = {71–75},
numpages = {5},
keywords = {Big Data, IoT, 5G, Cloud Computing, Natural Disasters},
location = {Chengdu, China},
series = {ICCAI 2018}
}

@inproceedings{10.1145/3097895.3097903,
author = {Ran, Xukan and Chen, Haoliang and Liu, Zhenming and Chen, Jiasi},
title = {Delivering Deep Learning to Mobile Devices via Offloading},
year = {2017},
isbn = {9781450350556},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3097895.3097903},
doi = {10.1145/3097895.3097903},
abstract = {Deep learning has the potential to make Augmented Reality (AR) devices smarter, but few AR apps use such technology today because it is compute-intensive, and front-end devices cannot deliver sufficient compute power. We propose a distributed framework that ties together front-end devices with more powerful back-end "helpers" that allow deep learning to be executed locally or to be offloaded. This framework should be able to intelligently use current estimates of network conditions and back-end server loads, in conjunction with the application's requirements, to determine an optimal strategy.This work reports our preliminary investigation in implementing such a framework, in which the front-end is assumed to be smartphones. Our specific contributions include: (1) development of an Android application that performs real-time object detection, either locally on the smartphone or remotely on a server; and (2) characterization of the tradeoffs between object detection accuracy, latency, and battery drain, based on the system parameters of video resolution, deep learning model size, and offloading decision.},
booktitle = {Proceedings of the Workshop on Virtual Reality and Augmented Reality Network},
pages = {42–47},
numpages = {6},
keywords = {Wireless, Offloading, Neural networks},
location = {Los Angeles, CA, USA},
series = {VR/AR Network '17}
}

@inproceedings{10.1145/3341105.3373867,
author = {Mbarek, Bacem and Ge, Mouzhi and Pitner, Tom\'{a}s},
title = {Enhanced Network Intrusion Detection System Protocol for Internet of Things},
year = {2020},
isbn = {9781450368667},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341105.3373867},
doi = {10.1145/3341105.3373867},
abstract = {With the emergence of the Internet of Things (IoT), different IoT nodes such as 6LoWPAN devices can be connected as a network to provide integrated services. Since security and intrusion detection are becoming crucial among IoT devices, real-time detection of the attacks are critical to protect the IoT networks. However, there exists limited research for efficient network intrusion detection systems (NIDS) in the IoT networks. This paper therefore proposes a new NIDS protocol with an efficient replica detection algorithm to increase the utility and performance of existing NIDS, where a number of replica test nodes are intentionally inserted into the network to test the reliability and response of witness nodes. The proposed protocol, Enhanced NIDS, can address the vulnerability of NIDS and improve IoT network security to detect severe compromise attacks such as clone attacks. The simulation study shows that compared to the state-of-the-art SVELTE protocol, the proposed protocol can significantly increase the detection probability and reduce the energy consumption for detecting clone attacks in IoT networks.},
booktitle = {Proceedings of the 35th Annual ACM Symposium on Applied Computing},
pages = {1156–1163},
numpages = {8},
keywords = {network protocol, internet of things, security, intrusion detection systems, clone attacks, replica detection},
location = {Brno, Czech Republic},
series = {SAC '20}
}

@inproceedings{10.1145/3230833.3233257,
author = {Bouchaud, Fran\c{c}ois and Grimaud, Gilles and Vantroys, Thomas},
title = {IoT Forensic: Identification and Classification of Evidence in Criminal Investigations},
year = {2018},
isbn = {9781450364485},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3230833.3233257},
doi = {10.1145/3230833.3233257},
abstract = {The Internet of Things (IoT) is everywhere around us. Smart communicating objects offer the digitalization of lives. Thus, IoT opens new opportunities in criminal investigations such as a protagonist or a witness to the event. Any investigation process involves four phases: firstly the identification of an incident and its evidence, secondly device collection and preservation, thirdly data examination and extraction and then finally data analysis and formalization.In recent years, the scientific community sought to develop a common digital framework and methodology adapted to IoT-based infrastructure. However, the difficulty of IoT lies in the heterogeneous nature of the device, lack of standards and the complex architecture. Although digital forensics are considered and adopted in IoT investigations, this work only focuses on collection. Indeed the identification phase is relatively unexplored. It addresses challenges of finding the best evidence and locating hidden devices. So, the traditional method of digital forensics does not fully fit the IoT environment.In this paperwork, we investigate the mobility in the context of IoT at the crime scene. This paper discusses the data identification and the classification methodology from IoT to looking for the best evidences. We propose tools and techniques to identify and locate IoT devices. We develop the recent concept of "digital footprint" in the crime area based on frequencies and interactions mapping between devices. We propose technical and data criteria to efficiently select IoT devices. Finally, the paper introduces a generalist classification table as well as the limits of such an approach.},
booktitle = {Proceedings of the 13th International Conference on Availability, Reliability and Security},
articleno = {60},
numpages = {9},
keywords = {Internet of Things, Evidence acquisition, IoT Investigations, Digital Forensics Model, IoT Forensics},
location = {Hamburg, Germany},
series = {ARES 2018}
}

@article{10.1145/3432196,
author = {Boldu, Roger and Matthies, Denys J.C. and Zhang, Haimo and Nanayakkara, Suranga},
title = {AiSee: An Assistive Wearable Device to Support Visually Impaired Grocery Shoppers},
year = {2020},
issue_date = {December 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {4},
url = {https://doi.org/10.1145/3432196},
doi = {10.1145/3432196},
abstract = {People with visual impairments (PVI) experience simple tasks, such as grocery shopping, to be an essential difficulty. Although the recent emergence of AI-technology has been dramatically improving visual recognition capabilities, the application to the daily life of PVI is still complex and erroneous. For example, image recognition engines require a clear shot of the targeted object and a contextual understanding of the information the user requires. In this paper, we aimed to understand the PVI's needs and their pain points in the task of identifying grocery items. Following a user-centered design process, we iteratively},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = dec,
articleno = {119},
numpages = {25},
keywords = {Finger Touch, Force, Localization, Acoustic}
}

@inproceedings{10.1145/3098954.3104052,
author = {Zia, Tanveer and Liu, Peng and Han, Weili},
title = {Application-Specific Digital Forensics Investigative Model in Internet of Things (IoT)},
year = {2017},
isbn = {9781450352574},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3098954.3104052},
doi = {10.1145/3098954.3104052},
abstract = {Besides its enormous benefits to the industry and community the Internet of Things (IoT) has introduced unique security challenges to its enablers and adopters. As the trend in cybersecurity threats continue to grow, it is likely to influence IoT deployments. Therefore it is eminent that besides strengthening the security of IoT systems we develop effective digital forensics techniques that when breaches occur we can track the sources of attacks and bring perpetrators to the due process with reliable digital evidence. The biggest challenge in this regard is the heterogeneous nature of devices in IoT systems and lack of unified standards. In this paper we investigate digital forensics from IoT perspectives. We argue that besides traditional digital forensics practices it is important to have application-specific forensics in place to ensure collection of evidence in context of specific IoT applications. We consider top three IoT applications and introduce a model which deals with not just traditional forensics but is applicable in digital as well as application-specific forensics process. We believe that the proposed model will enable collection, examination, analysis and reporting of forensically sound evidence in an IoT application-specific digital forensics investigation.},
booktitle = {Proceedings of the 12th International Conference on Availability, Reliability and Security},
articleno = {55},
numpages = {7},
keywords = {IoT Applications, IoT, Digital Forensics, Internet of Things, Digital Forensics Model, IoT Security, IoT Forensics},
location = {Reggio Calabria, Italy},
series = {ARES '17}
}

@inproceedings{10.1145/3356250.3360046,
author = {Chi, Zicheng and Li, Yan and Liu, Xin and Yao, Yao and Zhang, Yanchao and Zhu, Ting},
title = {Parallel Inclusive Communication for Connecting Heterogeneous IoT Devices at the Edge},
year = {2019},
isbn = {9781450369503},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3356250.3360046},
doi = {10.1145/3356250.3360046},
abstract = {WiFi and Bluetooth Low Energy (BLE) are widely used in Internet of Things (IoT) devices. Since WiFi and BLE work within the overlapped ISM 2.4 GHz band, they will interfere with each other. Existing approaches have demonstrated their effectiveness in mitigating the interference. However, further performance improvement has been hampered by the design goal of exclusive communication of WiFi or BLE, which only allows one WiFi or BLE device to transmit packets at any specific time slot on the overlapped channel within the communication range. In this paper, we explore a new communication method, called Parallel Inclusive Communication (PIC), which leverages the unique modulation schemes of WiFi and BLE for parallel inclusive bi-directional transmission of both WiFi and BLE data at the same time within the overlapped channel. In this communication system, the PIC gateway is designed upon the IEEE 802.11g and 802.15.1 frameworks while the WiFi and BLE clients are commercial off-the-shelf devices. PIC achieves similar data rates for these parallel WiFi and BLE communications as if WiFi and BLE are communicating separately. PIC's system architecture naturally fits at the edge of the Internet, which is an optimal site for concurrently collecting (or disseminating) data from (or to) an exponentially increasing number of IoT devices that are using WiFi or BLE. We conducted extensive evaluations under four real-world scenarios. Results show that compared with existing approaches, PIC can significantly i) increase the packet reception ratios by 183%; ii) reduce the round-trip delay time by 590 times and energy consumption by 50.5 times; and iii) improve the throughput under WiFi and BLE coexistence scenarios.},
booktitle = {Proceedings of the 17th Conference on Embedded Networked Sensor Systems},
pages = {205–218},
numpages = {14},
keywords = {heterogenous networks, parallel communication, IoT},
location = {New York, New York},
series = {SenSys '19}
}

@article{10.1145/3351882,
author = {Puthal, Deepak and Yang, Laurence T. and Dustdar, Schahram and Wen, Zhenyu and Jun, Song and Moorsel, Aad van and Ranjan, Rajiv},
title = {A User-Centric Security Solution for Internet of Things and Edge Convergence},
year = {2020},
issue_date = {May 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {3},
issn = {2378-962X},
url = {https://doi.org/10.1145/3351882},
doi = {10.1145/3351882},
abstract = {The Internet of Things (IoT) is becoming a backbone of sensing infrastructure to several mission-critical applications such as smart health, disaster management, and smart cities. Due to resource-constrained sensing devices, IoT infrastructures use Edge datacenters (EDCs) for real-time data processing. EDCs can be either static or mobile in nature, and this article considers both of these scenarios. Generally, EDCs communicate with IoT devices in emergency scenarios to evaluate data in real-time. Protecting data communications from malicious activity becomes a key factor, as all the communication flows through insecure channels. In such infrastructures, it is a challenging task for EDCs to ensure the trustworthiness of the data for emergency evaluations. The current communication security pattern of “communication before authentication” leaves a “black hole” for intruders to become part of communication processes without authentication. To overcome this issue and to develop security infrastructures for IoT and distributed Edge datacenters, this article proposes a user-centric security solution. The proposed security solution shifts from a network-centric approach to a user-centric security approach by authenticating users and devices before communication is established. A trusted controller is initialized to authenticate and establishes the secure channel between the devices before they start communication between themselves. The centralized controller draws a perimeter for secure communications within the boundary. Theoretical analysis and experimental evaluation of the proposed security model show that it not only secures the communication infrastructure but also improves the overall network performance.},
journal = {ACM Trans. Cyber-Phys. Syst.},
month = may,
articleno = {32},
numpages = {19},
keywords = {distributed edge networks, authentication, secure channel, perimeter-based security, Internet of Things}
}

@inproceedings{10.1145/3083187.3084012,
author = {Shea, Ryan and Sun, Andy and Fu, Silvery and Liu, Jiangchuan},
title = {Towards Fully Offloaded Cloud-Based AR: Design, Implementation and Experience},
year = {2017},
isbn = {9781450350020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3083187.3084012},
doi = {10.1145/3083187.3084012},
abstract = {Combining advanced sensors and powerful processing capabilities smart-phone based augmented reality (AR) is becoming increasingly prolific. The increase in prominence of these resource hungry AR applications poses significant challenges to energy constrained environments such as mobile-phones.; AB@To that end we present a platform for offloading AR applications to powerful cloud servers. We implement this system using a thin-client design and explore its performance using the real world application Pokemon Go as a case study. We show that with careful design a thin client is capable of offloading much of the AR processing to a cloud server, with the results being streamed back. Our initial experiments show substantial energy savings, low latency and excellent image quality even at relatively low bit-rates.},
booktitle = {Proceedings of the 8th ACM on Multimedia Systems Conference},
pages = {321–330},
numpages = {10},
keywords = {Mobile Gaming, Augmented Reality, Cloud Offloading},
location = {Taipei, Taiwan},
series = {MMSys'17}
}

@inproceedings{10.1145/3243082.3243085,
author = {de Sousa, Peron Rezende and Lage, Marcos and de Arag\~{a}o Rocha, Antonio A.},
title = {Future Internet and Scalability Techniques in Mobile Crowdsourcing},
year = {2018},
isbn = {9781450358675},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3243082.3243085},
doi = {10.1145/3243082.3243085},
abstract = {In this paper we present a new architecture for mobile crowdsourcing systems which leverages the infrastructure of services widely scalable. We successfully developed a proof of concept and discussed an alternative architecture that uses direct communication between devices to eliminate the additional financial contribution needed in the solutions developed with elastic/cloud computing. We also presented a new incentive mechanism and evaluated its scalability with up to 1500 simultaneous accesses. Our results show that it is capable of serving one of the largest crowdsourcing systems on the internet.},
booktitle = {Proceedings of the 24th Brazilian Symposium on Multimedia and the Web},
pages = {77–84},
numpages = {8},
keywords = {Scalability, Future Internet, Crowdsourcing},
location = {Salvador, BA, Brazil},
series = {WebMedia '18}
}

@inproceedings{10.1145/2994374.2994390,
author = {Kubler, Sylvain and Robert, J\'{e}r\'{e}my and Hefnawy, Ahmed and Cherifi, Chantal and Bouras, Abdelaziz and Fr\"{a}mling, Kary},
title = {IoT-Based Smart Parking System for Sporting Event Management},
year = {2016},
isbn = {9781450347501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2994374.2994390},
doi = {10.1145/2994374.2994390},
abstract = {By connecting devices, people, vehicles and infrastructures everywhere in a city, governments and their partners can improve community wellbeing and other economic and financial aspects (e.g., cost and energy savings). Nonetheless, smart cities are complex ecosystems that comprise many different stakeholders (network operators, managed service providers, logistic centers...) who must work together to provide the best services and unlock the commercial potential of the IoT. This is one of the major challenges that faces today's smart city movement, and more generally the IoT as a whole. Indeed, while new smart connected objects hit the market every day, they mostly feed "vertical silos" (e.g., vertical apps, siloed apps...) that are closed to the rest of the IoT, thus hampering developers to produce new added value across multiple platforms. Within this context, the contribution of this paper is twofold: (i) present the EU vision and ongoing activities to overcome the problem of vertical silos; (ii) introduce recent IoT standards used as part of a recent Horizon 2020 IoT project to address this problem. The implementation of those standards for enhanced sporting event management in a smart city/government context (FIFA World Cup 2022) is developed, presented, and evaluated as a proof-of-concept.},
booktitle = {Proceedings of the 13th International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services},
pages = {104–114},
numpages = {11},
keywords = {Product Lifecycle Management, Interoperability, Internet of Things, Smart city, Standardization, Messaging protocols},
location = {Hiroshima, Japan},
series = {MOBIQUITOUS 2016}
}

@inproceedings{10.1145/3339311.3339354,
author = {Sofia and Batra, Isha and Verma, Vikas and Malik, Arun},
title = {A Comparative Analysis of Data Collection Methods in Internet of Things},
year = {2019},
isbn = {9781450366526},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3339311.3339354},
doi = {10.1145/3339311.3339354},
abstract = {With the increase in demand of Internet of Things using smart devices, different architectures are available for collecting the data in IoT platforms. Data collection phase is one of the most critical phase in the whole process of communication between device and human. Numerous data collection solutions were proposed in the literature. But still these existing solutions are lacking rationale and can be further improvised. Therefore, this paper conducts a detailed review on the existing methods for data collection. Later, a comparison is made among the existing concurrent tree method, low-density parity check code method and context awareness routing method in terms of their research objectives, techniques, input and output. Finally this paper evaluates the energy consumption, latency and storage requirements for different data collection methods. Results show that concurrent data collection tree method provides maximum storage, consumes more energy and possess less latency.},
booktitle = {Proceedings of the Third International Conference on Advanced Informatics for Computing Research},
articleno = {43},
numpages = {7},
keywords = {security, IoT, data collection},
location = {Shimla, India},
series = {ICAICR '19}
}

@inproceedings{10.1145/3184558.3191605,
author = {Helmer, Sven},
title = {May I Have Your Attention, Please: - Building a Dystopian Attention Economy},
year = {2018},
isbn = {9781450356404},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3184558.3191605},
doi = {10.1145/3184558.3191605},
abstract = {We analyze the scenario depicted in the "Black Mirror" episode "Fifteen Million Merits" from an economic point of view, focusing on treating the attention of a user or consumer as a commodity. We continue by sketching the technological requirements for building such an economic framework, looking at advertisement platforms, payment schemes, and surveillance technology. As we show, a lot of the technology already exists and we expect the gaps to be filled in the very near future. Additionally, we briefly discuss the impact on social and work environments. While we believe that a scenario as extreme as shown in the episode is unlikely, we think that certain facets of it could find their way into our society.},
booktitle = {Companion Proceedings of the The Web Conference 2018},
pages = {1529–1533},
numpages = {5},
keywords = {attention economy, black mirror},
location = {Lyon, France},
series = {WWW '18}
}

@article{10.1145/3375572.3375576,
author = {Raibulet, Claudia and Drira, Khalil and Fugini, MariaGrazia and Rodrigues, Genaina Nunes and Pelliccione, Patrizio and Bures, Tom\'{a}s},
title = {Report of the 2nd International Workshop on Context-Aware Autonomous and Smart Architectures (CASA@ECSA 2018)},
year = {2020},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {1},
issn = {0163-5948},
url = {https://doi.org/10.1145/3375572.3375576},
doi = {10.1145/3375572.3375576},
abstract = {The 2018 2nd International Workshop on Context-aware, Autonomous and Smart Architectures (CASA 2018) was held in conjunction with the 12th European Conference on Software Architecture (ECSA 2018), on September, 24th, 2018 in Madrid, Spain. The main topic of the workshop concerned the design of software architectures for dynamic, autonomous, and adaptive context-aware smart systems. Such systems address changes and cope with uncertainties at runtime. Therefore, the software architecture of such system should ensure the basis for their dynamicity, adaptivity, and autonomy. These basis should be solid because they represent the backbone of a system, and in the same time flexible because they address dynamicity during execution. The one-day workshop aimed to bring together researchers and practitioners from the academic and the industrial world to share and discuss their approaches, solutions, methodologies, ideas, and open questions about the software architecture design for context-aware, autonomous, and smart systems. The workshop enabled discussions and put the basis for future collaborations among the participants.},
journal = {SIGSOFT Softw. Eng. Notes},
month = jan,
pages = {14–17},
numpages = {4},
keywords = {smart, adaptation, self-management, software architecture, context-aware, autonomous}
}

@article{10.1145/3122981,
author = {Zhou, Bowen and Dastjerdi, Amir Vahid and Calheiros, Rodrigo N. and Buyya, Rajkumar},
title = {An Online Algorithm for Task Offloading in Heterogeneous Mobile Clouds},
year = {2018},
issue_date = {March 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {2},
issn = {1533-5399},
url = {https://doi.org/10.1145/3122981},
doi = {10.1145/3122981},
abstract = {Mobile cloud computing is emerging as a promising approach to enrich user experiences at the mobile device end. Computation offloading in a heterogeneous mobile cloud environment has recently drawn increasing attention in research. The computation offloading decision making and tasks scheduling among heterogeneous shared resources in mobile clouds are becoming challenging problems in terms of providing global optimal task response time and energy efficiency. In this article, we address these two problems together in a heterogeneous mobile cloud environment as an optimization problem. Different from conventional distributed computing system scheduling problems, our joint offloading and scheduling optimization problem considers unique contexts of mobile clouds such as wireless network connections and mobile device mobility, which makes the problem more complex. We propose a context-aware mixed integer programming model to provide off-line optimal solutions for making the offloading decisions and scheduling the offloaded tasks among the shared computing resources in heterogeneous mobile clouds. The objective is to minimize the global task completion time (i.e., makespan). To solve the problem in real time, we further propose a deterministic online algorithm—the Online Code Offloading and Scheduling (OCOS) algorithm—based on the rent/buy problem and prove the algorithm is 2-competitive. Performance evaluation results show that the OCOS algorithm can generate schedules that have around two times shorter makespan than conventional independent task scheduling algorithms. Also, it can save around 30% more on makespan of task execution schedules than conventional offloading strategies, and scales well as the number of users grows.},
journal = {ACM Trans. Internet Technol.},
month = jan,
articleno = {23},
numpages = {25},
keywords = {online scheduling, mixed integer programming, code offloading, Mobile cloud computing}
}

@inproceedings{10.1145/3147234.3148093,
author = {Shadija, Dharmendra and Rezai, Mo and Hill, Richard},
title = {Microservices: Granularity vs. Performance},
year = {2017},
isbn = {9781450351959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3147234.3148093},
doi = {10.1145/3147234.3148093},
abstract = {Microservice Architectures (MA) have the potential to increase the agility of software development. In an era where businesses require software applications to evolve to support emerging software requirements, particularly for Internet of Things (IoT) applications, we examine the issue of microservice granularity and explore its effect upon application latency. Two approaches to microservice deployment are simulated; the first with microservices in a single container, and the second with microservices partitioned across separate containers. We observed a negligible increase in service latency for the multiple container deployment over a single container.},
booktitle = {Companion Proceedings of The10th International Conference on Utility and Cloud Computing},
pages = {215–220},
numpages = {6},
keywords = {microservice architecture, performance, software engineering, internet of things},
location = {Austin, Texas, USA},
series = {UCC '17 Companion}
}

@article{10.1145/3432814,
author = {Mukhopadhyay, Anand Kumar and Sharma, Atul and Chakrabarti, Indrajit and Basu, Arindam and Sharad, Mrigank},
title = {Power-Efficient Spike Sorting Scheme Using Analog Spiking Neural Network Classifier},
year = {2021},
issue_date = {January 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {2},
issn = {1550-4832},
url = {https://doi.org/10.1145/3432814},
doi = {10.1145/3432814},
abstract = {The method to map the neural signals to the neuron from which it originates is spike sorting. A low-power spike sorting system is presented for a neural implant device. The spike sorter constitutes a two-step trainer module that is shared by the signal acquisition channel associated with multiple electrodes. A low-power Spiking Neural Network (SNN) module is responsible for assigning the spike class. The two-step shared supervised on-chip training module is presented for improved training accuracy for the SNN. Post implant, the relatively power-hungry training module can be activated conditionally based on a statistics-driven retraining algorithm that allows on the fly training and adaptation. A low-power analog implementation for the SNN classifier is proposed based on resistive crossbar memory exploiting its approximate computing nature. Owing to the direct mapping of SNN functionality using physical characteristics of devices, the analog mode implementation can achieve ∼21 \texttimes{} lower power than its fully digital counterpart. We also incorporate the effect of device variation in the training process to suppress the impact of inevitable inaccuracies in such resistive crossbar devices on the classification accuracy. A variation-aware, digitally calibrated analog front-end is also presented, which consumes less than ∼50 nW power and interfaces with the digital training module as well as the analog SNN spike sorting module. Hence, the proposed scheme is a low-power, variation-tolerant, adaptive, digitally trained, all-analog spike sorter device, applicable to implantable and wearable multichannel brain-machine interfaces.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = jan,
articleno = {12},
numpages = {29},
keywords = {spike sorting, resistive crossbar network (RCN), spiking neural network (SNN), neuromorphic computing, Adaptation}
}

@inproceedings{10.1145/3292006.3300048,
author = {Gupta, Maanak and Benson, James and Patwa, Farhan and Sandhu, Ravi},
title = {Dynamic Groups and Attribute-Based Access Control for Next-Generation Smart Cars},
year = {2019},
isbn = {9781450360999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292006.3300048},
doi = {10.1145/3292006.3300048},
abstract = {Smart cars are among the essential components and major drivers of future cities and connected world. The interaction among connected entities in this vehicular internet of things (IoT) domain, which also involves smart traffic infrastructure, restaurant beacons, emergency vehicles, etc., offer several real-time applications and provide safer and pleasant driving experience to consumers. With more than 100 million lines of code and hundreds of sensors, these connected vehicles (CVs) expose a large attack surface, which can be remotely compromised and exploited by malicious attackers. Security and privacy are big concerns that deter the adoption of smart cars, which if not properly addressed will have grave implications with risk to human life and limb. In this paper, we present a formalized dynamic groups and attribute-based access control (ABAC) model (referred as CV-ABAC-G) for smart cars ecosystem, where the model not only considers system wide attributes-based security policies but also takes into account the individual user privacy preferences for allowing or denying service notifications, alerts and operations to on-board resources. Further, we introduce a novel notion of groups in vehicular IoT, which are dynamically assigned to moving entities like connected cars, based on their current GPS coordinates, speed or other attributes, to ensure relevance of location and time sensitive notification services, to provide administrative benefits to manage large numbers of entities, and to enable attributes inheritance for fine-grained authorization policies. We present proof of concept implementation of our model in AWS cloud platform demonstrating real-world uses cases along with performance metrics.},
booktitle = {Proceedings of the Ninth ACM Conference on Data and Application Security and Privacy},
pages = {61–72},
numpages = {12},
keywords = {autonomous cars, access control, authorization, privacy, internet of things, cloud computing, amazon web services (aws), smart cars, security, attribute-based access control, connected vehicles},
location = {Richardson, Texas, USA},
series = {CODASPY '19}
}

@article{10.1145/3412383,
author = {Edu, Jide S. and Such, Jose M. and Suarez-Tangil, Guillermo},
title = {Smart Home Personal Assistants: A Security and Privacy Review},
year = {2020},
issue_date = {February 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3412383},
doi = {10.1145/3412383},
abstract = {Smart Home Personal Assistants (SPA) are an emerging innovation that is changing the means by which home users interact with technology. However, several elements expose these systems to various risks: (i) the open nature of the voice channel they use, (ii) the complexity of their architecture, (iii) the AI features they rely on, and (iv) their use of a wide range of underlying technologies. This article presents an in-depth review of SPA’s security and privacy issues, categorizing the most important attack vectors and their countermeasures. Based on this, we discuss open research challenges that can help steer the community to tackle and address current security and privacy issues in SPA. One of our key findings is that even though the attack surface of SPA is conspicuously broad and there has been a significant amount of recent research efforts in this area, research has so far focused on a small part of the attack surface, particularly on issues related to the interaction between the user and the SPA devices. To the best of our knowledge, this is the first article to conduct such a comprehensive review and characterization of the security and privacy issues and countermeasures of SPA.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {116},
numpages = {36},
keywords = {Smart home personal assistants, Google Home/assistant, security and privacy, voice assistants, Apple Home Pod/Siri, Amazon Echo/Alexa, Microsoft Home Speaker/Cortana, smart home}
}

@article{10.1145/3282517.3302396,
author = {Raibulet, Claudia and Fugini, Mariagrazia and Drira, Khalil and Pelliccione, Patrizio and Gerostathopoulos, Ilias and Prehofer, Christian and Moessner, Klaus},
title = {Report of the 1st International Workshop on Context-Aware Autonomous and Smart Architectures (CASA@ECSA 2017)},
year = {2019},
issue_date = {October 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {4},
issn = {0163-5948},
url = {https://doi.org/10.1145/3282517.3302396},
doi = {10.1145/3282517.3302396},
abstract = {The 2017 1st International Workshop on Context-aware, Autonomous and Smart Architectures (CASA 2017) was held in conjunction with the 11th European Conference on Software Architecture (ECSA 2017), on September, 12th, 2017 in Canterbury, United Kingdom. The goal of this one-day workshop was to bring together researchers and practitioners from academic environment and from the industry to share their solutions, ideas, visions, and doubts in the design of software architectures for context-aware, autonomous, and smart solutions. The workshop focused on architectural aspects offering a complementary vision of such solutions with respect to the available application- and user-oriented perspectives on context-awareness, autonomy, and smartness. Furthermore, the workshop aimed to enable discussions, partnerships, and collaborations among the software engineers interested in these solutions.},
journal = {SIGSOFT Softw. Eng. Notes},
month = jan,
pages = {24–27},
numpages = {4},
keywords = {autonomous, adaptation, software architecture, self-management, smart, Context-aware}
}

@article{10.1109/TNET.2019.2890860,
author = {Luo, Chengwen and Liu, Xiao and Xue, Wanli and Shen, Yiran and Li, Jianqiang and Hu, Wen and Liu, Alex X.},
title = {Predictable Privacy-Preserving Mobile Crowd Sensing: A Tale of Two Roles},
year = {2019},
issue_date = {February 2019},
publisher = {IEEE Press},
volume = {27},
number = {1},
issn = {1063-6692},
url = {https://doi.org/10.1109/TNET.2019.2890860},
doi = {10.1109/TNET.2019.2890860},
abstract = {The rise of mobile crowd sensing has brought privacy issues into a sharp view. In this paper, our goal is to achieve the predictable privacy-preserving mobile crowd sensing, which we envision to have the capability to quantify the privacy protections, and simultaneously allowing application users to predict the utility loss at the same time. The Salus algorithm is first proposed to protect the private data against the data reconstruction attacks. To understand privacy protection, we quantify the privacy risks in terms of private data leakage under reconstruction attacks. To predict the utility, we provide accurate utility predictions for various crowd sensing applications using Salus. The risk assessments can be generally applied to different type of sensors on the mobile platform, and the utility prediction can also be used to support various applications that use data aggregators such as average, histogram, and classifiers. Finally, we propose and implement the $P^{3}$ application framework. Both measurement results using online datasets and real-world case studies show that the $P^{3}$ provides accurate risk assessments and utility estimations, which makes it a promising framework to support future privacy-preserving mobilecrowd sensing applications.},
journal = {IEEE/ACM Trans. Netw.},
month = feb,
pages = {361–374},
numpages = {14}
}

@inbook{10.1145/3328905.3329506,
author = {Russo, Gabriele Russo and Cardellini, Valeria and Presti, Francesco Lo},
title = {Reinforcement Learning Based Policies for Elastic Stream Processing on Heterogeneous Resources},
year = {2019},
isbn = {9781450367943},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3328905.3329506},
abstract = {Data Stream Processing (DSP) has emerged as a key enabler to develop pervasive services that require to process data in a near real-time fashion. DSP applications keep up with the high volume of produced data by scaling their execution on multiple computing nodes, so as to process the incoming data flow in parallel. Workloads variability requires to elastically adapt the application parallelism at run-time in order to avoid over-provisioning. Elasticity policies for DSP have been widely investigated, but mostly under the simplifying assumption of homogeneous infrastructures. The resulting solutions do not capture the richness and inherent complexity of modern infrastructures, where heterogeneous computing resources are available on-demand. In this paper, we formulate the problem of controlling elasticity on heterogeneous resources as a Markov Decision Process (MDP). The resulting MDP is not easily solved by traditional techniques due to state space explosion, and thus we show how linear Function Approximation and Tile Coding can be used to efficiently compute elasticity policies at run-time. In order to deal with parameters uncertainty, we integrate the proposed approach with Reinforcement Learning algorithms. Our numerical evaluation shows the efficacy of the presented solutions compared to standard methods in terms of accuracy and convergence speed.},
booktitle = {Proceedings of the 13th ACM International Conference on Distributed and Event-Based Systems},
pages = {31–42},
numpages = {12}
}

@article{10.1145/3397318,
author = {Li, Boning and Sano, Akane},
title = {Extraction and Interpretation of Deep Autoencoder-Based Temporal Features from Wearables for Forecasting Personalized Mood, Health, and Stress},
year = {2020},
issue_date = {June 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {2},
url = {https://doi.org/10.1145/3397318},
doi = {10.1145/3397318},
abstract = {Continuous wearable sensor data in high resolution contain physiological and behavioral information that can be utilized to predict human health and wellbeing, establishing the foundation for developing early warning systems to eventually improve human health and wellbeing. We propose a deep neural network framework, the Locally Connected Long Short-Term Memory Denoising AutoEncoder (LC-LSTM-DAE), to automatically extract features from passively collected raw sensor data and perform personalized prediction of self-reported mood, health, and stress scores with high precision. We enabled personalized learning of features by finetuning the general representation model with participant-specific data. The framework was evaluated using wearable sensor data and wellbeing labels collected from college students (total 6391 days from N=239). Sensor data include skin temperature, skin conductance, and acceleration; wellbeing labels include self-reported mood, health and stress scored 0 - 100. Compared to the prediction performance based on hand-crafted features, the proposed framework achieved higher precision with a smaller number of features. We also provide statistical interpretation and visual explanation to the automatically learned features and the prediction models. Our results show the possibility of predicting self-reported mood, health, and stress accurately using an interpretable deep learning framework, ultimately for developing real-time health and wellbeing monitoring and intervention systems that can benefit various populations.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = jun,
articleno = {49},
numpages = {26},
keywords = {neural networks, mood, health monitoring, regression, stress}
}

@article{10.1145/3351260,
author = {Shatilov, Kirill A. and Chatzopoulos, Dimitris and Hang, Alex Wong Tat and Hui, Pan},
title = {Using Deep Learning and Mobile Offloading to Control a 3D-Printed Prosthetic Hand},
year = {2019},
issue_date = {September 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {3},
url = {https://doi.org/10.1145/3351260},
doi = {10.1145/3351260},
abstract = {Although many children are born with congenital limb malformation, contemporary functional artificial hands are costly and are not meant to be adapted to growing hand. In this work, we develop a low cost, adaptable and personalizable system of an artificial prosthetic hand accompanied with hardware and software modules. Our solution consists of (i) a consumer grade electromyography (EMG) recording hardware, (ii) a mobile companion device empowered by deep learning classification algorithms, (iii) an cloud component for offloading computations, and (iv) mechanical 3D printed arm operated by the embedded hardware. We focus on the flexibility of the designed system making it more affordable than the alternatives. We use 3D printed materials and open-source software thus enabling the community to contribute and improve the system. In this paper, we describe the proposed system and its components and present the experiments we conducted in order to show the feasibility and applicability of our approach. Extended experimentation shows that our proposal is energy efficient and has high accuracy.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {102},
numpages = {19},
keywords = {Deep learning, EMG, Electromyography, prosthesis}
}

@inproceedings{10.1145/2973750.2973757,
author = {Syed, Aisha and Van der Merwe, Jacobus},
title = {P<span class="smallcaps SmallerCapital">roteus</span>: A Network Service Control Platform for Service Evolution in a Mobile Software Defined Infrastructure},
year = {2016},
isbn = {9781450342261},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2973750.2973757},
doi = {10.1145/2973750.2973757},
abstract = {We present Proteus, a mobile network service control platform to enable safe and rapid evolution of services in a mobile software defined infrastructure (SDI). Proteus allows for network service and network component functionality to be specified in templates. These templates are used by the Proteus orchestrator to realize and modify service instances based on the specifics of a service creation request and the availability of resources in the mobile SDI and allows for service specific policies to be implemented. We evaluate our Proteus prototype in a realistic mobile networking testbed illustrating its ability to support service evolution.},
booktitle = {Proceedings of the 22nd Annual International Conference on Mobile Computing and Networking},
pages = {257–270},
numpages = {14},
keywords = {service evolution, templates, data centric, orchestration, software defined infrastructure, mobile networks},
location = {New York City, New York},
series = {MobiCom '16}
}

@inproceedings{10.1145/3093742.3093910,
author = {An, Kyoungho and Khare, Shweta and Gokhale, Aniruddha and Hakiri, Akram},
title = {An Autonomous and Dynamic Coordination and Discovery Service for Wide-Area Peer-to-Peer Publish/Subscribe: Experience Paper},
year = {2017},
isbn = {9781450350655},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3093742.3093910},
doi = {10.1145/3093742.3093910},
abstract = {Industrial Internet of Things (IIoT) applications are mission-critical, which require a scalable data sharing and dissemination platform that supports quality of service (QoS) properties such as timeliness, resilience, and security. Although the Object Management Group (OMG)'s Data Distribution Service (DDS), which is a data-centric, peer-to-peer publish/subscribe standard supporting multiple QoS properties, is well-suited to meet the requirements of IIoT applications, its design and current technology limitations constrains its use to local area networks only. Moreover, although broker-based bridging services exist to inter-connect isolated DDS networks, these solutions lack autonomous and dynamic coordination and discovery capabilities that are needed to bridge multiple, isolated networks on demand. To address these limitations, and enable a practical and readily deployable solution for IIoT, this paper presents and empirically validates PubSubCoord, which is an autonomous, coordination and discovery service for DDS endpoints operating over wide area networks.},
booktitle = {Proceedings of the 11th ACM International Conference on Distributed and Event-Based Systems},
pages = {239–248},
numpages = {10},
keywords = {Pub/Sub, Coordination, Data Distribution Service, Discovery},
location = {Barcelona, Spain},
series = {DEBS '17}
}

@inproceedings{10.1145/3322645.3322651,
author = {Ni, David C. and Shen, Erik and Hsu, Sunny},
title = {Protocol Integration for Vertical Systems},
year = {2019},
isbn = {9781450361033},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3322645.3322651},
doi = {10.1145/3322645.3322651},
abstract = {As AIoT standards, such as wired-wireless sensor and control networks, are established, the users are seeking vertical systems for inclusion of backend services. In this paper, we present an implemented case of integration of wired DALI standard and wireless Zigbee standard by embedding the former protocol into the latter protocol, and further extend from frontend to backend systems via smart gateways, device and connectivity management framework from perspectives of end-to-end service systems.},
booktitle = {Proceedings of the 2019 2nd International Conference on Information Science and Systems},
pages = {247–251},
numpages = {5},
keywords = {Protocol, Integration, Embedded, Device Management, Connectivity Management, Zigbee, DALI},
location = {Tokyo, Japan},
series = {ICISS 2019}
}

@inproceedings{10.1145/3427477.3429273,
author = {Anand, Sruthy and Vinodini Ramesh, Maneesha},
title = {An IoT Based Disaster Response Solution for Ocean Environment},
year = {2021},
isbn = {9781450381840},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3427477.3429273},
doi = {10.1145/3427477.3429273},
abstract = { This paper discusses the importance of an emergency response system for the ocean disasters that affect the life of the fisher community. Ocean emergencies can vary from the extreme climatic conditions, collision between boats and ships as well as other unexpected health emergencies that may be faced by the older fishermen while at the ocean. We discuss the challenges in implementing disaster response activities in ocean scenarios and propose an IoT solution for the fisher community to help them during emergencies as well as to maintain frequent communication with the shore. This paper also presents how this IoT solution can bring a change in the fishermen’s life and how our solution can be used when they are in danger. We also proposed a partial-context aware algorithm that helps to monitor the fishing vessel movements and how this algorithm can help during an emergency. },
booktitle = {Adjunct Proceedings of the 2021 International Conference on Distributed Computing and Networking},
pages = {19–24},
numpages = {6},
keywords = {IoT, Disaster management, Emergency Response, Emergency Management, Technology Acceptance, Disaster},
location = {Nara, Japan},
series = {ICDCN '21}
}

@inproceedings{10.1145/3229631.3239370,
author = {Cristal, Adrian and Unsal, Osman S. and Martorell, Xavier and Carpenter, Paul and De La Cruz, Raul and Bautista, Leonardo and Jimenez, Daniel and Alvarez, Carlos and Salami, Behzad and Madonar, Sergi and Peric\`{a}s, Miquel and Trancoso, Pedro and vor dem Berge, Micha and Billung-Meyer, Gunnar and Krupop, Stefan and Christmann, Wolfgang and Klawonn, Frank and Mihklafi, Amani and Becker, Tobias and Gaydadjiev, Georgi and Salomonsson, Hans and Dubhashi, Devdatt and Port, Oron and Hadar, Elad and Etsion, Yoav and Fetzer, Christof and Hagemeyer, Jens and Jungeblut, Thorsten and Kucza, Nils and Kaiser, Martin and Porrmann, Mario and Pasin, Marcelo and Schiavoni, Valerio and Rocha, Isabelly and G\"{o}ttel, Christian and Felber, Pascal},
title = {LEGaTO: First Steps towards Energy-Efficient Toolset for Heterogeneous Computing},
year = {2018},
isbn = {9781450364942},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3229631.3239370},
doi = {10.1145/3229631.3239370},
abstract = {LEGaTO is a three-year EU H2020 project which started in December 2017. The LEGaTO project will leverage task-based programming models to provide a software ecosystem for Made-in-Europe heterogeneous hardware composed of CPUs, GPUs, FPGAs and dataflow engines. The aim is to attain one order of magnitude energy savings from the edge to the converged cloud/HPC.},
booktitle = {Proceedings of the 18th International Conference on Embedded Computer Systems: Architectures, Modeling, and Simulation},
pages = {210–217},
numpages = {8},
location = {Pythagorion, Greece},
series = {SAMOS '18}
}

@article{10.1145/3165266,
author = {Petrangeli, Stefano and Hooft, Jeroen Van Der and Wauters, Tim and Turck, Filip De},
title = {Quality of Experience-Centric Management of Adaptive Video Streaming Services: Status and Challenges},
year = {2018},
issue_date = {May 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2s},
issn = {1551-6857},
url = {https://doi.org/10.1145/3165266},
doi = {10.1145/3165266},
abstract = {Video streaming applications currently dominate Internet traffic. Particularly, HTTP Adaptive Streaming (HAS) has emerged as the dominant standard for streaming videos over the best-effort Internet, thanks to its capability of matching the video quality to the available network resources. In HAS, the video client is equipped with a heuristic that dynamically decides the most suitable quality to stream the content, based on information such as the perceived network bandwidth or the video player buffer status. The goal of this heuristic is to optimize the quality as perceived by the user, the so-called Quality of Experience (QoE). Despite the many advantages brought by the adaptive streaming principle, optimizing users’ QoE is far from trivial. Current heuristics are still suboptimal when sudden bandwidth drops occur, especially in wireless environments, thus leading to freezes in the video playout, the main factor influencing users’ QoE. This issue is aggravated in case of live events, where the player buffer has to be kept as small as possible in order to reduce the playout delay between the user and the live signal. In light of the above, in recent years, several works have been proposed with the aim of extending the classical purely client-based structure of adaptive video streaming, in order to fully optimize users’ QoE. In this article, a survey is presented of research works on this topic together with a classification based on where the optimization takes place. This classification goes beyond client-based heuristics to investigate the usage of server- and network-assisted architectures and of new application and transport layer protocols. In addition, we outline the major challenges currently arising in the field of multimedia delivery, which are going to be of extreme relevance in future years.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = may,
articleno = {31},
numpages = {29},
keywords = {HTTP adaptive streaming, Quality of experience, MPEG-DASH}
}

@article{10.1145/3176648,
author = {Skorin-Kapov, Lea and Varela, Mart\'{\i}n and Ho\ss{}feld, Tobias and Chen, Kuan-Ta},
title = {A Survey of Emerging Concepts and Challenges for QoE Management of Multimedia Services},
year = {2018},
issue_date = {May 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2s},
issn = {1551-6857},
url = {https://doi.org/10.1145/3176648},
doi = {10.1145/3176648},
abstract = {Quality of Experience (QoE) has received much attention over the past years and has become a prominent issue for delivering services and applications. A significant amount of research has been devoted to understanding, measuring, and modelling QoE for a variety of media services. The next logical step is to actively exploit that accumulated knowledge to improve and manage the quality of multimedia services, while at the same time ensuring efficient and cost-effective network operations. Moreover, with many different players involved in the end-to-end service delivery chain, identifying the root causes of QoE impairments and finding effective solutions for meeting the end users’ requirements and expectations in terms of service quality is a challenging and complex problem. In this article, we survey state-of-the-art findings and present emerging concepts and challenges related to managing QoE for networked multimedia services. Going beyond a number of previously published survey articles addressing the topic of QoE management, we address QoE management in the context of ongoing developments, such as the move to softwarized networks, the exploitation of big data analytics and machine learning, and the steady rise of new and immersive services (e.g., augmented and virtual reality). We address the implications of such paradigm shifts in terms of new approaches in QoE modeling and the need for novel QoE monitoring and management infrastructures.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = may,
articleno = {29},
numpages = {29},
keywords = {QoE modeling, QoE management, QoE monitoring, monitoring probes, NFV, encrypted traffic, data analytics, SDN, crowdsourcing}
}

@inproceedings{10.1145/3386723.3387834,
author = {Lo, Nogaye and Niang, Ibrahima},
title = {A Survey on QoS-Based Communication Protocols for IoT Systems},
year = {2020},
isbn = {9781450376341},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386723.3387834},
doi = {10.1145/3386723.3387834},
abstract = {Internet of Things (IoT) contributes to development of world through its technological contributions and its daily applications. Several technologies and protocols are used for the implementation of new applications allowing physical objects to connect with each other in support of smart decision-making. To provide efficient and reliable services to its end-users, it guarantees the quality of its pragmatic use by referring to QoS criteria.This implies efficient management of the quality of service in IoT systems in order to meet requirements of their applications. In this paper, we offer an analysis of quality of service mechanisms of communication protocols in IoT environment. This study opens a new perspective of dynamic QoS management.},
booktitle = {Proceedings of the 3rd International Conference on Networking, Information Systems &amp; Security},
articleno = {15},
numpages = {9},
keywords = {Internet of Things (IoT), Quality of service (QoS), Communication protocols},
location = {Marrakech, Morocco},
series = {NISS2020}
}

@inproceedings{10.1145/3371238.3371246,
author = {Lin, Jun and Long, Wen and Zhang, Anting and Chai, Yueting},
title = {Using Blockchain and IoT Technologies to Enhance Intellectual Property Protection},
year = {2019},
isbn = {9781450376402},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3371238.3371246},
doi = {10.1145/3371238.3371246},
abstract = {The Blockchain technology provides a way to record transactions or any digital interaction that is designed to be secure, tamper-proof, transparent, highly resistant to outages, traceable and auditable. The Internet of Things (IoT) technology is able to link computing devices, mechanical and digital machines, objects, animals or people that are provided with unique identifiers (UIDs) and provides the ability to transfer data over a network without requiring human-to-human or human-to-computer interaction. These features encourage us to explore the combined application of IoT and Blockchain-based technology. In this paper, we propose a system architecture of blockchain and IoT based intellectual property protection system, which can process three types of intellectual property: 1) Patents, Copyrights, Trademarks etc.; 2) Industrial design, Trade dress, Craft works, Trade secrets etc.; and 3) Plant variety rights, Geographical indications etc. Using blockchain P2P network and IoT devices, the system can help us to establish a trusted, self-organized, open and ecological intellectual property protection system. To the best of our knowledge, this is the first work that applying blockchain technology and IoT technology on traditional intellectual property protection and trade ecosystem.},
booktitle = {Proceedings of the 4th International Conference on Crowd Science and Engineering},
pages = {44–49},
numpages = {6},
keywords = {Intellectual Property Protection, Internet of Things (IoT), Blockchain},
location = {Jinan, China},
series = {ICCSE'19}
}

@article{10.1145/3390860,
author = {Azad, Muhammad Ajmal and Perera, Charith and Bag, Samiran and Barhamgi, Mahmoud and Hao, Feng},
title = {Privacy-Preserving Crowd-Sensed Trust Aggregation in the User-Centeric Internet of People Networks},
year = {2021},
issue_date = {January 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {1},
issn = {2378-962X},
url = {https://doi.org/10.1145/3390860},
doi = {10.1145/3390860},
abstract = {Today we are relying on Internet technologies for numerous services, for example, personal communication, online businesses, recruitment, and entertainment. Over these networks, people usually create content, a skillful worker profile, and provide services that are normally watched and used by other users, thus developing a social network among people termed as the Internet of People. Malicious users could also utilize such platforms for spreading unwanted content that could bring catastrophic consequences to a social network provider and the society, if not identified on time. The use of trust management over these networks plays a vital role in the success of these services. Crowd-sensing people or network users for their views about certain content or content creators could be a potential solution to assess the trustworthiness of content creators and their content. However, the human involvement in crowd-sensing would have challenges of privacy preservation and preventing intentional assignment of the fake high score given to certain user/content. To address these challenges, in this article, we propose a novel trust model that evaluates the aggregate trustworthiness of the content creator and the content without compromising the privacy of the participating people in a crowdsource group. The proposed system has inherent properties of privacy protection of participants, performs operations in the decentralized setup, and considers the trust weights of participants in a private and secure way. The system ensures privacy of participants under the malicious and honest-but-curious adversarial models. We evaluated the performance of the system by developing a prototype and applying it to different real data from different online social networks.},
journal = {ACM Trans. Cyber-Phys. Syst.},
month = dec,
articleno = {4},
numpages = {24},
keywords = {trustworthiness, privacy-preserving system, crowdsourcing, Content rating}
}

@inbook{10.1145/3366423.3380241,
author = {Duggal, Rahul and Freitas, Scott and Xiao, Cao and Chau, Duen Horng and Sun, Jimeng},
title = {REST: Robust and Efficient Neural Networks for Sleep Monitoring in the Wild},
year = {2020},
isbn = {9781450370233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366423.3380241},
abstract = {In recent years, significant attention has been devoted towards integrating deep learning technologies in the healthcare domain. However, to safely and practically deploy deep learning models for home health monitoring, two significant challenges must be addressed: the models should be (1) robust against noise; and (2) compact and energy-efficient. We propose Rest , a new method that simultaneously tackles both issues via 1) adversarial training and controlling the Lipschitz constant of the neural network through spectral regularization while 2) enabling neural network compression through sparsity regularization. We demonstrate that Rest produces highly-robust and efficient models that substantially outperform the original full-sized models in the presence of noise. For the sleep staging task over single-channel electroencephalogram (EEG), the Rest model achieves a macro-F1 score of 0.67 vs. 0.39 achieved by a state-of-the-art model in the presence of Gaussian noise while obtaining 19 \texttimes{} parameter reduction and 15 \texttimes{} MFLOPS reduction on two large, real-world EEG datasets. By deploying these models to an Android application on a smartphone, we quantitatively observe that Rest allows models to achieve up to 17 \texttimes{} energy reduction and 9 \texttimes{} faster inference. We open source the code repository with this paper: https://github.com/duggalrahul/REST.},
booktitle = {Proceedings of The Web Conference 2020},
pages = {1704–1714},
numpages = {11}
}

@inproceedings{10.1145/3390566.3391675,
author = {Tan, Min and Li, Guo-hui and Wei, Ming and Huang, Fei and Zhang, Li and Hu, Xiang},
title = {Research on Application of Blockchain Technology in Cloud-Network Collaboration},
year = {2020},
isbn = {9781450377676},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3390566.3391675},
doi = {10.1145/3390566.3391675},
abstract = {With the deep integration of blockchain, cloud computing and 5G technology, the business model of the Internet is also undergoing subversive changes. Based on the current development trends of the industry, this article illustrates the application prospects of blockchain technology in cloud-network collaboration For users to purchase network services, blockchain technology and consensus accounting are adopted to effectively avoid uploading user data to the Internet company's cloud server, thereby protecting user privacy from threats. This article provides a solution that uses blockchain technology in cloud-network collaboration to ensure transaction security. At the same time, it analyzes the consensus mechanism for the actual application scenario, and selects a consensus mechanism which is suitable for the cloud-network collaborative application scenario.},
booktitle = {Proceedings of the 2020 The 2nd International Conference on Blockchain Technology},
pages = {140–143},
numpages = {4},
keywords = {Cloud-network collaboration, 5G, Blockchain token, Blockchain consensus},
location = {Hilo, HI, USA},
series = {ICBCT'20}
}

@article{10.1145/3428124,
author = {Roy, Dibyendu and Agarwal, Nitin and Mukherjee, Amitava and Angne, Jitendra and Farhan, Anees and Sorathiya, Deven and Devarajan, R. and Nair, Manukumar Velayudhan},
title = {Utilizing Smart City Cyber-Physical Infrastructure for Tracking and Monitoring Pandemics like COVID-19 with the ICCC as the Nerve Centre},
year = {2020},
issue_date = {January 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {1},
issn = {2691-199X},
url = {https://doi.org/10.1145/3428124},
doi = {10.1145/3428124},
abstract = {Managing the ongoing COVID-19 (aka Coronavirus) pandemic has presented both challenges and new opportunities for urban local body administrators. With the Indian government's Smart City mission taking firm roots in some of the Indian cities, the authors share their learnings and experiences of how a Smart City Integrated Command and Control Centre (ICCC) can be extended to become the nerve centre of pandemic-related operations and management, leveraging the Smart City IoT infrastructure such as surveillance cameras for monitoring and enforcement. The authors are of the opinion that the lessons learned and experiences gained from these cities are extremely valuable and can easily be replicated in other cities in a relatively short time period, thus providing a standard and uniform method across the nation for handling epidemics in the future.},
journal = {Digit. Gov.: Res. Pract.},
month = nov,
articleno = {8},
numpages = {8},
keywords = {VMS – Video Management System, VA – Video Analytics, SMS – Short Messaging Service, SOP – Standard Operating Procedures, ICT – Information and Communication Technologies, ICCC – Integrated Command and Control Centre, MIS – Management Information System, ICMR – Indian Council of Medical Research}
}

@inproceedings{10.1145/3381427.3381428,
author = {Hosseinabady, Mohammad and Nunez-Yanez, Jose},
title = {Sparse Matrix-Dense Matrix Multiplication on Heterogeneous CPU+FPGA Embedded System},
year = {2020},
isbn = {9781450375450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3381427.3381428},
doi = {10.1145/3381427.3381428},
abstract = {Embedded intelligence is becoming the primary driver for new applications in industry, healthcare, and automotive, to name a few. The main characteristics of these applications are high computational demand, real-time interaction with the environment, security, low power consumption, and local autonomy, among others. Addressing these diverse characteristics, researchers have proposed heterogeneous multicore embedded systems comprising CPUs, GPUs, FPGAs, and ASICs. Whereas each computing element provides a unique capability to enable one of the application characteristics, collaborating these processing cores in running an application to get the maximum performance is a crucial challenge. This paper considers the collaborative usage of a multicore CPU and an FPGA in a heterogeneous embedded system to improve the performance of sparse matrix operations, which have been essential techniques in reducing the inference complexity in machine learning techniques, especially deep convolutional neural networks. Experimental results show that the collaborative execution of sparse-matrix-dense-matrix multiplication on the Xilinx Zynq MPSoC, a heterogeneous CPU+FPGA embedded system, can improve the performance by a factor of up to 42% compared with just using the FPGA as an accelerator.},
booktitle = {Proceedings of the 11th Workshop on Parallel Programming and Run-Time Management Techniques for Many-Core Architectures / 9th Workshop on Design Tools and Architectures for Multicore Embedded Computing Platforms},
articleno = {1},
numpages = {6},
keywords = {Heterogeneous System, Sparse Matrix, High-level Synthesis, Embedded FPGA},
location = {Bologna, Italy},
series = {PARMA-DITAM'2020}
}

@inproceedings{10.1145/3389189.3397986,
author = {Plattner, Johanna and Oberrauner, Elena and Str\"{o}ckl, Daniela Elisabeth and Oberzaucher, Johannes},
title = {Using IoT Middleware Solutions in Interdisciplinary Research Projects in the Context of AAL},
year = {2020},
isbn = {9781450377737},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3389189.3397986},
doi = {10.1145/3389189.3397986},
abstract = {Research projects in the field of Active and Assisted Living (AAL) are dedicated to enhance quality of life and independent living of the elderly by providing assistive technical and non-technical solutions. With the progress of the Age of Internet of Things (IoT) and digitalization, the implemented applications are also often focused on the integration of IoT technologies. As the field of AAL is characterized by a high amount of interdisciplinarity, there arises the need of integrating various proprietary solutions to one comprehensive application. This can be achieved by using dedicated IoT middleware solutions which provide the possibility to integrate information from different systems, users and devices into one comprehensive application. The aim of this paper is to show an overview on the process of interdisciplinary research in the field of AAL and to demonstrate the arising requirements for IoT middleware solutions in the given context. Furthermore, selected middleware frameworks and platforms are presented and the implementation of one selected solution is described for a given use case from the Smart VitAALity project.},
booktitle = {Proceedings of the 13th ACM International Conference on PErvasive Technologies Related to Assistive Environments},
articleno = {51},
numpages = {6},
keywords = {FIWARE, IoT middleware, IoT requirements, interdisciplinary research, AAL},
location = {Corfu, Greece},
series = {PETRA '20}
}

@article{10.1145/3243157.3243168,
author = {Calyam, Prasad and Ricart, Glenn},
title = {Research and Infrastructure Challenges for Applications and Services in the Year 2021},
year = {2018},
issue_date = {July 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {3},
issn = {0146-4833},
url = {https://doi.org/10.1145/3243157.3243168},
doi = {10.1145/3243157.3243168},
abstract = {The Applications and Services in the Year 2021 workshop was successfully organized on January 27--28, 2016 in Washington DC through funding support from the National Science Foundation (NSF). The goal of the workshop was to foster discussions that bring together applications researchers in multidisciplinary areas, and developers/operators of research infrastructures at both national, regional, university and city levels. Discussions were organized to identify grand challenge applications and obtain the community voice and consensus on the key issues relating to applications and services that might be delivered by advanced infrastructures in the decade beginning in 2020. The timing and organization for the workshop is significant because today's digital infrastructure is undergoing deep technological changes and new paradigms are rapidly taking shape in both the core and edge domains that pose fundamental challenges. The key outcomes of the discussions were targeted to enhance the quality of peoples' lives while addressing important national priorities, leveraging today's cutting edge applications such as the Internet of Things, Big Data Analytics, Robotics, The Industrial Internet, and Immersive Virtual/Augmented Reality. This report summarizes the workshop efforts to bring together diverse groups for delivering targeted short/long talks, sharing latest advances, and identifying gaps that exist in the community for 'research' and 'infrastructure' needs that require future NSF funding.},
journal = {SIGCOMM Comput. Commun. Rev.},
month = jul,
articleno = {11},
numpages = {5}
}

@inbook{10.1145/3340531.3412745,
author = {Li, Liangwei and Sun, Liucheng and Weng, Chenwei and Huo, Chengfu and Ren, Weijun},
title = {Spending Money Wisely: Online Electronic Coupon Allocation Based on Real-Time User Intent Detection},
year = {2020},
isbn = {9781450368599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340531.3412745},
abstract = {Online electronic coupon (e-coupon) is becoming a primary tool for e-commerce platforms to attract users to place orders. E-coupons are the digital equivalent of traditional paper coupons which provide customers with discounts or gifts. One of the fundamental problems related is how to deliver e-coupons with minimal cost while users' willingness to place an order is maximized. We call this problem the coupon allocation problem. This is a non-trivial problem since the number of regular users on a mature e-platform often reaches hundreds of millions and the types of e-coupons to be allocated are often multiple. The policy space is extremely large and the online allocation has to satisfy a budget constraint. Besides, one can never observe the responses of one user under different policies which increases the uncertainty of the policy making process. Previous work fails to deal with these challenges. In this paper, we decompose the coupon allocation task into two subtasks: the user intent detection task and the allocation task. Accordingly, we propose a two-stage solution: at the first stage (detection stage), we put forward a novel Instantaneous Intent Detection Network (IIDN) which takes the user-coupon features as input and predicts user real-time intents; at the second stage (allocation stage), we model the allocation problem as a Multiple-Choice Knapsack Problem (MCKP) and provide a computational efficient allocation method using the intents predicted at the detection stage. Long Short Term Memory (LSTM) and a special attention mechanism are applied on IIDN to better describe temporal dependencies of sequential features. And we manage to solve the imbalanced label problem for the user intent detection task with a brand new perspective by using the logical relationship between multiple user intents. We conduct extensive online and offline experiments and the results show the superiority of our proposed framework, which has brought great profits to the platform and continues to function online.},
booktitle = {Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management},
pages = {2597–2604},
numpages = {8}
}

@inproceedings{10.5555/3199700.3199820,
author = {Nakamura, Yuichi and Shimonishi, Hideyuki and Satoda, Kozo and Kanetomo, Dai and Kobayashi, Yuki and Matsunaga, Yashuhiro},
title = {Novel Heterogeneous Computing Platforms and 5G Communications for IoT Applications},
year = {2017},
publisher = {IEEE Press},
abstract = {IoT(Internet of Things), which collects various data in real world and analyzes values from collected data is one of good methods to help solve such serious problems and to construct efficient social systems. Meanwhile, since collected data is very complicated and has huge size, it takes a long time to collect and analyze "Complicated Big data". Then, efficient computer systems and efficient network systems are necessary. Integration of heterogeneous computing and 5G network is one of the best platforms to provide complex IoT systems and services. In this paper, first, a reason why complex IoT systems require high performance hetero computing and high-speed communication systems like as 5G is presented. In the next, some use cases of IoT systems infrastructures empowered by hetero computing are also introduced.},
booktitle = {Proceedings of the 36th International Conference on Computer-Aided Design},
pages = {874–879},
numpages = {6},
keywords = {heterogeneous computing, IoT, 5G},
location = {Irvine, California},
series = {ICCAD '17}
}

@inproceedings{10.1145/3395352.3402619,
author = {Luo, Zhengping and Zhao, Shangqing and Lu, Zhuo and Sagduyu, Yalin E. and Xu, Jie},
title = {Adversarial Machine Learning Based Partial-Model Attack in IoT},
year = {2020},
isbn = {9781450380072},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3395352.3402619},
doi = {10.1145/3395352.3402619},
abstract = {As Internet of Things (IoT) has emerged as the next logical stage of the Internet, it has become imperative to understand the vulnerabilities of the IoT systems when supporting diverse applications. Because machine learning has been applied in many IoT systems, the security implications of machine learning need to be studied following an adversarial machine learning approach. In this paper, we propose an adversarial machine learning based partial-model attack in the data fusion/aggregation process of IoT by only controlling a small part of the sensing devices. Our numerical results demonstrate the feasibility of this attack to disrupt the decision making in data fusion with limited control of IoT devices, e.g., the attack success rate reaches 83% when the adversary tampers with only 8 out of 20 IoT devices. These results show that the machine learning engine of IoT system is highly vulnerable to attacks even when the adversary manipulates a small portion of IoT devices, and the outcome of these attacks severely disrupts IoT system operations.},
booktitle = {Proceedings of the 2nd ACM Workshop on Wireless Security and Machine Learning},
pages = {13–18},
numpages = {6},
keywords = {adversarial machine learning, data fusion, internet of things, wireless security, machine learning},
location = {Linz, Austria},
series = {WiseML '20}
}

@article{10.1145/3432191,
author = {Kortbeek, Vito and Bakar, Abu and Cruz, Stefany and Yildirim, Kasim Sinan and Pawe\l{}czak, Przemys\l{}aw and Hester, Josiah},
title = {BFree: Enabling Battery-Free Sensor Prototyping with Python},
year = {2020},
issue_date = {December 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {4},
url = {https://doi.org/10.1145/3432191},
doi = {10.1145/3432191},
abstract = {Building and programming tiny battery-free energy harvesting embedded computer systems is hard for the average maker because of the lack of tools, hard to comprehend programming models, and frequent power failures. With the high ecologic cost of equipping the next trillion embedded devices with batteries, it is critical to equip the makers, hobbyists, and novice embedded systems programmers with easy-to-use tools supporting battery-free energy harvesting application development. This way, makers can create untethered embedded systems that are not plugged into the wall, the desktop, or even a battery, providing numerous new applications and allowing for a more sustainable vision of ubiquitous computing. In this paper, we present BFree, a system that makes it possible for makers, hobbyists, and novice embedded programmers to develop battery-free applications using Python programming language and widely available hobbyist maker platforms. BFree provides energy harvesting hardware and a power failure resilient version of Python, with durable libraries that enable common coding practice and off the shelf sensors. We develop demonstration applications, benchmark BFree against battery-powered approaches, and evaluate our system in a user study. This work enables makers to engage with a future of ubiquitous computing that is useful, long-term, and environmentally responsible.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = dec,
articleno = {135},
numpages = {39},
keywords = {Intermittent Computing, Energy Harvesting, Making}
}

@inproceedings{10.1145/3177102.3177107,
author = {Zhang, Wenxiao and Han, Bo and Hui, Pan and Gopalakrishnan, Vijay and Zavesky, Eric and Qian, Feng},
title = {CARS: Collaborative Augmented Reality for Socialization},
year = {2018},
isbn = {9781450356305},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3177102.3177107},
doi = {10.1145/3177102.3177107},
abstract = {As Augmented Reality (AR) ties closely to the physical world, its users looking at overlapped scenes are likely to be in the vicinity of each other, which naturally enables the collaboration and interaction among them. In this paper, we propose CARS (Collaborative Augmented Reality for Socialization), a framework that leverages the social nature of human beings to improve the user-perceived Quality of Experience (QoE) for AR, especially the end-to-end latency. CARS takes advantage of the unique feature of AR to support intelligent sharing of information between nearby users when it is feasible. It brings various benefits at the user, application and system levels, e.g., reduction of end-to-end latency and reuse of networking and computation resources. We demonstrate the efficacy of CARS through a preliminary evaluation based on a prototype implementation.},
booktitle = {Proceedings of the 19th International Workshop on Mobile Computing Systems &amp; Applications},
pages = {25–30},
numpages = {6},
keywords = {device to device communication, collaborative augmented reality, augmented reality, cloud offloading},
location = {Tempe, Arizona, USA},
series = {HotMobile '18}
}

@inproceedings{10.5555/3320516.3320607,
author = {Tolk, Andreas},
title = {The Elusiveness of Simulation Interoperability: What is Different from Other Interoperability Domains?},
year = {2018},
isbn = {978153866570},
publisher = {IEEE Press},
abstract = {Simulation interoperability is a recurring theme in simulation conferences and workshops for more than 20 years. With the IEEE Standards 1278 and 1516, two simulation interoperability standards were introduced, and both were adapted and implemented by the community. Nonetheless, the simulation community is still struggling with interoperability challenges that are not solved. Why is this the case? This paper gives an overview of the current approaches to simulation interoperability, including the standardized approaches as well as contributions of simulation formalism. It then addresses the mathematical foundations of simulation interoperability, including model theory. As a result, the need for the consistency in the representation of truth in all participating simulation systems emerges as the concept that needs to be addressed by interoperability solutions.},
booktitle = {Proceedings of the 2018 Winter Simulation Conference},
pages = {679–690},
numpages = {12},
location = {Gothenburg, Sweden},
series = {WSC '18}
}

@inproceedings{10.1145/3297662.3365787,
author = {Troiano, Ernesto and Soldatos, John and Polyviou, Ariana and Polyviou, Andreas and Mamelli, Alessandro and Drakoulis, Dimitris},
title = {Big Data Platform for Integrated Cyber and Physical Security of Critical Infrastructures for the Financial Sector: Critical Infrastructures as Cyber-Physical Systems},
year = {2019},
isbn = {9781450362382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297662.3365787},
doi = {10.1145/3297662.3365787},
abstract = {As critical infrastructures become more complex, sophisticated and digitally interconnected they are also more susceptible to cyber and physical security attacks. In order to mitigate the risks of such attacks, there is a need for securing them in an integrated way, which considers the simultaneous protection of their cyber and physical assets. In this paper we introduce a BigData platform that implements an integrated approach to securing and protecting critical infrastructures for the financial sector, by treating them as large scale cyber-physical systems. The main building blocks of the platform include an integrated security model that covers cyber and physical assets, an architecture for security monitoring and control based on appropriate probes, as well as a range of data analytics algorithms for detecting risks, vulnerabilities and threats. These building blocks are outlined in the paper, along with their deployment and use in a number of representative critical infrastructure protection use cases for the financial sector. One of the merits of our work is its reference character i.e. it can serve as a blueprint for developing and deploying systems for integrated cyber/physical security in various application areas.},
booktitle = {Proceedings of the 11th International Conference on Management of Digital EcoSystems},
pages = {262–269},
numpages = {8},
keywords = {Physical Security, Cyber Physical Systems, Finance, FINSTIX, STIX, Cybersecurity},
location = {Limassol, Cyprus},
series = {MEDES '19}
}

@article{10.1145/3204412,
author = {Wang, Ping and Ma, Meng and Chu, Chao-Hsien},
title = {Long-Term Event Processing over Data Streams in Cyber-Physical Systems},
year = {2018},
issue_date = {June 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {2},
issn = {2378-962X},
url = {https://doi.org/10.1145/3204412},
doi = {10.1145/3204412},
abstract = {Event processing is a crucial cornerstone supporting the revolution of Internet of Things (IoT) and Cyber-Physical Systems (CPS) by integrating physical-layer networking and providing intelligent computation and real-time control abilities. In various IoT and CPS application scenarios, the event processing systems are required to detect complex event patterns using large time window, namely long-term events. The detection of long-term event usually leads to a large number of redundant runtime instances and calculations that significantly deteriorates the system efficiency. In this article, we propose an efficient long-term event processing model, named Long-Term Complex Event Processing (LTCEP). It leverages the semantic constraints calculus to split long-term event into sub-models. We establish a long-term query and intermediate result buffering mechanism to optimize the real-time response ability and throughput performance. Experimental results show that LTCEP can effectively reduce more than 50% redundant runtime states, which provides over 60% faster response performance and around 30% higher system throughput comparing to other selected benchmarks. The results also imply that LTCEP model has better stability and scalability in large-scale event processing applications.},
journal = {ACM Trans. Cyber-Phys. Syst.},
month = jun,
articleno = {14},
numpages = {23},
keywords = {data stream, internet of things, event processing, long-term, Cyber-Physical Systems}
}

@inproceedings{10.1145/3361149.3361166,
author = {Moreno, Julio and Fernandez, Eduardo B. and Fernandez-Medina, Eduardo and Serrano, Manuel A.},
title = {BlockBD: A Security Pattern to Incorporate Blockchain in Big Data Ecosystems},
year = {2019},
isbn = {9781450362061},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3361149.3361166},
doi = {10.1145/3361149.3361166},
abstract = {Big Data is changing the perspective on how to obtain valuable information from data stored by organizations of all kinds. By using these insights, companies can make better decisions and thus achieve their business goals. However, each new technology can create new security problems, and Big Data is no exception. One of the major security issues in a Big Data ecosystem is what level of trust in data and data sources stakeholders can have: without reliable data, the results of data analysis lose value. In this paper, we propose a security pattern to improve traceability and veracity of data through the use of Blockchain technologies. In this pattern, Blockchain will be used as a distributed ledger where all operations performed on the data will be registered. Therefore, the veracity of the data will increase, as will the confidence in the insights obtained from the analysis. The purpose of this paper is to help Chief Security Officer and Big Data architects incorporate this mechanism to improve the security of their environment.},
booktitle = {Proceedings of the 24th European Conference on Pattern Languages of Programs},
articleno = {17},
numpages = {8},
keywords = {blockchain, security pattern, big data},
location = {Irsee, Germany},
series = {EuroPLop '19}
}

@inproceedings{10.1145/3302424.3303961,
author = {Im, Youngbin and Rahimzadeh, Parisa and Shouse, Brett and Park, Shinik and Joe-Wong, Carlee and Lee, Kyunghan and Ha, Sangtae},
title = {I Sent It: Where Does Slow Data Go to Wait?},
year = {2019},
isbn = {9781450362818},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3302424.3303961},
doi = {10.1145/3302424.3303961},
abstract = {Emerging applications like virtual reality (VR), augmented reality (AR), and 360-degree video aim to exploit the unprecedentedly low latencies promised by technologies like the tactile Internet and mobile 5G networks. Yet these promises are still unrealized. In order to fulfill them, it is crucial to understand where packet delays happen, which impacts protocol performance such as throughput and latency. In this work, we empirically find that sender-side protocol stack delays can cause high end-to-end latencies, though existing solutions primarily address network delays. Unfortunately, however, current latency diagnosis tools cannot even distinguish between delays on network links and delays in the end hosts. To close this gap, we present ELEMENT, a latency diagnosis framework that decomposes end-to-end TCP latency into endhost and network delays, without requiring admin privileges at the sender or receiver.We validate that ELEMENT achieves more than 90% accuracy in delay estimation compared to the ground truth in different production networks. To demonstrate ELEMENT's potential impact on real-world applications, we implement a relatively simple user-level library that uses ELEMENT to minimize delays. For evaluation, we integrate ELEMENT with legacy TCP applications and show that it can reduce latency by up to 10 times while maintaining throughput and fairness. We finally demonstrate that ELEMENT can significantly reduce the latency of a virtual reality application that needs extremely low latencies and high throughput.},
booktitle = {Proceedings of the Fourteenth EuroSys Conference 2019},
articleno = {22},
numpages = {15},
keywords = {Measurement tool, Latency control, TCP latency},
location = {Dresden, Germany},
series = {EuroSys '19}
}

@inproceedings{10.1145/3427477.3429990,
author = {Ahmed, Usman and Lin, Jerry Chun-Wei and Srivastava, Gautam and Djenouri, Youcef},
title = {A Deep Q-Learning Sanitization Approach for Privacy Preserving Data Mining},
year = {2021},
isbn = {9781450381840},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3427477.3429990},
doi = {10.1145/3427477.3429990},
abstract = { With the establishment of the 5G network, a number of data-intensive applications will be developed. Privacy of information over the network is increasingly relevant, and require protection. The privacy of information while utilizing data is a trade-off that needs to be addressed. In this paper, we propose data privacy of 5G connected devices over heterogeneous networks (5G-Hetnets). A deep Q learning (DQL) based technique is applied to sensitize sensitive information from a given database while keeping the balance between privacy protection and knowledge discovery during the sanitization process. It takes transaction states as input and results in state and action pair. The DQL discovers the transactions dynamically, then the sanitization operation hide the sensitive information by minimizing side effects. The proposed approach shows significant improvement of performance compared to greedy and meta-heuristics and heuristics approaches.},
booktitle = {Adjunct Proceedings of the 2021 International Conference on Distributed Computing and Networking},
pages = {43–48},
numpages = {6},
location = {Nara, Japan},
series = {ICDCN '21}
}

@inproceedings{10.1145/3427477.3429987,
author = {Srivastava, Gautam and G, Thippa Reddy and Deepa, N. and Prabadevi, B. and Reddy M, Praveen Kumar},
title = {An Ensemble Model for Intrusion Detection in the Internet of Softwarized Things},
year = {2021},
isbn = {9781450381840},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3427477.3429987},
doi = {10.1145/3427477.3429987},
abstract = { In recent years, there has been a rapid increase in the applications generating sensitive and personal information based on the Internet of Things (IoT). Due to the sensitive nature of the data there is a huge surge in intruders stealing the data from these applications. Hence a strong intrusion detection systems which can detect the intruders is the need of the hour to build a strong defence systems against the intruders. In this work, a Crow-Search based ensemble classifier is used to classify IoT- based UNSW-NB15 dataset. Firstly, the most significant features are selected from the dataset using Crow-Search algorithm, later these features are fed to the ensemble classifier based on Linear Regression, Random Forest and XGBoost algorithms for training. The performance of the proposed model is then evaluated against the state-of-the-art models to check for its effectiveness. The experimental results prove that the proposed model performs better than the other considered models.},
booktitle = {Adjunct Proceedings of the 2021 International Conference on Distributed Computing and Networking},
pages = {25–30},
numpages = {6},
keywords = {Crow-Search Algorithm, Intrusion Detection, Ensemble Classifier, Nature Inspired Algorithms, Internet of Things},
location = {Nara, Japan},
series = {ICDCN '21}
}

@inproceedings{10.1145/3081333.3081349,
author = {Guan, Le and Liu, Peng and Xing, Xinyu and Ge, Xinyang and Zhang, Shengzhi and Yu, Meng and Jaeger, Trent},
title = {TrustShadow: Secure Execution of Unmodified Applications with ARM TrustZone},
year = {2017},
isbn = {9781450349284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3081333.3081349},
doi = {10.1145/3081333.3081349},
abstract = {The rapid evolution of Internet-of-Things (IoT) technologies has led to an emerging need to make them smarter. A variety of applications now run simultaneously on an ARM-based processor. For example, devices on the edge of the Internet are provided with higher horsepower to be entrusted with storing, processing and analyzing data collected from IoT devices. This significantly improves efficiency and reduces the amount of data that needs to be transported to the cloud for data processing, analysis and storage. However, commodity OSes are prone to compromise. Once they are exploited, attackers can access the data on these devices. Since the data stored and processed on the devices can be sensitive, left untackled, this is particularly disconcerting. In this paper, we propose a new system, TrustShadow that shields legacy applications from untrusted OSes. TrustShadow takes advantage of ARM TrustZone technology and partitions resources into the secure and normal worlds. In the secure world, TrustShadow constructs a trusted execution environment for security-critical applications. This trusted environment is maintained by a lightweight runtime system that coordinates the communication between applications and the ordinary OS running in the normal world. The runtime system does not provide system services itself. Rather, it forwards requests for system services to the ordinary OS, and verifies the correctness of the responses. To demonstrate the efficiency of this design, we prototyped TrustShadow on a real chip board with ARM TrustZone support, and evaluated its performance using both microbenchmarks and real-world applications. We showed TrustShadow introduces only negligible overhead to real-world applications.},
booktitle = {Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {488–501},
numpages = {14},
keywords = {malicious operating systems, trusted execution, IoT, arm trustzone},
location = {Niagara Falls, New York, USA},
series = {MobiSys '17}
}

@inproceedings{10.5555/3408352.3408391,
author = {Salami, B. and Parasyris, K. and Cristal, A. and Unsal, O. and Martorell, X. and Carpenter, P. and De La Cruz, R. and Bautista, L. and Jimenez, D. and Alvarez, C. and Nabavi, S. and Madonar, S. and Peric\`{a}s, M. and Trancoso, P. and Abduljabbar, M. and Chen, J. and Soomro, P. N. and Manivannan, M and Berge, M. and Krupop, S. and Klawonn, F. and Mekhlafi, Al and May, S. and Becker, T. and Gaydadjiev, G. and Salomonsson, H. and Dubhashi, D. and Port, O. and Etsion, Y. and Do, Le Quoc and Fetzer, Christof and Kaiser, M. and Kucza, N. and Hagemeyer, J. and Griessl, R. and Tigges, L. and Mika, K. and H\"{u}ffmeier, A. and Pasin, M. and Schiavoni, V. and Rocha, I. and G\"{o}ttel, C. and Felber, P.},
title = {LEGaTO: Low-Energy, Secure, and Resilient Toolset for Heterogeneous Computing},
year = {2020},
isbn = {9783981926347},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
abstract = {The LEGaTO project leverages task-based programming models to provide a software ecosystem for Made in-Europe heterogeneous hardware composed of CPUs, GPUs, FPGAs and dataflow engines. The aim is to attain one order of magnitude energy savings from the edge to the converged cloud/HPC, balanced with the security and resilience challenges. LEGaTO is an ongoing three-year EU H2020 project started in December 2017.},
booktitle = {Proceedings of the 23rd Conference on Design, Automation and Test in Europe},
pages = {169–174},
numpages = {6},
location = {Grenoble, France},
series = {DATE '20}
}

@inproceedings{10.1145/3210240.3210313,
author = {Liu, Luyang and Zhong, Ruiguang and Zhang, Wuyang and Liu, Yunxin and Zhang, Jiansong and Zhang, Lintao and Gruteser, Marco},
title = {Cutting the Cord: Designing a High-Quality Untethered VR System with Low Latency Remote Rendering},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210313},
doi = {10.1145/3210240.3210313},
abstract = {This paper introduces an end-to-end untethered VR system design and open platform that can meet virtual reality latency and quality requirements at 4K resolution over a wireless link. High-quality VR systems generate graphics data at a data rate much higher than those supported by existing wireless-communication products such as Wi-Fi and 60GHz wireless communication. The necessary image encoding, makes it challenging to maintain the stringent VR latency requirements. To achieve the required latency, our system employs a Parallel Rendering and Streaming mechanism to reduce the add-on streaming latency, by pipelining the rendering, encoding, transmission and decoding procedures. Furthermore, we introduce a Remote VSync Driven Rendering technique to minimize display latency. To evaluate the system, we implement an end-to-end remote rendering platform on commodity hardware over a 60Ghz wireless network. Results show that the system can support current 2160x1200 VR resolution at 90Hz with less than 16ms end-to-end latency, and 4K resolution with 20ms latency, while keeping a visually lossless image quality to the user.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {68–80},
numpages = {13},
keywords = {60GHz, High-quality, Low latency, Untethered, Virtual Reality},
location = {Munich, Germany},
series = {MobiSys '18}
}

@inproceedings{10.1145/3376897.3377864,
author = {Kothari, Vivek and Liberis, Edgar and Lane, Nicholas D.},
title = {The Final Frontier: Deep Learning in Space},
year = {2020},
isbn = {9781450371162},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3376897.3377864},
doi = {10.1145/3376897.3377864},
abstract = {Machine learning, particularly deep learning, is being increasing utilised in space applications, mirroring the groundbreaking success in many earthbound problems. Deploying a space device, e.g. a satellite, is becoming more accessible to small actors due to the development of modular satellites and commercial space launches, which fuels further growth of this area. Deep learning's ability to deliver sophisticated computational intelligence makes it an attractive option to facilitate various tasks on space devices and reduce operational costs. In this work, we identify deep learning in space as one of development directions for mobile and embedded machine learning. We collate various applications of machine learning to space data, such as satellite imaging, and describe how on-device deep learning can meaningfully improve the operation of a spacecraft, such as by reducing communication costs or facilitating navigation. We detail and contextualise compute platform of satellites and draw parallels with embedded systems and current research in deep learning for resource-constrained environments.},
booktitle = {Proceedings of the 21st International Workshop on Mobile Computing Systems and Applications},
pages = {45–49},
numpages = {5},
keywords = {autonomy, deep learning, hardware in space},
location = {Austin, TX, USA},
series = {HotMobile '20}
}

@inproceedings{10.1145/3322385.3322403,
author = {Niederman, Fred and Kaarst-Brown, Michelle and Quesenberry, Jeria and Weitzel, Tim},
title = {The Future of IT Work},
year = {2019},
isbn = {9781450360883},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3322385.3322403},
doi = {10.1145/3322385.3322403},
abstract = {The future of work is widely debated in terms of skills shortages, disappearing or emerging jobs, ongoing automation through artificial intelligence (AI), and what might happen if we do not have to work due to increased substitution of human with machine labor. Our goal is not to rehash these debates, but to reflect on them in terms of information technology (IT) work in particular. The purpose of thinking about the future is not to predict with precision or certainty what will happen. Rather the purpose is to sensitize us toward choosing pathways and taking actions that increase the probability of the futures we would prefer and decrease the probability of future states we would like to avoid. This paper considers a number of trends and reflects upon them from the dual, potentially conflicting perspectives of IT worker and of society. We close with our thoughts on convergence of both trends and impact, and potential implications.},
booktitle = {Proceedings of the 2019 on Computers and People Research Conference},
pages = {28–34},
numpages = {7},
keywords = {role of it professionals, it professional, it identity, work},
location = {Nashville, TN, USA},
series = {SIGMIS-CPR '19}
}

@inproceedings{10.1145/3290605.3300475,
author = {Sanches, Pedro and Janson, Axel and Karpashevich, Pavel and Nadal, Camille and Qu, Chengcheng and Daud\'{e}n Roquet, Claudia and Umair, Muhammad and Windlin, Charles and Doherty, Gavin and H\"{o}\"{o}k, Kristina and Sas, Corina},
title = {HCI and Affective Health: Taking Stock of a Decade of Studies and Charting Future Research Directions},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300475},
doi = {10.1145/3290605.3300475},
abstract = {In the last decade, the number of articles on HCI and health has increased dramatically. We extracted 139 papers on depression, anxiety and bipolar health issues from 10 years of SIGCHI conference proceedings. 72 of these were published in the last two years. A systematic analysis of this growing body of literature revealed that most innovation happens in automated diagnosis, and self-tracking, although there are innovative ideas in tangible interfaces. We noted an overemphasis on data production without consideration of how it leads to fruitful interventions. Moreover, we see a need to promote ethical practices for involvement of people living with affective disorders. Finally, although only 16 studies evaluate technologies in a clinical context, several forms of support and intervention illustrate how rich insights are gained from evaluations with real patients. Our findings highlight potential for growth in the design space of affective health technologies.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–17},
numpages = {17},
keywords = {innovation, literature review, affective disorders, ethical issues, clinical trials},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3229584.3229588,
author = {Yaqoob, Touseef and Usama, Muhammad and Qadir, Junaid and Tyson, Gareth},
title = {On Analyzing Self-Driving Networks: A Systems Thinking Approach},
year = {2018},
isbn = {9781450359146},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3229584.3229588},
doi = {10.1145/3229584.3229588},
abstract = {Along with recent networking advances (such as software-defined networks, network functions virtualization, and programmable data planes), the networking field, in a bid to construct highly optimized self-driving and self-organizing networks, is increasingly embracing artificial intelligence and machine learning. It is worth remembering that the modern Internet that interconnects millions of networks is a 'complex adaptive social system', in which interventions not only cause effects but the effects have further knock-on consequences (not all of which are desirable or anticipated). We believe that self-driving networks will likely raise new unanticipated challenges (particularly in the human-facing domains of ethics, privacy, and security). In this paper, we propose the use of insights and tools from the field of "systems thinking"---a rich discipline developing for more than half a century, which encompasses more realistic models of complex social systems---and highlight their relevance for studying the long-term effects of network architectural interventions, particularly for self-driving networks. We show that these tools complement existing simulation and modeling tools and provide new insights and capabilities. To the best of our knowledge, this is the first study that has considered the relevance of formal systems thinking tools for the analysis of self-driving networks.},
booktitle = {Proceedings of the Afternoon Workshop on Self-Driving Networks},
pages = {1–7},
numpages = {7},
location = {Budapest, Hungary},
series = {SelfDN 2018}
}

@article{10.1145/3310013.3322175,
author = {Mascardi, Viviana and Weyns, Danny and Ricci, Alessandro and Earle, Clara Benac and Casals, Arthur and Challenger, Moharram and Chopra, Amit and Ciortea, Andrei and Dennis, Louise A. and D\'{\i}az, \'{A}lvaro Fern\'{a}ndez and El Fallah-Seghrouchni, Amal and Ferrando, Angelo and Fredlund, Lars-\r{A}ke and Giunchiglia, Eleonora and Guessoum, Zahia and G\"{u}nay, Akin and Hindriks, Koen and Iglesias, Carlos A. and Logan, Brian and Kampik, Timotheus and Kardas, Geylani and Koeman, Vincent J. and Larsen, John Bruntse and Mayer, Simon and M\'{e}ndez, Tasio and Nieves, Juan Carlos and Seidita, Valeria and Teze, Baris Tekin and Varga, L\'{a}szl\'{o} Z. and Winikoff, Michael},
title = {Engineering Multi-Agent Systems: State of Affairs and the Road Ahead},
year = {2019},
issue_date = {January 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {1},
issn = {0163-5948},
url = {https://doi.org/10.1145/3310013.3322175},
doi = {10.1145/3310013.3322175},
abstract = {The continuous integration of software-intensive systems together with the ever-increasing computing power offer a breeding ground for intelligent agents and multi-agent systems (MAS) more than ever before. Over the past two decades, a wide variety of languages, models, techniques and methodologies have been proposed to engineer agents and MAS. Despite this substantial body of knowledge and expertise, the systematic engineering of large-scale and open MAS still poses many challenges. Researchers and engineers still face fundamental questions regarding theories, architectures, languages, processes, and platforms for designing, implementing, running, maintaining, and evolving MAS. This paper reports on the results of the 6th International Workshop on Engineering Multi-Agent Systems (EMAS 2018, 14th-15th of July, 2018, Stockholm, Sweden), where participants discussed the issues above focusing on the state of affairs and the road ahead for researchers and engineers in this area.},
journal = {SIGSOFT Softw. Eng. Notes},
month = mar,
pages = {18–28},
numpages = {11},
keywords = {goal reasoning, ai., software engineering, multi-agent systems, agents}
}

@inproceedings{10.1109/ICSE-SEIP.2019.00042,
author = {Amershi, Saleema and Begel, Andrew and Bird, Christian and DeLine, Robert and Gall, Harald and Kamar, Ece and Nagappan, Nachiappan and Nushi, Besmira and Zimmermann, Thomas},
title = {Software Engineering for Machine Learning: A Case Study},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP.2019.00042},
doi = {10.1109/ICSE-SEIP.2019.00042},
abstract = {Recent advances in machine learning have stimulated widespread interest within the Information Technology sector on integrating AI capabilities into software and services. This goal has forced organizations to evolve their development processes. We report on a study that we conducted on observing software teams at Microsoft as they develop AI-based applications. We consider a nine-stage workflow process informed by prior experiences developing AI applications (e.g., search and NLP) and data science tools (e.g. application diagnostics and bug reporting). We found that various Microsoft teams have united this workflow into preexisting, well-evolved, Agile-like software engineering processes, providing insights about several essential engineering challenges that organizations may face in creating large-scale AI solutions for the marketplace. We collected some best practices from Microsoft teams to address these challenges. In addition, we have identified three aspects of the AI domain that make it fundamentally different from prior software application domains: 1) discovering, managing, and versioning the data needed for machine learning applications is much more complex and difficult than other types of software engineering, 2) model customization and model reuse require very different skills than are typically found in software teams, and 3) AI components are more difficult to handle as distinct modules than traditional software components --- models may be "entangled" in complex ways and experience non-monotonic error behavior. We believe that the lessons learned by Microsoft teams will be valuable to other organizations.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering: Software Engineering in Practice},
pages = {291–300},
numpages = {10},
keywords = {process, AI, software engineering, data},
location = {Montreal, Quebec, Canada},
series = {ICSE-SEIP '19}
}

@inproceedings{10.1145/3274808.3274830,
author = {Benson, Kyle E. and Bouloukakis, Georgios and Grant, Casey and Issarny, Val\'{e}rie and Mehrotra, Sharad and Moscholios, Ioannis and Venkatasubramanian, Nalini},
title = {FireDeX: A Prioritized IoT Data Exchange Middleware for Emergency Response},
year = {2018},
isbn = {9781450357029},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3274808.3274830},
doi = {10.1145/3274808.3274830},
abstract = {Real-time event detection and targeted decision making for emerging mission-critical applications, e.g. smart fire fighting, requires systems that extract and process relevant data from connected IoT devices in the environment. In this paper, we propose FireDeX, a cross-layer middleware that facilitates timely and effective exchange of data for coordinating emergency response activities. FireDeX adopts a publish-subscribe data exchange paradigm with brokers at the network edge to manage prioritized delivery of mission-critical data from IoT sources to relevant subscribers. It incorporates parameters at the application, network, and middleware layers into a data exchange service that accurately estimates end-to-end performance metrics (e.g. delays, success rates). We design an extensible queueing theoretic model that abstracts these cross-layer interactions as a network of queues, thereby making it amenable for rapid analysis. We propose novel algorithms that utilize results of this analysis to tune data exchange configurations (event priorities and dropping policies) while meeting situational awareness requirements and resource constraints. FireDeX leverages Software-Defined Networking (SDN) methodologies to enforce these configurations in the IoT network infrastructure. We evaluate its performance through simulated experiments in a smart building fire response scenario. Our results demonstrate significant improvement to mission-critical data delivery under a variety of conditions. Our application-aware prioritization algorithm improves the value of exchanged information by 36% when compared with no prioritization; the addition of our network-aware drop rate policies improves this performance by 42% over priorities only and by 94% over no prioritization.},
booktitle = {Proceedings of the 19th International Middleware Conference},
pages = {279–292},
numpages = {14},
keywords = {Utility Functions, SDN, Publish/Subscribe Middleware, Queueing Networks, Event Prioritization, Emergency Response},
location = {Rennes, France},
series = {Middleware '18}
}

@inproceedings{10.1145/3384943.3409431,
author = {Norvill, Robert and Cassanges, Cyril and Shbair, Wazen and Hilger, Jean and Cullen, Andrea and State, Radu},
title = {A Security and Privacy Focused KYC Data Sharing Platform},
year = {2020},
isbn = {9781450376105},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384943.3409431},
doi = {10.1145/3384943.3409431},
abstract = {Banks in Europe must comply with new EU regulation and legislation. Recent legislation has focused on personal data, Know Your Customer (KYC), and anti-money laundering. As a result, the cost of KYC compliance is higher than ever, requiring time consuming work by both the banks and their customers in the form of document collection and verification. In this paper we detail a system designed to ease the burden of compliance for banks within the EU and save their customers time through the secure and permissioned sharing of digital KYC data. In order to share data, banks need a secure system capable of protecting the privacy of both them and their clients. We detail a system which uses blockchain technology and various privacy and security enhancing techniques to provide banks with a fast and secure way to share documents required for know your customer compliance. The system was built to be aligned with the GDPR, meaning each participating bank must have explicit permission for a customer to access one or more of their documents. These permissions are stored on a private blockchain shared by the banks. Moreover, we detail methods to anonymise on-chain data where necessary. The use of a private blockchain to achieve consensus on the veracity of customer-granted permissions to data enables participating banks to trust one another as each permission and request is observed, agreed upon, and stored on-chain. To the best of our knowledge we propose the first data sharing system under which there is no outsourcing of data storage. This allows the banks to retain full control of storage security and encryption.},
booktitle = {Proceedings of the 2nd ACM International Symposium on Blockchain and Secure Critical Infrastructure},
pages = {151–160},
numpages = {10},
keywords = {blockchain, security, privacy, anonymity, KYC, data sharing},
location = {Taipei, Taiwan},
series = {BSCI '20}
}

@article{10.1109/TNET.2019.2944984,
author = {Wu, Haiqin and Wang, Liangmin and Xue, Guoliang and Tang, Jian and Yang, Dejun},
title = {Enabling Data Trustworthiness and User Privacy in Mobile Crowdsensing},
year = {2019},
issue_date = {Dec. 2019},
publisher = {IEEE Press},
volume = {27},
number = {6},
issn = {1063-6692},
url = {https://doi.org/10.1109/TNET.2019.2944984},
doi = {10.1109/TNET.2019.2944984},
abstract = {Ubiquitous mobile devices with rich sensors and advanced communication capabilities have given rise to mobile crowdsensing systems. The diverse reliabilities of mobile users and the openness of sensing paradigms raise concerns for data trustworthiness, user privacy, and incentive provision. Instead of considering these issues as isolated modules in most existing researches, we comprehensively capture both conflict and inner-relationship among them. In this paper, we propose a holistic solution for trustworthy and privacy-aware mobile crowdsensing with no need of a trusted third party. Specifically, leveraging cryptographic technologies, we devise a series of protocols to enable benign users to request tasks, contribute their data, and earn rewards anonymously without any data linkability. Meanwhile, an anonymous trust/reputation model is seamlessly integrated into our scheme, which acts as reference for our fair incentive design, and provides evidence to detect malicious users who degrade the data trustworthiness. Particularly, we first propose the idea of limiting the number of issued pseudonyms which serves to efficiently tackle the anonymity abuse issue. Security analysis demonstrates that our proposed scheme achieves stronger security with resilience against possible collusion attacks. Extensive simulations are presented which demonstrate the efficiency and practicality of our scheme.},
journal = {IEEE/ACM Trans. Netw.},
month = dec,
pages = {2294–2307},
numpages = {14}
}

